learning...
IDS: learning...
IDS: Search Depth 2: 6.8903e-05 / 80 = 8.61287e-07
IDS: Search Depth 3: 0.000230551 / 80 = 2.88188e-06
IDS: Search Depth 4: 0.000355005 / 80 = 4.43757e-06
IDS: Search Depth 5: 0.000482798 / 80 = 6.03497e-06
IDS: Search Depth 6: 0.000607252 / 80 = 7.59065e-06
IDS: Search Depth 7: 0.000725031 / 80 = 9.06289e-06
IDS: Search Depth 8: 0.000840187 / 80 = 1.05023e-05
IDS: Search Depth 9: 0.000953674 / 80 = 1.19209e-05
IDS: Search Depth 10: 0.00106859 / 80 = 1.33574e-05
IDS: Search Depth 11: 0.00118303 / 80 = 1.47879e-05
IDS: Search Depth 12: 0.00129175 / 80 = 1.61469e-05
IDS: Search Depth 13: 0.00140929 / 80 = 1.76162e-05
IDS: Search Depth 14: 0.00151801 / 80 = 1.89751e-05
IDS: Search Depth 15: 0.00163507 / 80 = 2.04384e-05
IDS: Search Depth 16: 0.00175285 / 80 = 2.19107e-05
IDS: Search Depth 17: 0.00186801 / 80 = 2.33501e-05
IDS: Search Depth 18: 0.00197887 / 80 = 2.47359e-05
IDS: Search Depth 19: 0.00209308 / 80 = 2.61635e-05
IDS: Search Depth 20: 0.00221419 / 80 = 2.76774e-05
IDS: Search Depth 21: 0.00232935 / 80 = 2.91169e-05
IDS: Search Depth 22: 0.00244117 / 80 = 3.05146e-05
IDS: Search Depth 23: 0.0025599 / 80 = 3.19988e-05
IDS: Search Depth 24: 0.0026722 / 80 = 3.34024e-05
IDS: Search Depth 25: 0.0027864 / 80 = 3.483e-05
IDS: Search Depth 26: 0.00290298 / 80 = 3.62873e-05
IDS: Search Depth 27: 0.0030148 / 80 = 3.7685e-05
IDS: Search Depth 28: 0.00312591 / 80 = 3.90738e-05
IDS: Search Depth 29: 0.00324011 / 80 = 4.05014e-05
IDS: Search Depth 30: 0.00336432 / 80 = 4.20541e-05
IDS: Search Depth 31: 0.00348401 / 80 = 4.35501e-05
IDS: Search Depth 32: 0.00358987 / 80 = 4.48734e-05
IDS: Search Depth 33: 0.00370789 / 80 = 4.63486e-05
IDS: Search Depth 34: 0.00381899 / 80 = 4.77374e-05
IDS: Search Depth 35: 0.003932 / 80 = 4.915e-05
IDS: Search Depth 36: 0.00404263 / 80 = 5.05328e-05
IDS: Search Depth 37: 0.00415754 / 80 = 5.19693e-05
IDS: Search Depth 38: 0.00427055 / 80 = 5.33819e-05
IDS: Search Depth 39: 0.00438356 / 80 = 5.47945e-05
IDS: Search Depth 40: 0.00451899 / 80 = 5.64873e-05
IDS: Setting max search depth to 40!
IDS: ...finished
DP-UCT: learning...
DP-UCT: ...finished
...finished (0.044986s).

Final task: 
----------------Actions---------------

Action fluents: 
move-east
move-north
move-south
move-west
---------------

Legal Action Combinations: 
noop() : 
Index : 0
Relevant preconditions: 
---------------
move-west : 
Index : 1
Relevant preconditions: 
---------------
move-south : 
Index : 2
Relevant preconditions: 
---------------
move-north : 
Index : 3
Relevant preconditions: 
---------------
move-east : 
Index : 4
Relevant preconditions: 
---------------

-----------------CPFs-----------------

obstacle-at(x1, y2)
  HashIndex: 0, deterministic, caching in vectors, Kleene caching in vectors of size 3.

  Action Hash Key Map: 
  Formula: 
obstacle-at(x2, y2)

  Domain: false true 
  HashKeyBase: 0: 0, 1: 1
  KleeneHashKeyBase: 1

--------------
obstacle-at(x2, y2)
  HashIndex: 1, deterministic, caching in vectors, Kleene caching in vectors of size 3.

  Action Hash Key Map: 
  Formula: 
obstacle-at(x3, y2)

  Domain: false true 
  HashKeyBase: 0: 0, 1: 2
  KleeneHashKeyBase: 3

--------------
robot-at(x1, y1)
  HashIndex: 2, deterministic, caching in vectors, Kleene caching in vectors of size 1215.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x3, y3) then 0
case (and move-north robot-at(x1, y1))  then 0
case (and move-south robot-at(x1, y2) (not obstacle-at(x1, y2)) )  then 1
case (and move-east robot-at(x1, y1))  then 0
case (and move-west robot-at(x2, y1))  then 1
case 1 then robot-at(x1, y1)


  Domain: false true 
  HashKeyBase: 0: 0, 1: 4
  KleeneHashKeyBase: 9

--------------
robot-at(x1, y2)
  HashIndex: 3, deterministic, caching in vectors, Kleene caching in vectors of size 10935.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x3, y3) then 0
case (and move-north robot-at(x1, y1))  then 1
case (and move-north robot-at(x1, y2))  then 0
case (and move-south robot-at(x1, y3))  then 1
case (and move-south robot-at(x1, y2))  then 0
case (and move-east robot-at(x1, y2))  then 0
case (and move-west robot-at(x2, y2) (not obstacle-at(x2, y2)) )  then 1
case 1 then (and robot-at(x1, y2) (not obstacle-at(x1, y2)) ) 


  Domain: false true 
  HashKeyBase: 0: 0, 1: 8
  KleeneHashKeyBase: 27

--------------
robot-at(x1, y3)
  HashIndex: 4, deterministic, caching in vectors, Kleene caching in vectors of size 1215.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x3, y3) then 0
case (and move-north robot-at(x1, y2) (not obstacle-at(x1, y2)) )  then 1
case (and move-south robot-at(x1, y3))  then 0
case (and move-east robot-at(x1, y3))  then 0
case (and move-west robot-at(x2, y3))  then 1
case 1 then robot-at(x1, y3)


  Domain: false true 
  HashKeyBase: 0: 0, 1: 16
  KleeneHashKeyBase: 81

--------------
robot-at(x2, y1)
  HashIndex: 5, deterministic, caching in vectors, Kleene caching in vectors of size 3645.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x3, y3) then 0
case (and move-north robot-at(x2, y1))  then 0
case (and move-south robot-at(x2, y2) (not obstacle-at(x2, y2)) )  then 1
case (and move-east robot-at(x1, y1))  then 1
case (and move-east robot-at(x2, y1))  then 0
case (and move-west robot-at(x3, y1))  then 1
case (and move-west robot-at(x2, y1))  then 0
case 1 then robot-at(x2, y1)


  Domain: false true 
  HashKeyBase: 0: 0, 1: 32
  KleeneHashKeyBase: 243

--------------
robot-at(x2, y2)
  HashIndex: 6, deterministic, caching in vectors, Kleene caching in vectors of size 98415.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x3, y3) then 0
case (and move-north robot-at(x2, y1))  then 1
case (and move-north robot-at(x2, y2))  then 0
case (and move-south robot-at(x2, y3))  then 1
case (and move-south robot-at(x2, y2))  then 0
case (and move-east robot-at(x1, y2) (not obstacle-at(x1, y2)) )  then 1
case (and move-east robot-at(x2, y2))  then 0
case (and move-west robot-at(x3, y2) (not obstacle-at(x3, y2)) )  then 1
case (and move-west robot-at(x2, y2))  then 0
case 1 then (and robot-at(x2, y2) (not obstacle-at(x2, y2)) ) 


  Domain: false true 
  HashKeyBase: 0: 0, 1: 64
  KleeneHashKeyBase: 729

--------------
robot-at(x2, y3)
  HashIndex: 7, deterministic, caching in vectors, Kleene caching in vectors of size 1215.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x3, y3) then 0
case (and move-north robot-at(x2, y2) (not obstacle-at(x2, y2)) )  then 1
case (and move-south robot-at(x2, y3))  then 0
case (and move-east robot-at(x1, y3))  then 1
case (and move-east robot-at(x2, y3))  then 0
case (and move-west robot-at(x3, y3))  then 1
case (and move-west robot-at(x2, y3))  then 0
case 1 then robot-at(x2, y3)


  Domain: false true 
  HashKeyBase: 0: 0, 1: 128
  KleeneHashKeyBase: 2187

--------------
robot-at(x3, y1)
  HashIndex: 8, deterministic, caching in vectors, Kleene caching in vectors of size 1215.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x3, y3) then 0
case (and move-north robot-at(x3, y1))  then 0
case (and move-south robot-at(x3, y2) (not obstacle-at(x3, y2)) )  then 1
case (and move-east robot-at(x2, y1))  then 1
case (and move-west robot-at(x3, y1))  then 0
case 1 then robot-at(x3, y1)


  Domain: false true 
  HashKeyBase: 0: 0, 1: 256
  KleeneHashKeyBase: 6561

--------------
robot-at(x3, y2)
  HashIndex: 9, deterministic, caching in vectors, Kleene caching in vectors of size 3645.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x3, y3) then 0
case (and move-north robot-at(x3, y1))  then 1
case (and move-north robot-at(x3, y2))  then 0
case (and move-south robot-at(x3, y3))  then 1
case (and move-south robot-at(x3, y2))  then 0
case (and move-east robot-at(x2, y2) (not obstacle-at(x2, y2)) )  then 1
case (and move-west robot-at(x3, y2))  then 0
case 1 then (and robot-at(x3, y2) (not obstacle-at(x3, y2)) ) 


  Domain: false true 
  HashKeyBase: 0: 0, 1: 512
  KleeneHashKeyBase: 19683

--------------
robot-at(x3, y3)
  HashIndex: 10, deterministic, caching in vectors, Kleene caching in vectors of size 405.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x3, y3) then 1
case robot-at(x3, y3) then 0
case (and move-north robot-at(x3, y2) (not obstacle-at(x3, y2)) )  then 1
case (and move-south robot-at(x3, y3))  then 0
case (and move-east robot-at(x2, y3))  then 1
case (and move-west robot-at(x3, y3))  then 0
case 1 then robot-at(x3, y3)


  Domain: false true 
  HashKeyBase: 0: 0, 1: 1024
  KleeneHashKeyBase: 59049

--------------
obstacle-at(x3, y2)
  HashIndex: 11, probabilistic, caching in vectors, Kleene caching in vectors of size 1.

  Action Hash Key Map: 
  Formula: 
Bernoulli(0.3) 
  Determinized formula: 
0
  Domain: false true 
  HashKeyBase: 0: 0, 1: 2048
  KleeneHashKeyBase: 177147

--------------

Reward CPF:
Reward
  HashIndex: 12, deterministic, caching in vectors, Kleene caching in vectors of size 3.

  Action Hash Key Map: 
  Formula: 
(- 0 (not robot-at(x3, y3)) ) 
Minimal reward: -1
Maximal reward: 0
Is action independent: 1



------State Fluent Hash Key Map-------

a change of deterministic state fluent 0 influences variables 2 (5) 3 (5) 4 (5) 6 (5) 
a change of deterministic state fluent 1 influences variables 0 (1) 3 (10) 5 (5) 6 (10) 7 (5) 9 (5) 
a change of deterministic state fluent 2 influences variables 2 (10) 3 (20) 5 (10) 
a change of deterministic state fluent 3 influences variables 2 (20) 3 (40) 4 (10) 6 (20) 
a change of deterministic state fluent 4 influences variables 3 (80) 4 (20) 7 (10) 
a change of deterministic state fluent 5 influences variables 2 (40) 5 (20) 6 (40) 8 (5) 
a change of deterministic state fluent 6 influences variables 3 (160) 5 (40) 6 (80) 7 (20) 9 (10) 
a change of deterministic state fluent 7 influences variables 4 (40) 6 (160) 7 (40) 10 (5) 
a change of deterministic state fluent 8 influences variables 5 (80) 8 (10) 9 (20) 
a change of deterministic state fluent 9 influences variables 6 (320) 8 (20) 9 (40) 10 (10) 
a change of deterministic state fluent 10 influences variables 2 (80) 3 (320) 4 (80) 5 (160) 6 (640) 7 (80) 8 (40) 9 (80) 10 (20) 12 (1) 

a change of probabilistic state fluent 0 influences variables 1 (1) 6 (1280) 8 (80) 9 (160) 10 (40) 


a change of variable 0 influences variables in Kleene states 2 (5) 3 (5) 4 (5) 6 (5) 
a change of variable 1 influences variables in Kleene states 0 (1) 3 (15) 5 (5) 6 (15) 7 (5) 9 (5) 
a change of variable 2 influences variables in Kleene states 2 (15) 3 (45) 5 (15) 
a change of variable 3 influences variables in Kleene states 2 (45) 3 (135) 4 (15) 6 (45) 
a change of variable 4 influences variables in Kleene states 3 (405) 4 (45) 7 (15) 
a change of variable 5 influences variables in Kleene states 2 (135) 5 (45) 6 (135) 8 (5) 
a change of variable 6 influences variables in Kleene states 3 (1215) 5 (135) 6 (405) 7 (45) 9 (15) 
a change of variable 7 influences variables in Kleene states 4 (135) 6 (1215) 7 (135) 10 (5) 
a change of variable 8 influences variables in Kleene states 5 (405) 8 (15) 9 (45) 
a change of variable 9 influences variables in Kleene states 6 (3645) 8 (45) 9 (135) 10 (15) 
a change of variable 10 influences variables in Kleene states 2 (405) 3 (3645) 4 (405) 5 (1215) 6 (10935) 7 (405) 8 (135) 9 (405) 10 (45) 12 (1) 
a change of variable 11 influences variables in Kleene states 1 (1) 6 (32805) 8 (405) 9 (1215) 10 (135) 

---------Action Preconditions---------

----------Initial State---------------

obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 1
robot-at(x3, y2): 0
robot-at(x3, y3): 0

obstacle-at(x3, y2): 1
Remaining Steps: 40
StateHashKey: 2305

Hashing of States is possible.
Hashing of KleeneStates is possible.
Reward lock detection is enabled for goals and dead ends.
This task contains unreasonable actions.
The final reward is determined by applying NOOP.

***********************************************
>>> STARTING ROUND 1 -- REMAINING TIME 1080s
***********************************************
***********************************************
Planning step 1/40 in round 1/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 0.8975s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0169089s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1635
Cache Hits: 0
Skipped backups: 2214
Initialization: 
  Statistics of IDS:
  Average search depth: 3.19149 (in 47 runs)
  Maximal search depth: 40
  Cache hits: 244

Root Node: 
-5.22925 (in 503 real visits)

Q-Value Estimates: 
noop() : -14.1 (in 51 real visits)
move-west : -5.22925 (in 443 real visits)
move-north : -13.4 (in 9 real visits)

Used RAM: 313600

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 1/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 1 

Setting time for this decision to 0.898194328607173s.
DP-UCT: Maximal search depth set to 39

Search time: 0.013057s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1628
Cache Hits: 0
Skipped backups: 4400
Initialization: 
  Statistics of IDS:
  Average search depth: 3.19149 (in 47 runs)
  Maximal search depth: 40
  Cache hits: 539

Root Node: 
-5.34137 (in 504 real visits)

Q-Value Estimates: 
noop() : -5.34137 (in 467 real visits)
move-west : -15.2625 (in 12 real visits)
move-north : SOLVED with: -39 (in 3 real visits)
move-east : -14.255 (in 22 real visits)

Used RAM: 313788

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 1/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 0.898928213689482s.
DP-UCT: Maximal search depth set to 38

Search time: 0.010649s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1611
Cache Hits: 0
Skipped backups: 6758
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 821

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -12.425 (in 10 real visits)
move-west : -14.9167 (in 10 real visits)
move-north : -3 (in 474 real visits)
move-east : -10.7 (in 10 real visits)

Used RAM: 313788

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 1/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 0 

Setting time for this decision to 0.899663324979114s.
DP-UCT: Maximal search depth set to 37

Search time: 0.00836897s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1575
Cache Hits: 0
Skipped backups: 9082
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1091

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -5.325 (in 10 real visits)
move-west : -11.955 (in 10 real visits)
move-south : -7.15 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -12.5 (in 10 real visits)

Used RAM: 313788

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 1/30
Current state: 0 0 0 0 0 0 0 1 0 0 0 | 1 

Setting time for this decision to 0.900402173913044s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0117242s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1568
Cache Hits: 0
Skipped backups: 11782
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 488 real visits)
move-west : -5.9 (in 10 real visits)
move-south : SOLVED with: -36 (in 3 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313788

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 1/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.90113640167364s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 35
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 1/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.901886097152429s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 34
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 1/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.902636211232188s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 33
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 1/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.903388422818792s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 32
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 1/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.904141057934509s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 31
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 1/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.904896638655462s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 30
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 1/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.905652649285113s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 29
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 1/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.906407407407407s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 28
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 1/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.907165122156698s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 27
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 1/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.907924957841484s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 26
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 1/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.908685232067511s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 25
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 1/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.909446790540541s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 24
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 1/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.910210481825866s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 23
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 1/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.91097461928934s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 22
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 1/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.911740897544454s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 21
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 1/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.912508474576271s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 20
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 1/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.913278201865988s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 19
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 1/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.914050084889643s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 18
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 1/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.914822429906542s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 17
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 1/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.915596088435374s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 16
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 1/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.916371063829787s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 15
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 1/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.917148211243612s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 14
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 1/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.917926683716965s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 13
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 1/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.918707337883959s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 12
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 1/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.919487617421008s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 11
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 1/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.920268376068376s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 10
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 1/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.921051325919589s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 9
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 1/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.921837328767123s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 8
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 1/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.92262382176521s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 7
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 1/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.923412521440823s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 6
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 1/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.924202575107296s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 5
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 1/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.924993127147766s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 4
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 1/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.925784178847807s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 3
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 1/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.926577452667814s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 2
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 1/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.927372093023256s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.22449 (in 49 runs)
  Maximal search depth: 40
  Cache hits: 1366

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 500
Accumulated number of search nodes in root state: 1635

Used RAM: 313788

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 1 -- REWARD RECEIVED: -5
***********************************************

***********************************************
>>> STARTING ROUND 2 -- REMAINING TIME 1079s
***********************************************
***********************************************
Planning step 1/40 in round 2/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 0.928168965517241s.
DP-UCT: Maximal search depth set to 40

Search time: 0.00864792s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1632
Cache Hits: 0
Skipped backups: 14080
Initialization: 
  Statistics of IDS:
  Average search depth: 3.26 (in 50 runs)
  Maximal search depth: 40
  Cache hits: 1653

Root Node: 
-5.2765 (in 503 real visits)

Q-Value Estimates: 
noop() : -14.1 (in 14 real visits)
move-west : -5.2765 (in 479 real visits)
move-north : -13.4 (in 10 real visits)

Used RAM: 313788

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 2/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 1 

Setting time for this decision to 0.928928386540121s.
DP-UCT: Maximal search depth set to 39

Search time: 0.00961208s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1685
Cache Hits: 0
Skipped backups: 16200
Initialization: 
  Statistics of IDS:
  Average search depth: 3.26 (in 50 runs)
  Maximal search depth: 40
  Cache hits: 1964

Root Node: 
-5.36552 (in 504 real visits)

Q-Value Estimates: 
noop() : -5.36552 (in 447 real visits)
move-west : -15.4462 (in 12 real visits)
move-north : SOLVED with: -39 (in 3 real visits)
move-east : -12.4276 (in 42 real visits)

Used RAM: 313792

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 2/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 0.929719343696028s.
DP-UCT: Maximal search depth set to 38

Search time: 0.00823998s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1604
Cache Hits: 0
Skipped backups: 18604
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2246

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -14.45 (in 10 real visits)
move-west : -14.9167 (in 10 real visits)
move-north : -3 (in 474 real visits)
move-east : -11.9975 (in 10 real visits)

Used RAM: 313800

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 2/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 0 

Setting time for this decision to 0.930512532411409s.
DP-UCT: Maximal search depth set to 37

Search time: 0.00978494s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1610
Cache Hits: 0
Skipped backups: 20992
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2525

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -5.325 (in 10 real visits)
move-west : -6.25 (in 10 real visits)
move-south : -13.6667 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -12.5 (in 10 real visits)

Used RAM: 313800

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 2/30
Current state: 0 0 0 0 0 0 0 1 0 0 0 | 0 

Setting time for this decision to 0.931306228373702s.
DP-UCT: Maximal search depth set to 36

Search time: 0.00973797s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1520
Cache Hits: 0
Skipped backups: 23034
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 244 real visits)
move-west : -3 (in 251 real visits)
move-south : -11.15 (in 6 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313800

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 2/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.932099567099567s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 35
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 2/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.932903812824957s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 34
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 2/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.933708586296618s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 33
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 2/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.934515625s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 32
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 2/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.93532406602954s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 31
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 2/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.936133913043478s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 30
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 2/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.936946040034813s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 29
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 2/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.937757839721254s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 28
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 2/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.938571054925894s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 27
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 2/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.939385689354276s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 26
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 2/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.940202620087336s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 25
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 2/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.941020979020979s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 24
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 2/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.941839895013123s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 23
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 2/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.942660245183888s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 22
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 2/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.943482033304119s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 21
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 2/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.944306140350877s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 20
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 2/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.945130816505707s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 19
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 2/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.945958699472759s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 18
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 2/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.946787159190853s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 17
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 2/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.947617077464789s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 16
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 2/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.948447577092511s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 15
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 2/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.949280423280423s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 14
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 2/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.95011385701677s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 13
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 2/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.950949646643109s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 12
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 2/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.951786030061892s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 11
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 2/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.95262389380531s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 10
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 2/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.953464127546501s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 9
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 2/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.95430585106383s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 8
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 2/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.955148181011535s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 7
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 2/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.955992895204263s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 6
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 2/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.956838222222222s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 5
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 2/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.957687722419929s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 4
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 2/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.958537845057881s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 3
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 2/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.959390374331551s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 2
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 2/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.960244424620874s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 2787

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 1000
Accumulated number of search nodes in root state: 3267

Used RAM: 313800

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 2 -- REWARD RECEIVED: -5
***********************************************

***********************************************
>>> STARTING ROUND 3 -- REMAINING TIME 1079s
***********************************************
***********************************************
Planning step 1/40 in round 3/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 0.961098214285714s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0165598s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1715
Cache Hits: 0
Skipped backups: 25324
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 3107

Root Node: 
-5.19077 (in 503 real visits)

Q-Value Estimates: 
noop() : -14.4733 (in 24 real visits)
move-west : -5.19077 (in 455 real visits)
move-north : -13.4 (in 24 real visits)

Used RAM: 313800

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 3/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 1 

Setting time for this decision to 0.961907059874888s.
DP-UCT: Maximal search depth set to 39

Search time: 0.010078s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1696
Cache Hits: 0
Skipped backups: 27486
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 3421

Root Node: 
-5.242 (in 504 real visits)

Q-Value Estimates: 
noop() : -5.242 (in 469 real visits)
move-west : -15.4462 (in 15 real visits)
move-north : SOLVED with: -39 (in 3 real visits)
move-east : -14.9475 (in 17 real visits)

Used RAM: 313808

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 3/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 | 1 

Setting time for this decision to 0.962755813953488s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0112488s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1660
Cache Hits: 0
Skipped backups: 29796
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 3720

Root Node: 
-5.12125 (in 504 real visits)

Q-Value Estimates: 
noop() : -5.12125 (in 465 real visits)
move-west : -15.25 (in 12 real visits)
move-north : SOLVED with: -38 (in 3 real visits)
move-east : -12.975 (in 24 real visits)

Used RAM: 313812

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 3/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 0.963604297224709s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0104439s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1607
Cache Hits: 0
Skipped backups: 32134
Initialization: 
  Statistics of IDS:
  Average search depth: 3.27451 (in 51 runs)
  Maximal search depth: 40
  Cache hits: 4000

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -11.5 (in 10 real visits)
move-west : -14.5708 (in 10 real visits)
move-north : -3 (in 474 real visits)
move-east : -10.4667 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 3/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 0 

Setting time for this decision to 0.964454301075269s.
DP-UCT: Maximal search depth set to 36

Search time: 0.00918102s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1556
Cache Hits: 0
Skipped backups: 34564
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4272

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -4.575 (in 10 real visits)
move-west : -13.8875 (in 10 real visits)
move-south : -12.8958 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -12.2 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 3/30
Current state: 0 0 0 0 0 0 0 1 0 0 0 | 0 

Setting time for this decision to 0.965306726457399s.
DP-UCT: Maximal search depth set to 35

Search time: 0.00923085s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1582
Cache Hits: 0
Skipped backups: 36768
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 294 real visits)
move-west : -3 (in 201 real visits)
move-south : -10.25 (in 6 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 3/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.96616157989228s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 34
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 3/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.967026055705301s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 33
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 3/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.967892985611511s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 32
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 3/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.968760576057606s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 31
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 3/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.96962972972973s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 30
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 3/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.970500450856628s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 29
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 3/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.97137274368231s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 28
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 3/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.972248419150858s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 27
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 3/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.973124773960217s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 26
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 3/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.974003619909502s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 25
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 3/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.974884057971014s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 24
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 3/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.975765185856754s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 23
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 3/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.976648820326679s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 22
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 3/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.977533151680291s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 21
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 3/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.97842s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 20
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 3/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.979307552320291s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 19
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 3/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.980197632058288s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 18
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 3/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.981088422971741s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 17
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 3/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.981981751824818s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 16
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 3/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.982876712328767s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 15
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 3/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.98377239488117s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 14
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 3/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.984670631290027s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 13
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 3/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.985569597069597s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 12
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 3/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.986471127406049s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 11
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 3/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.987373394495413s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 10
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 3/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.9882782369146s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 9
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 3/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.989184742647059s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 8
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 3/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.990091996320147s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 7
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 3/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.991001841620626s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 6
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 3/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.9919133640553s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 5
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 3/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.992825645756457s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 4
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 3/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.9937405355494s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 3
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 3/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 0.994657116451017s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 2
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 3/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 0.995575393154487s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4547

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 1500
Accumulated number of search nodes in root state: 4982

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 3 -- REWARD RECEIVED: -6
***********************************************

***********************************************
>>> STARTING ROUND 4 -- REMAINING TIME 1079s
***********************************************
***********************************************
Planning step 1/40 in round 4/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 0.996494444444444s.
DP-UCT: Maximal search depth set to 40

Search time: 0.013772s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1636
Cache Hits: 0
Skipped backups: 39042
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 4843

Root Node: 
-5.2765 (in 503 real visits)

Q-Value Estimates: 
noop() : -15.865 (in 18 real visits)
move-west : -5.2765 (in 443 real visits)
move-north : -13.4 (in 42 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 4/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 1 

Setting time for this decision to 0.997366079703429s.
DP-UCT: Maximal search depth set to 39

Search time: 0.00960898s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1675
Cache Hits: 0
Skipped backups: 41328
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 5144

Root Node: 
-5.218 (in 504 real visits)

Q-Value Estimates: 
noop() : -5.218 (in 468 real visits)
move-west : -15.6913 (in 14 real visits)
move-north : SOLVED with: -39 (in 3 real visits)
move-east : -14.653 (in 19 real visits)

Used RAM: 313812

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 4/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 | 1 

Setting time for this decision to 0.998280148423005s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0105119s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1646
Cache Hits: 0
Skipped backups: 43670
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 5442

Root Node: 
-4.78622 (in 504 real visits)

Q-Value Estimates: 
noop() : -4.78622 (in 466 real visits)
move-west : -15.0917 (in 19 real visits)
move-north : SOLVED with: -38 (in 3 real visits)
move-east : -15.7287 (in 16 real visits)

Used RAM: 313812

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 4/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 0.99919591457753s.
DP-UCT: Maximal search depth set to 37

Search time: 0.00883889s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1573
Cache Hits: 0
Skipped backups: 45986
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 5719

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.2667 (in 10 real visits)
move-west : -14.5708 (in 10 real visits)
move-north : -3 (in 474 real visits)
move-east : -13.2583 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 4/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 0 

Setting time for this decision to 1.00011338289963s.
DP-UCT: Maximal search depth set to 36

Search time: 0.00835419s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1617
Cache Hits: 0
Skipped backups: 48218
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6003

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -7.475 (in 10 real visits)
move-west : -12.1125 (in 10 real visits)
move-south : -9.075 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -12.2 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 4/30
Current state: 0 0 0 0 0 0 0 1 0 0 0 | 1 

Setting time for this decision to 1.00103441860465s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0080812s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1511
Cache Hits: 0
Skipped backups: 50672
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 488 real visits)
move-west : -5.8 (in 10 real visits)
move-south : SOLVED with: -35 (in 3 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 4/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.00195530726257s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 34
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 4/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.0028863000932s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 33
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 4/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.00381809701493s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 32
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 4/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.00475163398693s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 31
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 4/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.00568691588785s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 30
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 4/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.0066230121609s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 29
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 4/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.00756179775281s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 28
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 4/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.00850234301781s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 27
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 4/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.00944465290807s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 26
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 4/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.01038873239437s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 25
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 4/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.01133458646617s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 24
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 4/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.01228127939793s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 23
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 4/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.01323069679849s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 22
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 4/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.01418190386428s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 21
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 4/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.01513490566038s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 20
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 4/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.01608876298395s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 19
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 4/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.01704536862004s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 18
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 4/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.01800378429518s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 17
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 4/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.01896590909091s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 16
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 4/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.01992890995261s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 15
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 4/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.02089468690702s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 14
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 4/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.02186229819563s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 13
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 4/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.02283174904943s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 12
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 4/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.02380209324453s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 11
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 4/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.02477523809524s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 10
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 4/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.02575023832221s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 9
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 4/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.02672709923664s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 8
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 4/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.02770582617001s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 7
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 4/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.02868642447419s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 6
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 4/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.02966794258373s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 5
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 4/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.03065229885057s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 4
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 4/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.03163854266539s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 3
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 4/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.03262476007678s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 2
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 4/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.03361287223823s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6263

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 2000
Accumulated number of search nodes in root state: 6618

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 4 -- REWARD RECEIVED: -6
***********************************************

***********************************************
>>> STARTING ROUND 5 -- REMAINING TIME 1078s
***********************************************
***********************************************
Planning step 1/40 in round 5/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 1.03460288461538s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0119469s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1681
Cache Hits: 0
Skipped backups: 52884
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6569

Root Node: 
-5.29945 (in 503 real visits)

Q-Value Estimates: 
noop() : -14.1 (in 32 real visits)
move-west : -5.29945 (in 461 real visits)
move-north : -13.4 (in 10 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 5/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 1 

Setting time for this decision to 1.03554667949952s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0105541s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1697
Cache Hits: 0
Skipped backups: 55262
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 6880

Root Node: 
-4.9426 (in 504 real visits)

Q-Value Estimates: 
noop() : -4.9426 (in 458 real visits)
move-west : -14.16 (in 20 real visits)
move-north : SOLVED with: -39 (in 3 real visits)
move-east : -13.8 (in 23 real visits)

Used RAM: 313812

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 5/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 | 1 

Setting time for this decision to 1.03653082851638s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0105841s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1613
Cache Hits: 0
Skipped backups: 57324
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 7171

Root Node: 
-4.99075 (in 504 real visits)

Q-Value Estimates: 
noop() : -4.99075 (in 469 real visits)
move-west : -14.2117 (in 21 real visits)
move-north : SOLVED with: -38 (in 3 real visits)
move-east : -17.42 (in 11 real visits)

Used RAM: 313812

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 5/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 1.03751783992285s.
DP-UCT: Maximal search depth set to 37

Search time: 0.009799s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1599
Cache Hits: 0
Skipped backups: 59812
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 7456

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.9167 (in 10 real visits)
move-west : -14.5708 (in 10 real visits)
move-north : -3 (in 474 real visits)
move-east : -12.465 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 5/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 0 

Setting time for this decision to 1.03850579150579s.
DP-UCT: Maximal search depth set to 36

Search time: 0.00895619s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1568
Cache Hits: 0
Skipped backups: 62060
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 7733

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -5.9 (in 10 real visits)
move-west : -12.7083 (in 10 real visits)
move-south : -13.3333 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -12.2 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 5/30
Current state: 0 0 0 0 0 0 0 1 0 0 0 | 0 

Setting time for this decision to 1.03949758454106s.
DP-UCT: Maximal search depth set to 35

Search time: 0.00813794s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1553
Cache Hits: 0
Skipped backups: 64352
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 481 real visits)
move-west : -6.045 (in 10 real visits)
move-south : -6.6975 (in 10 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.04049226305609s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 34
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.04149661181026s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 33
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.04250387596899s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 32
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.04351309408341s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 31
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 5/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.04452330097087s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 30
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 5/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.04553644314869s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 29
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.04655155642023s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 28
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.04756864654333s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 27
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 5/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.04858771929825s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 26
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 5/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.0496087804878s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 25
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 5/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.0506318359375s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 24
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 5/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.05165591397849s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 23
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 5/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.05268297455969s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 22
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.05371204701273s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 21
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.05474215686275s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 20
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.05577526987242s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 19
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.05681041257367s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 18
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 5/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.05784759095379s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 17
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 5/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.05888582677165s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 16
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.05992709359606s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 15
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.06096942800789s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 14
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.06201480750247s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 13
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.06306225296443s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 12
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.06411078140455s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 11
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 5/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.06516237623762s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 10
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 5/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.0662160555005s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 9
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 5/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.06727182539683s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 8
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 5/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.06832869910626s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 7
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.06938866799205s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 6
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.07045074626866s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 5
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.07151394422311s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 4
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.07258025922233s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 3
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.07364870259481s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 2
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.07471828171828s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8002

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 2500
Accumulated number of search nodes in root state: 8299

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 5 -- REWARD RECEIVED: -6
***********************************************

***********************************************
>>> STARTING ROUND 6 -- REMAINING TIME 1078s
***********************************************
***********************************************
Planning step 1/40 in round 6/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 1.075791s.
DP-UCT: Maximal search depth set to 40

Search time: 0.00927711s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1657
Cache Hits: 0
Skipped backups: 66600
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8301

Root Node: 
-5.31227 (in 503 real visits)

Q-Value Estimates: 
noop() : -14.1 (in 32 real visits)
move-west : -5.31227 (in 461 real visits)
move-north : -13.4 (in 10 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 6/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 1.07681881881882s.
DP-UCT: Maximal search depth set to 39

Search time: 0.00786996s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1540
Cache Hits: 0
Skipped backups: 68832
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8570

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -14.2 (in 14 real visits)
move-west : -15.36 (in 10 real visits)
move-north : -3 (in 470 real visits)
move-east : -14.89 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 6/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 0 

Setting time for this decision to 1.07788677354709s.
DP-UCT: Maximal search depth set to 38

Search time: 0.00770807s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1612
Cache Hits: 0
Skipped backups: 71280
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 8854

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -7.08 (in 10 real visits)
move-west : -7.2625 (in 10 real visits)
move-south : -14.5475 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -12.8 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 6/30
Current state: 0 0 0 0 0 0 0 1 0 0 0 | 1 

Setting time for this decision to 1.07895787362086s.
DP-UCT: Maximal search depth set to 37

Search time: 0.00688314s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1497
Cache Hits: 0
Skipped backups: 73440
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 97 real visits)
move-west : -3 (in 401 real visits)
move-south : SOLVED with: -37 (in 3 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 6/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.08003112449799s.
DP-UCT: Maximal search depth set to 36

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 36
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 6/40 in round 6/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.08111457286432s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 35
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 6/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.08220020120724s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 34
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 6/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.08328700906344s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 33
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 6/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.08437701612903s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 32
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 6/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.08546922300706s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 31
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 6/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.08656363636364s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 30
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 6/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.08766026289181s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 29
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 6/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.08875809716599s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 28
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 6/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.08985916919959s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 27
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 6/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.09096247464503s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 26
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 6/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.09206802030457s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 25
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 6/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.09317581300813s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 24
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 6/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.09428585961343s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 23
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 6/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.09539816700611s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 22
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 6/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.0965127420999s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 21
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 6/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.09762959183673s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 20
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 6/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.09874770173647s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 19
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 6/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.0998691206544s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 18
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 6/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.10099283520983s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 17
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 6/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.10211885245902s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 16
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 6/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.10324717948718s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 15
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 6/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.10437782340862s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 14
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 6/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.10551079136691s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 13
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 6/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.10664609053498s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 12
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 6/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.10778372811534s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 11
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 6/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.10892268041237s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 10
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 6/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.11006295149639s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 9
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 6/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.1112055785124s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 8
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 6/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.11235056876939s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 7
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 6/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.11349792960663s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 6
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 6/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.11464766839378s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 5
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 6/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.11580082987552s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 4
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 6/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.11695534787124s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 3
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 6/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.11811330561331s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 2
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 6/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.1192726326743s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9109

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 3000
Accumulated number of search nodes in root state: 9956

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 6 -- REWARD RECEIVED: -4
***********************************************

***********************************************
>>> STARTING ROUND 7 -- REMAINING TIME 1078s
***********************************************
***********************************************
Planning step 1/40 in round 7/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 1.12043541666667s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0133581s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1609
Cache Hits: 0
Skipped backups: 75606
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9397

Root Node: 
-5.2585 (in 503 real visits)

Q-Value Estimates: 
noop() : -14.1 (in 31 real visits)
move-west : -5.2585 (in 446 real visits)
move-north : -13.4 (in 26 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 7/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 1 

Setting time for this decision to 1.12154953076121s.
DP-UCT: Maximal search depth set to 39

Search time: 0.00946999s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1621
Cache Hits: 0
Skipped backups: 77844
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9692

Root Node: 
-5.218 (in 504 real visits)

Q-Value Estimates: 
noop() : -5.218 (in 462 real visits)
move-west : -14.3438 (in 19 real visits)
move-north : SOLVED with: -39 (in 3 real visits)
move-east : -14.29 (in 20 real visits)

Used RAM: 313812

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 7/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 1.12270668058455s.
DP-UCT: Maximal search depth set to 38

Search time: 0.00951099s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1564
Cache Hits: 0
Skipped backups: 80186
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 9968

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -7 (in 10 real visits)
move-west : -15.0067 (in 10 real visits)
move-north : -3 (in 474 real visits)
move-east : -13.65 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 7/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 0 

Setting time for this decision to 1.12386624869383s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0090301s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1575
Cache Hits: 0
Skipped backups: 82386
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10242

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -8.425 (in 17 real visits)
move-west : -12.15 (in 10 real visits)
move-south : -12.855 (in 10 real visits)
move-north : -2 (in 458 real visits)
move-east : -12.5 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 7/30
Current state: 0 0 0 0 0 0 0 1 0 0 0 | 1 

Setting time for this decision to 1.12502928870293s.
DP-UCT: Maximal search depth set to 36

Search time: 0.00898004s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1570
Cache Hits: 0
Skipped backups: 85104
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -4.325 (in 10 real visits)
move-west : -3 (in 488 real visits)
move-south : SOLVED with: -36 (in 3 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 7/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.12619371727749s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 35
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 7/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.12737106918239s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 34
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 7/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.12855089192025s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 33
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 7/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.12973214285714s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 32
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 7/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.13091692954784s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 31
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 7/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.13210315789474s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 30
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 7/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.13329293993678s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 29
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 7/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.13448417721519s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 28
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 7/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.13567793030623s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 27
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 7/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.13687526427061s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 26
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 7/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.13807407407407s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 25
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 7/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.13927648305085s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 24
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 7/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.14048038176034s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 23
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 7/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.14168683651805s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 22
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 7/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.14289691817216s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 21
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 7/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.1441085106383s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 20
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 7/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.14532268370607s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 19
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 7/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.146539445629s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 18
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 7/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.14775880469584s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 17
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 7/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.14898076923077s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 16
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 7/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.15020534759358s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 15
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 7/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.15143361884368s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 14
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 7/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.15266345123258s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 13
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 7/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.15389592274678s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 12
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 7/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.15513104189044s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 11
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 7/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.1563688172043s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 10
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 7/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.15760925726588s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 9
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 7/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.15885237068966s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 8
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 7/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.16009924487594s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 7
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 7/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.16134773218143s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 6
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 7/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.1626s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 5
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 7/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.1638538961039s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 4
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 7/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.1651105092091s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 3
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 7/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.16637093275488s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 2
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 7/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.16763300760043s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10519

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 3500
Accumulated number of search nodes in root state: 11565

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 7 -- REWARD RECEIVED: -5
***********************************************

***********************************************
>>> STARTING ROUND 8 -- REMAINING TIME 1078s
***********************************************
***********************************************
Planning step 1/40 in round 8/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 1.16889782608696s.
DP-UCT: Maximal search depth set to 40

Search time: 0.015626s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1648
Cache Hits: 0
Skipped backups: 87392
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 10817

Root Node: 
-5.29 (in 503 real visits)

Q-Value Estimates: 
noop() : -15.885 (in 16 real visits)
move-west : -5.29 (in 477 real visits)
move-north : -13.4 (in 10 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 8/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 1.1701077257889s.
DP-UCT: Maximal search depth set to 39

Search time: 0.00769496s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1599
Cache Hits: 0
Skipped backups: 89768
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11100

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -14.3333 (in 10 real visits)
move-west : -15.2625 (in 10 real visits)
move-north : -3 (in 474 real visits)
move-east : -15.2525 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 8/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 0 

Setting time for this decision to 1.17137037037037s.
DP-UCT: Maximal search depth set to 38

Search time: 0.00944996s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1619
Cache Hits: 0
Skipped backups: 92268
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11390

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -7.08 (in 10 real visits)
move-west : -12.8525 (in 10 real visits)
move-south : -12.425 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -12.8 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 8/30
Current state: 0 0 0 0 0 0 0 1 0 0 0 | 0 

Setting time for this decision to 1.17263358778626s.
DP-UCT: Maximal search depth set to 37

Search time: 0.00873303s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1562
Cache Hits: 0
Skipped backups: 94778
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -4.4 (in 10 real visits)
move-west : -3 (in 481 real visits)
move-south : -5.325 (in 10 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 8/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.17390065502183s.
DP-UCT: Maximal search depth set to 36

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 36
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 6/40 in round 8/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.17518032786885s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 35
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 8/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.17646280087527s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 34
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 8/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.17774808324206s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 33
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 8/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.1790350877193s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 32
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 8/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.18032601536773s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 31
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 8/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.18161868131868s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 30
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 8/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.18291529152915s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 29
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 8/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.18421475770925s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 28
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 8/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.18551598676957s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 27
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 8/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.18682119205298s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 26
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 8/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.18812817679558s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 25
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 8/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.18943915929204s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 24
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 8/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.1907519379845s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 23
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 8/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.19206762749446s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 22
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 8/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.19338734739179s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 21
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 8/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.19471s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 20
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 8/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.19603448275862s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 19
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 8/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.19736302895323s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 18
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 8/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.19869342251951s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 17
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 8/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.20002790178571s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 16
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 8/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.20136424581006s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 15
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 8/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.20270357941834s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 14
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 8/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.20404591265398s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 13
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 8/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.20539125560538s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 12
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 8/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.20674074074074s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 11
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 8/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.20809213483146s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 10
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 8/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.20944769403825s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 9
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 8/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.21080518018018s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 8
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 8/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.21216572717024s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 7
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 8/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.21352934537246s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 6
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 8/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.21489830508475s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 5
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 8/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.21626809954751s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 4
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 8/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.21764099660249s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 3
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 8/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.21901247165533s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 2
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 8/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.22039160045403s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11659

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 4000
Accumulated number of search nodes in root state: 13213

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 8 -- REWARD RECEIVED: -4
***********************************************

***********************************************
>>> STARTING ROUND 9 -- REMAINING TIME 1078s
***********************************************
***********************************************
Planning step 1/40 in round 9/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 1.22177386363636s.
DP-UCT: Maximal search depth set to 40

Search time: 0.01178s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1656
Cache Hits: 0
Skipped backups: 97078
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 11958

Root Node: 
-5.50195 (in 503 real visits)

Q-Value Estimates: 
noop() : -15.605 (in 11 real visits)
move-west : -5.50195 (in 474 real visits)
move-north : -13.4 (in 18 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 9/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 1.22310466439135s.
DP-UCT: Maximal search depth set to 39

Search time: 0.00891304s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1650
Cache Hits: 0
Skipped backups: 99606
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12248

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -14.3333 (in 10 real visits)
move-west : -15.2625 (in 10 real visits)
move-north : -3 (in 474 real visits)
move-east : -6.8625 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 9/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 0 

Setting time for this decision to 1.22448291571754s.
DP-UCT: Maximal search depth set to 38

Search time: 0.00934291s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1620
Cache Hits: 0
Skipped backups: 102168
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12538

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -6.1 (in 10 real visits)
move-west : -6.325 (in 10 real visits)
move-south : -14.2625 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -12.8 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 9/30
Current state: 0 0 0 0 0 0 0 1 0 0 0 | 1 

Setting time for this decision to 1.22586545039909s.
DP-UCT: Maximal search depth set to 37

Search time: 0.00869203s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1544
Cache Hits: 0
Skipped backups: 104744
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 488 real visits)
move-west : -5.325 (in 10 real visits)
move-south : SOLVED with: -37 (in 3 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 9/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.22725114155251s.
DP-UCT: Maximal search depth set to 36

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 36
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 6/40 in round 9/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.22865028571429s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 35
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 9/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.23005148741419s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 34
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 9/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.23145704467354s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 33
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 9/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.23286582568807s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 32
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 9/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.23427784156142s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 31
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 9/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.23569195402299s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 30
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 9/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.23711047180667s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 29
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 9/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.23853110599078s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 28
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 9/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.23995617070358s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 27
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 9/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.24138452655889s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 26
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 9/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.2428161849711s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 25
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 9/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.24425115740741s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 24
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 9/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.24568945538818s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 23
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 9/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.24713109048724s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 22
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 9/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.24857607433217s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 21
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 9/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.25002441860465s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 20
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 9/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.2514772991851s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 19
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 9/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.25293356643357s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 18
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 9/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.25439206534422s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 17
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 9/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.25585397196262s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 16
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 9/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.25731812865497s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 15
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 9/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.2587868852459s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 14
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 9/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.26025791324736s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 13
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 9/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.26173356807512s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 12
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 9/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.26321269095182s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 11
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 9/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.26469529411765s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 10
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 9/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.26618256772674s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 9
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 9/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.26767099056604s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 8
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 9/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.26916410861865s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 7
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 9/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.27065957446809s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 6
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 9/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.27215857988166s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 5
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 9/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.27366232227488s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 4
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 9/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.2751684460261s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 3
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 9/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.27667933491686s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 2
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 9/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.27819262782402s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 12807

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 4500
Accumulated number of search nodes in root state: 14869

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 9 -- REWARD RECEIVED: -4
***********************************************

***********************************************
>>> STARTING ROUND 10 -- REMAINING TIME 1077s
***********************************************
***********************************************
Planning step 1/40 in round 10/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 1.27970952380952s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0111148s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1603
Cache Hits: 0
Skipped backups: 106870
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13090

Root Node: 
-5.29 (in 503 real visits)

Q-Value Estimates: 
noop() : -18.435 (in 11 real visits)
move-west : -5.29 (in 457 real visits)
move-north : -13.4 (in 35 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 10/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 1.28117520858164s.
DP-UCT: Maximal search depth set to 39

Search time: 0.00856209s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1645
Cache Hits: 0
Skipped backups: 109358
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13379

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -12.7 (in 10 real visits)
move-west : -15.2625 (in 10 real visits)
move-north : -3 (in 474 real visits)
move-east : -10.9333 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 10/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 0 

Setting time for this decision to 1.28268973747017s.
DP-UCT: Maximal search depth set to 38

Search time: 0.00900006s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1557
Cache Hits: 0
Skipped backups: 111672
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13651

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -5.4 (in 10 real visits)
move-west : -14 (in 10 real visits)
move-south : -14 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -12.8 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 10/30
Current state: 0 0 0 0 0 0 0 1 0 0 0 | 1 

Setting time for this decision to 1.28420788530466s.
DP-UCT: Maximal search depth set to 37

Search time: 0.00873303s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1536
Cache Hits: 0
Skipped backups: 114220
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 488 real visits)
move-west : -6 (in 10 real visits)
move-south : SOLVED with: -37 (in 3 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 10/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.28572966507177s.
DP-UCT: Maximal search depth set to 36

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 36
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 6/40 in round 10/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.28726586826347s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 35
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 10/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.28880575539568s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 34
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 10/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.2903481392557s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 33
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 10/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.29189543269231s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 32
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 10/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.29344524669073s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 31
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 10/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.29499879518072s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 30
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 10/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.29655729794934s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 29
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 10/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.29811835748792s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 28
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 10/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.29968319226118s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 27
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 10/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.30125302663438s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 26
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 10/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.30282545454545s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 25
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 10/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.30440291262136s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 24
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 10/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.3059829890644s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 23
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 10/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.30756690997567s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 22
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 10/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.30915590742996s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 21
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 10/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.31074756097561s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 20
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 10/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.31234432234432s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 19
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 10/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.31394376528117s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 18
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 10/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.31554834761322s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 17
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 10/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.3171556372549s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 16
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 10/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.31876809815951s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 15
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 10/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.32038329238329s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 14
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 10/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.3220024600246s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 13
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 10/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.32362561576355s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 12
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 10/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.32525400739827s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 11
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 10/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.32688518518519s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 10
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 10/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.328521631644s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 9
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 10/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.33016089108911s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 8
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 10/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.33180545229244s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 7
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 10/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.3334540942928s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 6
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 10/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.33510559006211s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 5
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 10/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.33676243781095s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 4
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 10/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.33842216687422s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 3
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 10/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.34008603491272s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 2
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 10/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.34175405742821s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 13916

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 5000
Accumulated number of search nodes in root state: 16472

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 10 -- REWARD RECEIVED: -4
***********************************************

***********************************************
>>> STARTING ROUND 11 -- REMAINING TIME 1077s
***********************************************
***********************************************
Planning step 1/40 in round 11/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 1.3434275s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0116949s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1610
Cache Hits: 0
Skipped backups: 116182
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 14206

Root Node: 
-5.29 (in 503 real visits)

Q-Value Estimates: 
noop() : -13.183 (in 59 real visits)
move-west : -5.29 (in 435 real visits)
move-north : -13.4 (in 9 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 11/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 1.34504255319149s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0087719s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1603
Cache Hits: 0
Skipped backups: 118648
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 14489

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -10.7433 (in 10 real visits)
move-west : -15.875 (in 10 real visits)
move-north : -3 (in 474 real visits)
move-east : -15.66 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 11/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 1 

Setting time for this decision to 1.34671428571429s.
DP-UCT: Maximal search depth set to 38

Search time: 0.00892687s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1571
Cache Hits: 0
Skipped backups: 121006
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 14761

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -38 (in 3 real visits)
move-west : -14 (in 10 real visits)
move-south : -9.425 (in 10 real visits)
move-north : -2 (in 472 real visits)
move-east : -12.8 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 11/30
Current state: 0 1 0 0 0 0 0 1 0 0 0 | 0 

Setting time for this decision to 1.34838770388959s.
DP-UCT: Maximal search depth set to 37

Search time: 0.00882411s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1578
Cache Hits: 0
Skipped backups: 123264
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 142 real visits)
move-west : -3 (in 351 real visits)
move-south : -5.325 (in 8 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 11/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.35006658291457s.
DP-UCT: Maximal search depth set to 36

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 36
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 6/40 in round 11/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.35176100628931s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 35
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 11/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.353459697733s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 34
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 11/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.35516267339218s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 33
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 11/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.35686994949495s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 32
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 11/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.35858154235145s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 31
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 11/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.36029620253165s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 30
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 11/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.36201520912548s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 29
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 11/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.3637385786802s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 28
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 11/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.36546632782719s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 27
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 11/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.36719974554707s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 26
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 11/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.36893630573248s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 25
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 11/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.37067857142857s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 24
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 11/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.37242528735632s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 23
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 11/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.37417519181586s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 22
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 11/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.37593085787452s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 21
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 11/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.37768974358974s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 20
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 11/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.37945314505777s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 19
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 11/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.38122107969152s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 18
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 11/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.38299485199485s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 17
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 11/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.3847719072165s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 16
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 11/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.38655483870968s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 15
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 11/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.38834108527132s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 14
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 11/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.39013324708926s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 13
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 11/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.39192875647668s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 12
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 11/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.39373022049287s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 11
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 11/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.39553506493506s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 10
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 11/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.39734590377113s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 9
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 11/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.39916145833333s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 8
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 11/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.40098044328553s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 7
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 11/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.40280548302872s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 6
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 11/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.40463529411765s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 5
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 11/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.40646858638743s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 4
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 11/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.40830799475754s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 3
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 11/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.41015223097113s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 2
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 11/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.41200131406045s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15037

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 5500
Accumulated number of search nodes in root state: 18082

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 11 -- REWARD RECEIVED: -4
***********************************************

***********************************************
>>> STARTING ROUND 12 -- REMAINING TIME 1077s
***********************************************
***********************************************
Planning step 1/40 in round 12/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 1.41385394736842s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0118821s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1697
Cache Hits: 0
Skipped backups: 125648
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15346

Root Node: 
-5.392 (in 503 real visits)

Q-Value Estimates: 
noop() : -14.0545 (in 28 real visits)
move-west : -5.392 (in 465 real visits)
move-north : -13.4 (in 10 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 12/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 1 

Setting time for this decision to 1.41564690382082s.
DP-UCT: Maximal search depth set to 39

Search time: 0.00939798s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1622
Cache Hits: 0
Skipped backups: 127818
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15642

Root Node: 
-5.1298 (in 504 real visits)

Q-Value Estimates: 
noop() : -5.1298 (in 456 real visits)
move-west : -15 (in 17 real visits)
move-north : SOLVED with: -39 (in 3 real visits)
move-east : -13.8 (in 28 real visits)

Used RAM: 313812

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 12/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 1.41749868073879s.
DP-UCT: Maximal search depth set to 38

Search time: 0.00868082s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1573
Cache Hits: 0
Skipped backups: 130094
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 15913

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -9.425 (in 10 real visits)
move-west : -14.9167 (in 10 real visits)
move-north : -3 (in 474 real visits)
move-east : -13.45 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 12/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 1 

Setting time for this decision to 1.41935667107001s.
DP-UCT: Maximal search depth set to 37

Search time: 0.00857711s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1612
Cache Hits: 0
Skipped backups: 132588
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16192

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -37 (in 3 real visits)
move-west : -8.93 (in 10 real visits)
move-south : -14.8117 (in 10 real visits)
move-north : -2 (in 472 real visits)
move-east : -12.5 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 12/30
Current state: 0 1 0 0 0 0 0 1 0 0 0 | 0 

Setting time for this decision to 1.4212208994709s.
DP-UCT: Maximal search depth set to 36

Search time: 0.00808811s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1550
Cache Hits: 0
Skipped backups: 134982
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 481 real visits)
move-west : -5.25 (in 10 real visits)
move-south : -11.15 (in 10 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 12/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.42308874172185s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 35
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.42497214854111s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 34
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.42686055776892s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 33
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.4287539893617s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 32
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 12/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.43065246338216s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 31
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 12/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.43255466666667s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 30
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 12/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.43446194926569s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 29
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.4363756684492s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 28
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 12/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.43829317269076s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 27
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 12/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.44021715817694s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 26
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.44214630872483s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 25
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.44407930107527s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 24
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 12/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.44601749663526s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 23
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 12/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.44796226415094s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 22
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.44991093117409s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 21
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.45186621621622s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 20
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.45382679296346s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 19
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.45579132791328s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 18
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.45776255088195s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 17
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.45973777173913s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 16
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.46172108843537s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 15
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.46370708446867s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 14
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.46569986357435s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 13
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.46769672131148s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 12
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.46969904240766s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 11
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.47170821917808s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 10
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.47372153635117s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 9
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.47574175824176s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 8
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.47776616231087s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 7
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 12/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.47979614325069s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 6
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 12/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.48183172413793s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 5
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.48387430939227s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 4
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 12/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.48592116182573s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 3
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 12/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.48797506925208s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 2
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 12/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.4900346740638s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16461

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 6000
Accumulated number of search nodes in root state: 19779

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 12 -- REWARD RECEIVED: -5
***********************************************

***********************************************
>>> STARTING ROUND 13 -- REMAINING TIME 1077s
***********************************************
***********************************************
Planning step 1/40 in round 13/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 1.49209861111111s.
DP-UCT: Maximal search depth set to 40

Search time: 0.011817s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1696
Cache Hits: 0
Skipped backups: 137164
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 16770

Root Node: 
-6.0923 (in 503 real visits)

Q-Value Estimates: 
noop() : -14.1 (in 27 real visits)
move-west : -6.0923 (in 449 real visits)
move-north : -13.4 (in 27 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 13/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 1.49410292072323s.
DP-UCT: Maximal search depth set to 39

Search time: 0.00850797s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1609
Cache Hits: 0
Skipped backups: 139610
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17054

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -12 (in 10 real visits)
move-west : -15.6125 (in 10 real visits)
move-north : -3 (in 474 real visits)
move-east : -15.66 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 13/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 0 

Setting time for this decision to 1.49616852367688s.
DP-UCT: Maximal search depth set to 38

Search time: 0.00894713s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1568
Cache Hits: 0
Skipped backups: 141682
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17325

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -7.78 (in 10 real visits)
move-west : -12.425 (in 10 real visits)
move-south : -14 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -12.8 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 13/30
Current state: 0 0 0 0 0 0 0 1 0 0 0 | 0 

Setting time for this decision to 1.49823709902371s.
DP-UCT: Maximal search depth set to 37

Search time: 0.00871801s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1601
Cache Hits: 0
Skipped backups: 143930
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 193 real visits)
move-west : -3 (in 301 real visits)
move-south : -6 (in 7 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.50031284916201s.
DP-UCT: Maximal search depth set to 36

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 36
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 6/40 in round 13/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.50240699300699s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 35
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 13/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.50450840336134s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 34
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.50661290322581s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 33
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.50872471910112s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 32
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.51084247538678s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 31
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.51296478873239s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 30
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.51509449929478s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 29
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.51722881355932s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 28
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.51936916548798s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 27
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.52151699716714s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 26
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.5236695035461s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 25
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.52582954545455s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 24
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.52799431009957s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 23
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 13/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.53016524216524s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 22
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 13/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.53234379457917s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 21
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.53452714285714s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 20
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.53671816881259s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 19
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.53891404011461s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 18
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 13/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.54111764705882s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 17
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 13/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.54332614942529s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 16
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.54554100719424s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 15
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.54776368876081s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 14
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.54999134199134s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 13
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 13/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.55222687861272s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 12
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 13/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.55446743849493s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 11
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.55671594202899s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 10
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.55896952104499s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 9
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.56123110465116s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 8
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.56349927219796s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 7
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.56577259475219s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 6
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.56805255474453s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 5
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.57033918128655s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 4
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.57263396778917s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 3
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 13/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.57493401759531s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 2
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 13/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.5772422907489s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17604

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 6500
Accumulated number of search nodes in root state: 21475

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 13 -- REWARD RECEIVED: -4
***********************************************

***********************************************
>>> STARTING ROUND 14 -- REMAINING TIME 1077s
***********************************************
***********************************************
Planning step 1/40 in round 14/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 1.57955588235294s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0131299s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1624
Cache Hits: 0
Skipped backups: 146238
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 17900

Root Node: 
-5.2405 (in 503 real visits)

Q-Value Estimates: 
noop() : -14.5525 (in 25 real visits)
move-west : -5.2405 (in 440 real visits)
move-north : -13.4 (in 38 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 14/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 1 

Setting time for this decision to 1.58180559646539s.
DP-UCT: Maximal search depth set to 39

Search time: 0.00928998s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1636
Cache Hits: 0
Skipped backups: 148490
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 18197

Root Node: 
-5.10595 (in 504 real visits)

Q-Value Estimates: 
noop() : -5.10595 (in 481 real visits)
move-west : -15.5437 (in 10 real visits)
move-north : SOLVED with: -39 (in 3 real visits)
move-east : -10.9333 (in 10 real visits)

Used RAM: 313812

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 14/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 | 1 

Setting time for this decision to 1.5841209439528s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0110519s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1652
Cache Hits: 0
Skipped backups: 150686
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 18497

Root Node: 
-5.33725 (in 504 real visits)

Q-Value Estimates: 
noop() : -5.33725 (in 467 real visits)
move-west : -14.9167 (in 12 real visits)
move-north : SOLVED with: -38 (in 3 real visits)
move-east : -12.975 (in 22 real visits)

Used RAM: 313812

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 14/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 1.58644017725258s.
DP-UCT: Maximal search depth set to 37

Search time: 0.00946498s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1586
Cache Hits: 0
Skipped backups: 153022
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 18776

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -10.9867 (in 10 real visits)
move-west : -14.5708 (in 10 real visits)
move-north : -3 (in 472 real visits)
move-east : -10.14 (in 12 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 14/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 0 

Setting time for this decision to 1.58876775147929s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0089581s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1571
Cache Hits: 0
Skipped backups: 155366
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19047

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -8.925 (in 10 real visits)
move-west : -8.9975 (in 10 real visits)
move-south : -13.7583 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -12.2 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 14/30
Current state: 0 0 0 0 0 0 0 1 0 0 0 | 1 

Setting time for this decision to 1.5911037037037s.
DP-UCT: Maximal search depth set to 35

Search time: 0.00840092s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1535
Cache Hits: 0
Skipped backups: 157542
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 488 real visits)
move-west : -6.045 (in 10 real visits)
move-south : SOLVED with: -35 (in 3 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 14/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.59344658753709s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 34
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 14/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.59580980683507s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 33
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 14/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.59818005952381s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 32
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 14/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.60055737704918s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 31
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 14/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.60294179104478s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 30
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 14/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.60533183856502s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 29
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 14/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.60773053892216s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 28
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 14/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.61013493253373s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 27
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 14/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.61254654654655s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 26
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 14/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.61496691729323s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 25
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 14/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.61739307228916s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 24
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 14/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.61982805429864s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 23
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 14/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.62226888217523s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 22
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 14/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.62471860816944s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 21
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 14/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.62717424242424s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 20
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 14/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.6296373292868s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 19
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 14/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.63210790273556s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 18
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 14/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.63458751902588s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 17
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 14/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.63707469512195s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 16
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 14/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.6395679389313s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 15
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 14/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.64207033639144s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 14
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 14/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.64457886676876s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 13
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 14/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.64709662576687s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 12
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 14/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.64962058371736s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 11
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 14/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.65215230769231s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 10
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 14/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.65469337442219s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 9
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 14/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.65724074074074s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 8
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 14/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.65979752704791s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 7
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 14/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.66236068111455s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 6
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 14/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.66493333333333s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 5
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 14/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.66751242236025s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 4
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 14/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.67009953343701s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 3
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 14/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.67269470404984s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 2
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 14/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.67529953198128s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19309

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 7000
Accumulated number of search nodes in root state: 23099

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 14 -- REWARD RECEIVED: -6
***********************************************

***********************************************
>>> STARTING ROUND 15 -- REMAINING TIME 1076s
***********************************************
***********************************************
Planning step 1/40 in round 15/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 1.6779109375s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0162311s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1689
Cache Hits: 0
Skipped backups: 159672
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19615

Root Node: 
-6.92953 (in 503 real visits)

Q-Value Estimates: 
noop() : -6.92953 (in 453 real visits)
move-west : -13.9575 (in 28 real visits)
move-north : -13.4 (in 22 real visits)

Used RAM: 313812

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 15/30
Current state: 0 1 0 0 0 0 0 0 1 0 0 | 0 

Setting time for this decision to 1.68044913928013s.
DP-UCT: Maximal search depth set to 39

Search time: 0.00865579s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1606
Cache Hits: 0
Skipped backups: 161758
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 19903

Root Node: 
-4.9426 (in 503 real visits)

Q-Value Estimates: 
noop() : -14.16 (in 26 real visits)
move-west : -4.9426 (in 442 real visits)
move-north : -13.1 (in 35 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 15/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 1.68306426332288s.
DP-UCT: Maximal search depth set to 38

Search time: 0.00970721s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1633
Cache Hits: 0
Skipped backups: 164186
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20190

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -12.425 (in 10 real visits)
move-west : -15.5 (in 10 real visits)
move-north : -3 (in 474 real visits)
move-east : -12.75 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 15/30
Current state: 0 0 0 0 0 0 1 0 0 0 0 | 0 

Setting time for this decision to 1.68568602825746s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0091269s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1602
Cache Hits: 0
Skipped backups: 166662
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20473

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -5.325 (in 10 real visits)
move-west : -9.25 (in 10 real visits)
move-south : -13.0167 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -12.5 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 15/30
Current state: 0 0 0 0 0 0 0 1 0 0 0 | 1 

Setting time for this decision to 1.68831761006289s.
DP-UCT: Maximal search depth set to 36

Search time: 0.00843716s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1563
Cache Hits: 0
Skipped backups: 168954
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 297 real visits)
move-west : -3 (in 201 real visits)
move-south : SOLVED with: -36 (in 3 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 15/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.69095748031496s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 35
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 15/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.6936214511041s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 34
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 15/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.69629225908373s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 33
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 15/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.69897151898734s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 32
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 15/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.70165768621236s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 31
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 15/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.70435555555556s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 30
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 15/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.70706041335453s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 29
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 15/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.70977229299363s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 28
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 15/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.71249282296651s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 27
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 15/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.71522204472843s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 26
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 15/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.7179632s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 25
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 15/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.72071153846154s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 24
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 15/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.72347191011236s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 23
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 15/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.72623794212219s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 22
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 15/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.72901127214171s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 21
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 15/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.73179516129032s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 20
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 15/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.73458642972536s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 19
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 15/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.73738834951456s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 18
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 15/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.74019773095624s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 17
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 15/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.74301785714286s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 16
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 15/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.74584552845528s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 15
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 15/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.74868403908795s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 14
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 15/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.75153017944535s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 13
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 15/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.75438725490196s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 12
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 15/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.75725368248773s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 11
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 15/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.76013114754098s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 10
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 15/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.76301642036125s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 9
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 15/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.76591118421053s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 8
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 15/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.76881383855025s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 7
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 15/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.77172772277228s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 6
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 15/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.77464958677686s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 5
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 15/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.77758278145695s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 4
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 15/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.78052404643449s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 3
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 15/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.78347674418605s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 2
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 15/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.78644093178037s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 20745

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 7500
Accumulated number of search nodes in root state: 24788

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 15 -- REWARD RECEIVED: -5
***********************************************

***********************************************
>>> STARTING ROUND 16 -- REMAINING TIME 1076s
***********************************************
***********************************************
Planning step 1/40 in round 16/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 1.78941333333333s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0155909s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1618
Cache Hits: 0
Skipped backups: 171194
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21034

Root Node: 
-5.245 (in 503 real visits)

Q-Value Estimates: 
noop() : -14.1 (in 18 real visits)
move-west : -5.245 (in 466 real visits)
move-north : -13.4 (in 19 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 16/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 1.79230383973289s.
DP-UCT: Maximal search depth set to 39

Search time: 0.00792885s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1619
Cache Hits: 0
Skipped backups: 173566
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21316

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -14.3333 (in 10 real visits)
move-west : -15.2625 (in 10 real visits)
move-north : -3 (in 474 real visits)
move-east : -13.96 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 16/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 0 

Setting time for this decision to 1.79528428093645s.
DP-UCT: Maximal search depth set to 38

Search time: 0.00911784s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1601
Cache Hits: 0
Skipped backups: 176016
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21595

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -5.4 (in 10 real visits)
move-west : -9.425 (in 10 real visits)
move-south : -14.45 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -12.8 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 16/30
Current state: 0 0 0 0 0 0 0 1 0 0 0 | 1 

Setting time for this decision to 1.79826968174204s.
DP-UCT: Maximal search depth set to 37

Search time: 0.00841403s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1544
Cache Hits: 0
Skipped backups: 178234
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 297 real visits)
move-west : -3 (in 201 real visits)
move-south : SOLVED with: -37 (in 3 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 16/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.80126845637584s.
DP-UCT: Maximal search depth set to 36

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 36
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 6/40 in round 16/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.80429075630252s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 35
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 16/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.80732323232323s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 34
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 16/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.81036593591906s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 33
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 16/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.81341891891892s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 32
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 16/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.81648223350254s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 31
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 16/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.81955593220339s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 30
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 16/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.82264006791171s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 29
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 16/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.82573469387755s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 28
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 16/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.82884156729131s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 27
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 16/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.8319590443686s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 26
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 16/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.83508547008547s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 25
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 16/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.83822431506849s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 24
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 16/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.8413704974271s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 23
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 16/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.84452920962199s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 22
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 16/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.84769879518072s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 21
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 16/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.8508775862069s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 20
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 16/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.85406908462867s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 19
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 16/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.85727162629758s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 18
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 16/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.8604835355286s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 17
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 16/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.86370833333333s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 16
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 16/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.86694260869565s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 15
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 16/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.87018989547038s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 14
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 16/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.87344677137871s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 13
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 16/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.87671678321678s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 12
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 16/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.87999649737303s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 11
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 16/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.88328947368421s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 10
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 16/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.88659226713533s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 9
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 16/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.88990845070423s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 8
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 16/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.89323456790123s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 7
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 16/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.896574204947s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 6
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 16/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.89992389380531s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 5
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 16/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.90328723404255s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 4
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 16/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.90666252220249s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 3
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 16/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.91004804270463s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 2
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 16/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.91344563279857s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 21864

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 8000
Accumulated number of search nodes in root state: 26406

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 16 -- REWARD RECEIVED: -4
***********************************************

***********************************************
>>> STARTING ROUND 17 -- REMAINING TIME 1076s
***********************************************
***********************************************
Planning step 1/40 in round 17/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 1.91685714285714s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0138831s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1667
Cache Hits: 0
Skipped backups: 180606
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 22167

Root Node: 
-5.425 (in 503 real visits)

Q-Value Estimates: 
noop() : -14.27 (in 14 real visits)
move-west : -5.425 (in 479 real visits)
move-north : -13.4 (in 10 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 17/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 1 

Setting time for this decision to 1.92018604651163s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0104451s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1682
Cache Hits: 0
Skipped backups: 182734
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 22478

Root Node: 
-5.2825 (in 504 real visits)

Q-Value Estimates: 
noop() : -5.2825 (in 463 real visits)
move-west : -13.8975 (in 21 real visits)
move-north : SOLVED with: -39 (in 3 real visits)
move-east : -14.64 (in 17 real visits)

Used RAM: 313812

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 17/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 1.92360394265233s.
DP-UCT: Maximal search depth set to 38

Search time: 0.009444s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1624
Cache Hits: 0
Skipped backups: 185120
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 22762

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.79 (in 10 real visits)
move-west : -14.9167 (in 10 real visits)
move-north : -3 (in 473 real visits)
move-east : -12.75 (in 11 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 17/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 1 

Setting time for this decision to 1.92703411131059s.
DP-UCT: Maximal search depth set to 37

Search time: 0.00876498s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1550
Cache Hits: 0
Skipped backups: 187476
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23030

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -37 (in 3 real visits)
move-west : -11.955 (in 10 real visits)
move-south : -6.9 (in 10 real visits)
move-north : -2 (in 472 real visits)
move-east : -12.5 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 17/30
Current state: 0 1 0 0 0 0 0 1 0 0 0 | 0 

Setting time for this decision to 1.93047841726619s.
DP-UCT: Maximal search depth set to 36

Search time: 0.00866413s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1539
Cache Hits: 0
Skipped backups: 189736
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 481 real visits)
move-west : -5.25 (in 10 real visits)
move-south : -6.825 (in 10 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 17/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.93393693693694s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 35
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 17/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.93742238267148s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 34
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 17/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.94092043399638s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 33
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 17/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.94443115942029s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 32
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 17/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.94795462794918s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 31
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 17/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.95149090909091s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 30
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 17/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.95504189435337s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 29
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 17/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.95860401459854s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 28
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 17/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.9621773308958s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 27
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 17/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.96576556776557s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 26
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 17/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.96936513761468s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 25
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 17/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.97298345588235s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 24
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 17/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.97661141804788s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 23
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 17/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.98025276752768s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 22
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 17/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.98390757855823s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 21
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 17/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.98757407407407s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 20
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 17/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 1.9912560296846s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 19
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 17/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.99494981412639s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 18
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 17/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1.99865921787709s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 17
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 17/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.00238246268657s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 16
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 17/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.00611775700935s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 15
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 17/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.00986891385768s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 14
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 17/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.01363227016886s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 13
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 17/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.01741165413534s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 12
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 17/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.02120338983051s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 11
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 17/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.02501132075472s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 10
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 17/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.02883364839319s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 9
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 17/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.03266856060606s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 8
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 17/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.03651992409867s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 7
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 17/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.04038403041825s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 6
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 17/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.04426476190476s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 5
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 17/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.04815839694656s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 4
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 17/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.05206883365201s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 3
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 17/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.05599425287356s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 2
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 17/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.05993474088292s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23301

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 8500
Accumulated number of search nodes in root state: 28073

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 17 -- REWARD RECEIVED: -5
***********************************************

***********************************************
>>> STARTING ROUND 18 -- REMAINING TIME 1076s
***********************************************
***********************************************
Planning step 1/40 in round 18/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 2.06389230769231s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0155408s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1618
Cache Hits: 0
Skipped backups: 191966
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23588

Root Node: 
-4.81187 (in 503 real visits)

Q-Value Estimates: 
noop() : -13.32 (in 15 real visits)
move-west : -4.81187 (in 473 real visits)
move-north : -13.4 (in 15 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 18/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 2.06776493256262s.
DP-UCT: Maximal search depth set to 39

Search time: 0.00790501s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1629
Cache Hits: 0
Skipped backups: 194428
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 23878

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.19 (in 10 real visits)
move-west : -15.875 (in 10 real visits)
move-north : -3 (in 474 real visits)
move-east : -12.265 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 18/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 0 

Setting time for this decision to 2.07173745173745s.
DP-UCT: Maximal search depth set to 38

Search time: 0.00844407s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1566
Cache Hits: 0
Skipped backups: 196898
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24153

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -9.32 (in 10 real visits)
move-west : -14.2625 (in 10 real visits)
move-south : -12.425 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -12.8 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 18/30
Current state: 0 0 0 0 0 0 0 1 0 0 0 | 0 

Setting time for this decision to 2.07572340425532s.
DP-UCT: Maximal search depth set to 37

Search time: 0.00882721s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1578
Cache Hits: 0
Skipped backups: 199438
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 481 real visits)
move-west : -5.325 (in 10 real visits)
move-south : -6.9525 (in 10 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 18/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.07972286821705s.
DP-UCT: Maximal search depth set to 36

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 36
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 6/40 in round 18/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.08375533980583s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 35
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 18/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.08780350194553s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 34
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 18/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.09186744639376s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 33
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 18/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.095947265625s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 32
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 18/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.10004109589041s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 31
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 18/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.10415294117647s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 30
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 18/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.108278978389s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 29
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 18/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.11242322834646s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 28
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 18/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.11658185404339s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 27
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 18/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.12075691699605s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 26
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 18/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.1249504950495s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 25
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 18/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.12915873015873s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 24
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 18/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.13338369781312s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 23
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 18/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.13762749003984s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 22
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 18/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.14188622754491s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 21
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 18/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.146162s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 20
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 18/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.15045691382766s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 19
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 18/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.15476907630522s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 18
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 18/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.15909657947686s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 17
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 18/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.1634435483871s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 16
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 18/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.16780606060606s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 15
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 18/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.17218825910931s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 14
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 18/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.17658823529412s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 13
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 18/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.18100406504065s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 12
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 18/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.1854399185336s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 11
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 18/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.18989387755102s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 10
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 18/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.19436400817996s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 9
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 18/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.19885450819672s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 8
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 18/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.20336344969199s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 7
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 18/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.20789094650206s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 6
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 18/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.21243711340206s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 5
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 18/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.217s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 4
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 18/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.22158592132505s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 3
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 18/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.2261867219917s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 2
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 18/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.23080665280665s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24428

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 9000
Accumulated number of search nodes in root state: 29691

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 18 -- REWARD RECEIVED: -4
***********************************************

***********************************************
>>> STARTING ROUND 19 -- REMAINING TIME 1076s
***********************************************
***********************************************
Planning step 1/40 in round 19/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 2.23544791666667s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0116761s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1649
Cache Hits: 0
Skipped backups: 201744
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 24725

Root Node: 
-5.24747 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.02 (in 12 real visits)
move-west : -5.24747 (in 466 real visits)
move-north : -13.4 (in 25 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 19/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 2.24s.
DP-UCT: Maximal search depth set to 39

Search time: 0.00896096s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1622
Cache Hits: 0
Skipped backups: 204174
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25013

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -14.6083 (in 10 real visits)
move-west : -15 (in 10 real visits)
move-north : -3 (in 474 real visits)
move-east : -12.5 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 19/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 0 

Setting time for this decision to 2.24466317991632s.
DP-UCT: Maximal search depth set to 38

Search time: 0.00911212s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1581
Cache Hits: 0
Skipped backups: 206622
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25292

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -10.02 (in 10 real visits)
move-west : -12.425 (in 10 real visits)
move-south : -9.3625 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -12.8 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 19/30
Current state: 0 0 0 0 0 0 0 1 0 0 0 | 0 

Setting time for this decision to 2.24934171907757s.
DP-UCT: Maximal search depth set to 37

Search time: 0.00857902s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1540
Cache Hits: 0
Skipped backups: 208850
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 481 real visits)
move-west : -5.325 (in 10 real visits)
move-south : -8.425 (in 10 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 19/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.25404411764706s.
DP-UCT: Maximal search depth set to 36

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 36
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 6/40 in round 19/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.25878315789474s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 35
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 19/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.26354430379747s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 34
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 19/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.26832346723044s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 33
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 19/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.273125s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 32
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 19/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.27794692144374s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 31
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 19/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.28278936170213s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 30
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 19/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.28765031982942s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 29
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 19/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.29253418803419s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 28
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 19/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.29743897216274s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 27
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 19/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.30236051502146s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 26
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 19/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.30730537634409s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 25
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 19/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.31226939655172s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 24
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 19/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.31725701943845s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 23
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 19/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.32226623376623s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 22
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 19/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.32729501084599s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 21
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 19/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.33234782608696s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 20
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 19/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.33742265795207s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 19
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 19/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.34251746724891s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 18
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 19/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.34763676148796s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 17
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 19/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.35277850877193s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 16
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 19/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.35794285714286s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 15
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 19/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.36312995594714s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 14
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 19/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.36833774834437s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 13
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 19/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.3735685840708s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 12
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 19/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.37882483370288s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 11
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 19/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.38410222222222s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 10
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 19/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.38940534521158s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 9
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 19/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.39472991071429s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 8
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 19/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.40008053691275s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 7
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 19/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.40545291479821s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 6
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 19/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.41085168539326s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 5
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 19/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.41627252252252s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 4
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 19/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.42172009029345s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 3
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 19/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.42719230769231s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 2
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 19/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.43268934240363s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25559

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 9500
Accumulated number of search nodes in root state: 31340

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 19 -- REWARD RECEIVED: -4
***********************************************

***********************************************
>>> STARTING ROUND 20 -- REMAINING TIME 1075s
***********************************************
***********************************************
Planning step 1/40 in round 20/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 2.43821136363636s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0161219s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1663
Cache Hits: 0
Skipped backups: 211158
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 25861

Root Node: 
-5.4412 (in 503 real visits)

Q-Value Estimates: 
noop() : -15.885 (in 13 real visits)
move-west : -5.4412 (in 480 real visits)
move-north : -13.4 (in 10 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 20/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 2.44363781321185s.
DP-UCT: Maximal search depth set to 39

Search time: 0.00796795s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1622
Cache Hits: 0
Skipped backups: 213632
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26149

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -11.2333 (in 10 real visits)
move-west : -15.2625 (in 10 real visits)
move-north : -3 (in 474 real visits)
move-east : -16.0333 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 20/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 0 

Setting time for this decision to 2.44919178082192s.
DP-UCT: Maximal search depth set to 38

Search time: 0.00878501s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1551
Cache Hits: 0
Skipped backups: 215754
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26417

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -7.78 (in 10 real visits)
move-west : -12.425 (in 10 real visits)
move-south : -12.6875 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -12.8 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 20/30
Current state: 0 0 0 0 0 0 0 1 0 0 0 | 0 

Setting time for this decision to 2.45476887871854s.
DP-UCT: Maximal search depth set to 37

Search time: 0.00870895s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1566
Cache Hits: 0
Skipped backups: 218064
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 481 real visits)
move-west : -7.6275 (in 10 real visits)
move-south : -7.6275 (in 10 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 20/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.46037385321101s.
DP-UCT: Maximal search depth set to 36

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 36
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 6/40 in round 20/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.46602298850575s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 35
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 20/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.47169815668203s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 34
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 20/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.47739953810624s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 33
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 20/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.48312731481481s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 32
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 20/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.48887935034803s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 31
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 20/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.49466046511628s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 30
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 20/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.5004662004662s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 29
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 20/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.50629906542056s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 28
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 20/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.51216159250585s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 27
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 20/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.51804929577465s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 26
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 20/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.52396705882353s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 25
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 20/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.52991273584906s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 24
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 20/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.5358841607565s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 23
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 20/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.54188625592417s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 22
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 20/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.54791686460808s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 21
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 20/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.55397380952381s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 20
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 20/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.56006205250597s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 19
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 20/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.56617703349282s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 18
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 20/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.57232374100719s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 17
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 20/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.5785s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 16
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 20/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.58470361445783s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 15
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 20/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.59093961352657s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 14
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 20/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.59720581113801s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 13
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 20/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.6035s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 12
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 20/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.60982725060827s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 11
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 20/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.61618536585366s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 10
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 20/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.62257457212714s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 9
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 20/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.62899264705882s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 8
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 20/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.63544471744472s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 7
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 20/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.64192610837438s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 6
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 20/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.64843950617284s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 5
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 20/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.65498762376238s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 4
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 20/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.6615682382134s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 3
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 20/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.6681815920398s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 2
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 20/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.67482543640898s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26690

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 10000
Accumulated number of search nodes in root state: 33003

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 20 -- REWARD RECEIVED: -4
***********************************************

***********************************************
>>> STARTING ROUND 21 -- REMAINING TIME 1075s
***********************************************
***********************************************
Planning step 1/40 in round 21/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 2.681505s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0139949s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1659
Cache Hits: 0
Skipped backups: 220456
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 26993

Root Node: 
-5.2405 (in 503 real visits)

Q-Value Estimates: 
noop() : -14.6667 (in 10 real visits)
move-west : -5.2405 (in 483 real visits)
move-north : -13.4 (in 10 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 21/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 2.68809273182957s.
DP-UCT: Maximal search depth set to 39

Search time: 0.00844622s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1638
Cache Hits: 0
Skipped backups: 222960
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27281

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.1625 (in 10 real visits)
move-west : -15.2625 (in 10 real visits)
move-north : -3 (in 472 real visits)
move-east : -10.56 (in 12 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 21/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 0 

Setting time for this decision to 2.69481909547739s.
DP-UCT: Maximal search depth set to 38

Search time: 0.00902915s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1578
Cache Hits: 0
Skipped backups: 225280
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27553

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -8.6 (in 10 real visits)
move-west : -14 (in 10 real visits)
move-south : -8.6275 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -12.8 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 21/30
Current state: 0 0 0 0 0 0 0 1 0 0 0 | 0 

Setting time for this decision to 2.70157682619647s.
DP-UCT: Maximal search depth set to 37

Search time: 0.012861s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1569
Cache Hits: 0
Skipped backups: 227970
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 481 real visits)
move-west : -3 (in 10 real visits)
move-south : -5.325 (in 10 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 21/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.70834090909091s.
DP-UCT: Maximal search depth set to 36

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 36
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 6/40 in round 21/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.71519240506329s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 35
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 21/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.72207614213198s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 34
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 21/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.72899491094148s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 33
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 21/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.73594897959184s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 32
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 21/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.74293861892583s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 31
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 21/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.74996153846154s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 30
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 21/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.7570205655527s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 29
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 21/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.76411855670103s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 28
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 21/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.77125322997416s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 27
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 21/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.77842227979275s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 26
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 21/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.78563116883117s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 25
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 21/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.792875s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 24
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 21/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.8001592689295s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 23
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 21/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.80747905759162s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 22
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 21/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.81483989501312s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 21
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 21/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.82223947368421s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 20
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 21/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.82967810026385s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 19
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 21/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.83715343915344s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 18
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 21/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.84467108753316s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 17
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 21/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.85222606382979s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 16
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 21/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.859824s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 15
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 21/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.86745989304813s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 14
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 21/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.87513941018767s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 13
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 21/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.88286021505376s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 12
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 21/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.89062264150943s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 11
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 21/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.89842432432432s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 10
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 21/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.90627100271003s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 9
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 21/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.91415760869565s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 8
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 21/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.92208719346049s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 7
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 21/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.93006284153005s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 6
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 21/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.93807945205479s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 5
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 21/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.94614285714286s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 4
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 21/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 2.9542479338843s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 3
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 21/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.96240055248619s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 2
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 21/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 2.97059833795014s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 27830

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 10500
Accumulated number of search nodes in root state: 34662

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 21 -- REWARD RECEIVED: -4
***********************************************

***********************************************
>>> STARTING ROUND 22 -- REMAINING TIME 1075s
***********************************************
***********************************************
Planning step 1/40 in round 22/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 2.97883888888889s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0119381s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1678
Cache Hits: 0
Skipped backups: 229940
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 28135

Root Node: 
-4.6672 (in 503 real visits)

Q-Value Estimates: 
noop() : -14.5525 (in 37 real visits)
move-west : -4.6672 (in 409 real visits)
move-north : -13.4 (in 57 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 22/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 1 

Setting time for this decision to 2.98698885793872s.
DP-UCT: Maximal search depth set to 39

Search time: 0.00983405s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1649
Cache Hits: 0
Skipped backups: 231934
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 28436

Root Node: 
-5.74376 (in 504 real visits)

Q-Value Estimates: 
noop() : -5.74376 (in 448 real visits)
move-west : -14.9318 (in 18 real visits)
move-north : SOLVED with: -39 (in 3 real visits)
move-east : -13.065 (in 35 real visits)

Used RAM: 313812

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 22/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 | 1 

Setting time for this decision to 2.99529888268156s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0103669s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1655
Cache Hits: 0
Skipped backups: 234150
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 28738

Root Node: 
-5.52137 (in 504 real visits)

Q-Value Estimates: 
noop() : -5.52137 (in 474 real visits)
move-west : -15.0067 (in 10 real visits)
move-north : SOLVED with: -38 (in 3 real visits)
move-east : -14.5062 (in 17 real visits)

Used RAM: 313812

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 22/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 | 1 

Setting time for this decision to 3.00365266106443s.
DP-UCT: Maximal search depth set to 37

Search time: 0.010525s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1678
Cache Hits: 0
Skipped backups: 236474
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 29047

Root Node: 
-4.9048 (in 504 real visits)

Q-Value Estimates: 
noop() : -4.9048 (in 461 real visits)
move-west : -14.4996 (in 16 real visits)
move-north : SOLVED with: -37 (in 3 real visits)
move-east : -13.2 (in 24 real visits)

Used RAM: 313812

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 22/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 | 1 

Setting time for this decision to 3.01205617977528s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0103219s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1684
Cache Hits: 0
Skipped backups: 238594
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 29353

Root Node: 
-4.84088 (in 504 real visits)

Q-Value Estimates: 
noop() : -4.84088 (in 431 real visits)
move-west : -15.3097 (in 12 real visits)
move-north : SOLVED with: -36 (in 3 real visits)
move-east : -11.374 (in 58 real visits)

Used RAM: 313812

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 22/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 | 1 

Setting time for this decision to 3.02050704225352s.
DP-UCT: Maximal search depth set to 35

Search time: 0.010457s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1675
Cache Hits: 0
Skipped backups: 240574
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 29656

Root Node: 
-5.14 (in 504 real visits)

Q-Value Estimates: 
noop() : -5.14 (in 451 real visits)
move-west : -12.94 (in 21 real visits)
move-north : SOLVED with: -35 (in 3 real visits)
move-east : -12.6 (in 29 real visits)

Used RAM: 313812

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 22/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 | 1 

Setting time for this decision to 3.02900282485876s.
DP-UCT: Maximal search depth set to 34

Search time: 0.01105s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1654
Cache Hits: 0
Skipped backups: 242580
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 29956

Root Node: 
-5.06275 (in 504 real visits)

Q-Value Estimates: 
noop() : -5.06275 (in 466 real visits)
move-west : -14.4742 (in 13 real visits)
move-north : SOLVED with: -34 (in 3 real visits)
move-east : -12.79 (in 22 real visits)

Used RAM: 313812

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 22/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 3.03754390934844s.
DP-UCT: Maximal search depth set to 33

Search time: 0.00945401s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1601
Cache Hits: 0
Skipped backups: 244856
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30239

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -12.5333 (in 10 real visits)
move-west : -13.1875 (in 10 real visits)
move-north : -3 (in 467 real visits)
move-east : -9.3 (in 17 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 9/40 in round 22/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 0 

Setting time for this decision to 3.04613636363636s.
DP-UCT: Maximal search depth set to 32

Search time: 0.0092001s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1585
Cache Hits: 0
Skipped backups: 247250
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30517

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -5.5 (in 10 real visits)
move-west : -6.4 (in 10 real visits)
move-south : -11.1425 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -11 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 10/40 in round 22/30
Current state: 0 0 0 0 0 0 0 1 0 0 0 | 0 

Setting time for this decision to 3.05478062678063s.
DP-UCT: Maximal search depth set to 31

Search time: 0.008394s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1585
Cache Hits: 0
Skipped backups: 249476
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 338 real visits)
move-west : -6.1875 (in 7 real visits)
move-south : -3 (in 156 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 11/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.06347714285714s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 30
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 3.07224641833811s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 29
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 22/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.08106609195402s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 28
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 22/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.08993659942363s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 27
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.09885838150289s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 26
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.10783188405797s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 25
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.11685465116279s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 24
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.12593294460641s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 23
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.13506140350877s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 22
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 3.14424633431085s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 21
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 22/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.15348529411765s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 20
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 22/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.16277581120944s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 19
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.17212426035503s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 18
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.18152818991098s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 17
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.19098511904762s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 16
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.20050149253731s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 15
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.21007784431138s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 14
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.21971171171171s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 13
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.22940361445783s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 12
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.23915407854985s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 11
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.24896060606061s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 10
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 3.25882674772036s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 9
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 22/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.26875304878049s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 8
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 22/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.27874006116208s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 7
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.28878834355828s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 6
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.29889538461538s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 5
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.30906790123457s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 4
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 3.31930030959752s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 3
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 22/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.32959937888199s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 2
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 22/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.33996261682243s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 30794

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 11000
Accumulated number of search nodes in root state: 36340

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 22 -- REWARD RECEIVED: -10
***********************************************

***********************************************
>>> STARTING ROUND 23 -- REMAINING TIME 1075s
***********************************************
***********************************************
Planning step 1/40 in round 23/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 3.350390625s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0146441s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1628
Cache Hits: 0
Skipped backups: 251696
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31085

Root Node: 
-4.59925 (in 503 real visits)

Q-Value Estimates: 
noop() : -14.59 (in 23 real visits)
move-west : -4.59925 (in 446 real visits)
move-north : -13.4 (in 34 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 23/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 3.36071786833856s.
DP-UCT: Maximal search depth set to 39

Search time: 0.00952983s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1616
Cache Hits: 0
Skipped backups: 254032
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31366

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.19 (in 10 real visits)
move-west : -15.2625 (in 10 real visits)
move-north : -3 (in 464 real visits)
move-east : -10.56 (in 20 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 23/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 1 

Setting time for this decision to 3.37124842767296s.
DP-UCT: Maximal search depth set to 38

Search time: 0.00869703s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1540
Cache Hits: 0
Skipped backups: 256402
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31633

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -38 (in 3 real visits)
move-west : -12.425 (in 10 real visits)
move-south : -7 (in 10 real visits)
move-north : -2 (in 472 real visits)
move-east : -12.8 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 23/30
Current state: 0 1 0 0 0 0 0 1 0 0 0 | 1 

Setting time for this decision to 3.38184542586751s.
DP-UCT: Maximal search depth set to 37

Search time: 0.00850606s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1549
Cache Hits: 0
Skipped backups: 258670
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 197 real visits)
move-west : -3 (in 301 real visits)
move-south : SOLVED with: -37 (in 3 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 23/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.39250949367089s.
DP-UCT: Maximal search depth set to 36

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 36
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 6/40 in round 23/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.40327301587302s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 35
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 23/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 3.41410191082803s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 34
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 23/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 3.425s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 33
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 23/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.43596794871795s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 32
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 23/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 3.44700964630225s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 31
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 23/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.45811612903226s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 30
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 23/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.46929449838188s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 29
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 23/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.4805487012987s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 28
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 23/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.49187622149837s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 27
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 23/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.50327450980392s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 26
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 23/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.51475081967213s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 25
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 23/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.52630263157895s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 24
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 23/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 3.53793069306931s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 23
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 23/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.54963245033113s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 22
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 23/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.56141528239203s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 21
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 23/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.57327333333333s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 20
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 23/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.58521404682274s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 19
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 23/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 3.59723489932886s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 18
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 23/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.6093367003367s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 17
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 23/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 3.62151689189189s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 16
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 23/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 3.63378305084746s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 15
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 23/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 3.64612925170068s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 14
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 23/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.65855972696246s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 13
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 23/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 3.67107876712329s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 12
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 23/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.68368384879725s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 11
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 23/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.69637586206897s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 10
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 23/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.70915570934256s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 9
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 23/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 3.72202083333333s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 8
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 23/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.73497909407666s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 7
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 23/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.74802447552448s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 6
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 23/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 3.7611649122807s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 5
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 23/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.77439788732394s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 4
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 23/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 3.78772084805654s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 3
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 23/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.80113120567376s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 2
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 23/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.81464412811388s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 31905

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 11500
Accumulated number of search nodes in root state: 37968

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 23 -- REWARD RECEIVED: -4
***********************************************

***********************************************
>>> STARTING ROUND 24 -- REMAINING TIME 1074s
***********************************************
***********************************************
Planning step 1/40 in round 24/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 3.82825357142857s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0143201s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1734
Cache Hits: 0
Skipped backups: 260608
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 32221

Root Node: 
-4.95047 (in 503 real visits)

Q-Value Estimates: 
noop() : -15.5237 (in 30 real visits)
move-west : -4.95047 (in 394 real visits)
move-north : -13.4 (in 79 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 24/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 3.84177419354839s.
DP-UCT: Maximal search depth set to 39

Search time: 0.00815511s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1590
Cache Hits: 0
Skipped backups: 263028
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 32502

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -8.57 (in 10 real visits)
move-west : -15.875 (in 10 real visits)
move-north : -3 (in 474 real visits)
move-east : -14.4225 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 24/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 1 

Setting time for this decision to 3.85555395683453s.
DP-UCT: Maximal search depth set to 38

Search time: 0.00913s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1623
Cache Hits: 0
Skipped backups: 265512
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 32791

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -38 (in 3 real visits)
move-west : -8.6275 (in 10 real visits)
move-south : -13.5275 (in 10 real visits)
move-north : -2 (in 472 real visits)
move-east : -12.8 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 24/30
Current state: 0 1 0 0 0 0 0 1 0 0 0 | 0 

Setting time for this decision to 3.86942960288809s.
DP-UCT: Maximal search depth set to 37

Search time: 0.00868392s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1575
Cache Hits: 0
Skipped backups: 267782
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 193 real visits)
move-west : -3 (in 301 real visits)
move-south : -10 (in 7 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 24/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 3.88340579710145s.
DP-UCT: Maximal search depth set to 36

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 36
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 6/40 in round 24/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.89751636363636s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 35
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 24/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.91173357664234s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 34
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 24/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.92605128205128s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 33
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 24/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.94047426470588s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 32
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 24/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.955s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 31
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 24/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.96963703703704s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 30
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 24/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.98438289962825s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 29
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 24/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 3.99923507462687s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 28
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 24/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.01420224719101s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 27
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 24/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 4.02927819548872s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 26
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 24/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 4.04447169811321s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 25
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 24/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.0597803030303s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 24
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 24/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.07520532319392s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 23
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 24/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.09074427480916s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 22
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 24/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.1064061302682s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 21
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 24/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 4.12218846153846s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 20
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 24/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 4.13809266409266s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 19
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 24/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.15411627906977s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 18
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 24/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 4.17026459143969s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 17
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 24/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.18654296875s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 16
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 24/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 4.20294509803922s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 15
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 24/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.21948031496063s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 14
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 24/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.23614624505929s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 13
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 24/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.25294444444444s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 12
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 24/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.2698764940239s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 11
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 24/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.28694s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 10
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 24/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.30414859437751s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 9
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 24/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.32149596774194s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 8
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 24/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.33898380566802s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 7
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 24/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.35660975609756s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 6
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 24/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.37437959183673s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 5
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 24/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.39229098360656s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 4
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 24/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 4.41035390946502s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 3
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 24/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.42856611570248s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 2
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 24/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.44692946058091s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33066

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 12000
Accumulated number of search nodes in root state: 39702

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 24 -- REWARD RECEIVED: -4
***********************************************

***********************************************
>>> STARTING ROUND 25 -- REMAINING TIME 1074s
***********************************************
***********************************************
Planning step 1/40 in round 25/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 4.46544583333333s.
DP-UCT: Maximal search depth set to 40

Search time: 0.016412s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1701
Cache Hits: 0
Skipped backups: 269882
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33381

Root Node: 
-5.17187 (in 503 real visits)

Q-Value Estimates: 
noop() : -14.0425 (in 47 real visits)
move-west : -5.17187 (in 416 real visits)
move-north : -13.4 (in 40 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 25/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 4.48389539748954s.
DP-UCT: Maximal search depth set to 39

Search time: 0.00793386s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1596
Cache Hits: 0
Skipped backups: 272206
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33666

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -14.6083 (in 10 real visits)
move-west : -15.2625 (in 10 real visits)
move-north : -3 (in 474 real visits)
move-east : -9.79 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 25/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 0 

Setting time for this decision to 4.50269327731092s.
DP-UCT: Maximal search depth set to 38

Search time: 0.00834203s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1570
Cache Hits: 0
Skipped backups: 274434
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 33938

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -8.6 (in 10 real visits)
move-west : -14 (in 10 real visits)
move-south : -14 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -12.8 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 25/30
Current state: 0 0 0 0 0 0 0 1 0 0 0 | 0 

Setting time for this decision to 4.52164978902954s.
DP-UCT: Maximal search depth set to 37

Search time: 0.00887585s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1572
Cache Hits: 0
Skipped backups: 276978
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 481 real visits)
move-west : -5.325 (in 10 real visits)
move-south : -6.9525 (in 10 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 25/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.54076271186441s.
DP-UCT: Maximal search depth set to 36

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 36
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 6/40 in round 25/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.56007659574468s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 35
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 25/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.57955555555556s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 34
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 25/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 4.5992017167382s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 33
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 25/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 4.61901293103448s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 32
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 25/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.63899567099567s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 31
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 25/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 4.65915652173913s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 30
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 25/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.67949344978166s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 29
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 25/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.70000877192983s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 28
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 25/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.72070925110132s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 27
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 25/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 4.74158849557522s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 26
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 25/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 4.76264888888889s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 25
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 25/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.78389732142857s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 24
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 25/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 4.80534080717489s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 23
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 25/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 4.82697297297297s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 22
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 25/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 4.84880090497738s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 21
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 25/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.87082727272727s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 20
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 25/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.89305479452055s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 19
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 25/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.91548623853211s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 18
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 25/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.9381198156682s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 17
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 25/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 4.96096759259259s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 16
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 25/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 4.98402790697674s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 15
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 25/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 5.00730373831776s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 14
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 25/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 5.03079812206573s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 13
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 25/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 5.05450943396226s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 12
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 25/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 5.07845023696682s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 11
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 25/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 5.10261904761905s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 10
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 25/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 5.12701435406699s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 9
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 25/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 5.15164903846154s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 8
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 25/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 5.17652173913043s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 7
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 25/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 5.20163106796117s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 6
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 25/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 5.22699024390244s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 5
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 25/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 5.25259803921569s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 4
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 25/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 5.27845812807882s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 3
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 25/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 5.30456930693069s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 2
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 25/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 5.33094527363184s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34214

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 12500
Accumulated number of search nodes in root state: 41403

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 25 -- REWARD RECEIVED: -4
***********************************************

***********************************************
>>> STARTING ROUND 26 -- REMAINING TIME 1074s
***********************************************
***********************************************
Planning step 1/40 in round 26/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 5.357585s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0116532s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1634
Cache Hits: 0
Skipped backups: 279228
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34505

Root Node: 
-5.24747 (in 503 real visits)

Q-Value Estimates: 
noop() : -14.6667 (in 10 real visits)
move-west : -5.24747 (in 468 real visits)
move-north : -13.4 (in 25 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 26/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 5.38424623115578s.
DP-UCT: Maximal search depth set to 39

Search time: 0.00882721s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1610
Cache Hits: 0
Skipped backups: 281660
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 34791

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -16.0333 (in 10 real visits)
move-west : -15.2625 (in 10 real visits)
move-north : -3 (in 468 real visits)
move-east : -13.8 (in 16 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 26/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 0 

Setting time for this decision to 5.41137878787879s.
DP-UCT: Maximal search depth set to 38

Search time: 0.00873208s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1580
Cache Hits: 0
Skipped backups: 283874
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35065

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -5.4 (in 10 real visits)
move-west : -10.5017 (in 10 real visits)
move-south : -14 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -12.8 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 26/30
Current state: 0 0 0 0 0 0 0 1 0 0 0 | 1 

Setting time for this decision to 5.43878680203046s.
DP-UCT: Maximal search depth set to 37

Search time: 0.00830388s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1531
Cache Hits: 0
Skipped backups: 286148
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 197 real visits)
move-west : -3 (in 301 real visits)
move-south : SOLVED with: -37 (in 3 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 26/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 5.46647959183673s.
DP-UCT: Maximal search depth set to 36

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 36
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 6/40 in round 26/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 5.49449743589744s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 35
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 26/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 5.52280412371134s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 34
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 26/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 5.55140414507772s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 33
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 26/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 5.58030208333333s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 32
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 26/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 5.60950261780105s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 31
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 26/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 5.63900526315789s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 30
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 26/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 5.6688253968254s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 29
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 26/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 5.69896276595745s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 28
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 26/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 5.72942245989305s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 27
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 26/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 5.76020430107527s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 26
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 26/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 5.79132432432432s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 25
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 26/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 5.82278260869565s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 24
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 26/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 5.85458469945355s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 23
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 26/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 5.88673076923077s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 22
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 26/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 5.91923756906077s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 21
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 26/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 5.9521s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 20
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 26/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 5.98533519553073s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 19
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 26/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 6.01894382022472s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 18
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 26/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 6.05293220338983s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 17
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 26/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 6.08730681818182s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 16
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 26/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 6.12207428571429s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 15
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 26/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 6.15723563218391s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 14
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 26/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 6.19280924855491s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 13
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 26/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 6.22879651162791s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 12
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 26/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 6.26520467836257s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 11
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 26/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 6.30203529411765s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 10
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 26/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 6.33930769230769s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 9
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 26/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 6.37701785714286s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 8
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 26/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 6.41518562874252s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 7
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 26/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 6.45380722891566s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 6
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 26/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 6.49290303030303s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 5
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 26/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 6.5324756097561s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 4
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 26/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 6.57252760736196s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 3
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 26/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 6.61308024691358s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 2
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 26/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 6.65413664596273s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35332

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 13000
Accumulated number of search nodes in root state: 43037

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 26 -- REWARD RECEIVED: -4
***********************************************

***********************************************
>>> STARTING ROUND 27 -- REMAINING TIME 1074s
***********************************************
***********************************************
Planning step 1/40 in round 27/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 6.69570625s.
DP-UCT: Maximal search depth set to 40

Search time: 0.014261s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1699
Cache Hits: 0
Skipped backups: 288454
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35641

Root Node: 
-6.0996 (in 503 real visits)

Q-Value Estimates: 
noop() : -12.322 (in 53 real visits)
move-west : -6.0996 (in 441 real visits)
move-north : -13.4 (in 9 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 27/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 6.73747798742138s.
DP-UCT: Maximal search depth set to 39

Search time: 0.00811505s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1611
Cache Hits: 0
Skipped backups: 291000
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 35930

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -12.7 (in 10 real visits)
move-west : -15.2625 (in 10 real visits)
move-north : -3 (in 473 real visits)
move-east : -11.05 (in 11 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 27/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 0 

Setting time for this decision to 6.78005063291139s.
DP-UCT: Maximal search depth set to 38

Search time: 0.00892782s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1610
Cache Hits: 0
Skipped backups: 293254
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36210

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -6.1 (in 10 real visits)
move-west : -12.425 (in 10 real visits)
move-south : -12.6875 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -12.8 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 27/30
Current state: 0 0 0 0 0 0 0 1 0 0 0 | 1 

Setting time for this decision to 6.82315923566879s.
DP-UCT: Maximal search depth set to 37

Search time: 0.00835109s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1534
Cache Hits: 0
Skipped backups: 295396
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 297 real visits)
move-west : -3 (in 201 real visits)
move-south : SOLVED with: -37 (in 3 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 27/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 6.86682692307692s.
DP-UCT: Maximal search depth set to 36

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 36
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 6/40 in round 27/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 6.91111612903226s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 35
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 27/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 6.95597402597403s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 34
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 27/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 7.0014183006536s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 33
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 27/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 7.04746052631579s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 32
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 27/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 7.09411258278146s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 31
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 27/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 7.14138666666667s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 30
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 27/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 7.18929530201342s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 29
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 27/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 7.23784459459459s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 28
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 27/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 7.2870612244898s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 27
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 27/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 7.33695205479452s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 26
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 27/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 7.38753103448276s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 25
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 27/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 7.4388125s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 24
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 27/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 7.49081818181818s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 23
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 27/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 7.54354929577465s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 22
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 27/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 7.59702836879433s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 21
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 27/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 7.65127142857143s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 20
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 27/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 7.70630215827338s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 19
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 27/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 7.76213043478261s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 18
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 27/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 7.81877372262774s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 17
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 27/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 7.87625s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 16
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 27/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 7.93457777777778s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 15
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 27/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 7.99377611940298s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 14
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 27/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 8.05385714285714s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 13
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 27/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 8.11484848484849s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 12
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 27/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 8.17677099236641s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 11
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 27/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 8.23964615384615s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 10
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 27/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 8.30349612403101s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 9
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 27/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 8.3683359375s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 8
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 27/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 8.43420472440945s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 7
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 27/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 8.50111904761905s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 6
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 27/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 8.569104s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 5
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 27/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 8.63817741935484s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 4
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 27/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 8.70838211382114s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 3
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 27/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 8.77973770491803s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 2
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 27/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 8.85227272727273s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36476

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 13500
Accumulated number of search nodes in root state: 44736

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 27 -- REWARD RECEIVED: -4
***********************************************

***********************************************
>>> STARTING ROUND 28 -- REMAINING TIME 1074s
***********************************************
***********************************************
Planning step 1/40 in round 28/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 8.92600833333333s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0160451s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1641
Cache Hits: 0
Skipped backups: 297486
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 36774

Root Node: 
-4.597 (in 503 real visits)

Q-Value Estimates: 
noop() : -14.8513 (in 33 real visits)
move-west : -4.597 (in 407 real visits)
move-north : -13.4 (in 63 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 28/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 9.00055462184874s.
DP-UCT: Maximal search depth set to 39

Search time: 0.00811696s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1631
Cache Hits: 0
Skipped backups: 300046
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37065

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -14.3333 (in 10 real visits)
move-west : -15 (in 10 real visits)
move-north : -3 (in 474 real visits)
move-east : -10.9333 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 28/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 0 

Setting time for this decision to 9.07674576271186s.
DP-UCT: Maximal search depth set to 38

Search time: 0.008847s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1572
Cache Hits: 0
Skipped backups: 302416
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37339

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -7.78 (in 10 real visits)
move-west : -11.75 (in 10 real visits)
move-south : -11.75 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -12.8 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 28/30
Current state: 0 0 0 0 0 0 0 1 0 0 0 | 0 

Setting time for this decision to 9.15422222222222s.
DP-UCT: Maximal search depth set to 37

Search time: 0.00795197s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1574
Cache Hits: 0
Skipped backups: 304782
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 481 real visits)
move-west : -5.325 (in 10 real visits)
move-south : -5.325 (in 10 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 28/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 9.23305172413793s.
DP-UCT: Maximal search depth set to 36

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 36
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 6/40 in round 28/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 9.31331304347826s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 35
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 28/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 9.39499122807018s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 34
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 28/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 9.47810619469027s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 33
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 28/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 9.56270535714286s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 32
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 28/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 9.64882882882883s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 31
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 28/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 9.73650909090909s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 30
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 28/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 9.82579816513761s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 29
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 28/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 9.91675s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 28
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 28/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 10.0094018691589s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 27
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 28/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 10.1038018867925s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 26
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 28/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 10.2s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 25
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 28/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 10.2980480769231s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 24
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 28/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 10.398s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 23
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 28/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 10.4999019607843s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 22
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 28/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 10.6038316831683s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 21
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 28/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 10.70983s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 20
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 28/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 10.8179797979798s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 19
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 28/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 10.9283367346939s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 18
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 28/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 11.0409587628866s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 17
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 28/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 11.1559375s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 16
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 28/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 11.2733368421053s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 15
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 28/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 11.3932340425532s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 14
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 28/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 11.5156989247312s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 13
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 28/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 11.6408369565217s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 12
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 28/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 11.7687252747253s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 11
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 28/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 11.8994444444444s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 10
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 28/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 12.0331123595506s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 9
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 28/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 12.1698068181818s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 8
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 28/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 12.3096551724138s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 7
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 28/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 12.4527441860465s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 6
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 28/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 12.5992117647059s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 5
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 28/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 12.7491666666667s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 4
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 28/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 12.902734939759s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 3
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 28/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 13.0600487804878s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 2
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 28/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 13.2212469135802s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37613

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 14000
Accumulated number of search nodes in root state: 46377

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 28 -- REWARD RECEIVED: -4
***********************************************

***********************************************
>>> STARTING ROUND 29 -- REMAINING TIME 1073s
***********************************************
***********************************************
Planning step 1/40 in round 29/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 13.3864625s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0154021s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1668
Cache Hits: 0
Skipped backups: 306924
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 37916

Root Node: 
-4.9615 (in 503 real visits)

Q-Value Estimates: 
noop() : -14.2005 (in 44 real visits)
move-west : -4.9615 (in 409 real visits)
move-north : -13.4 (in 50 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 29/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 13.5552151898734s.
DP-UCT: Maximal search depth set to 39

Search time: 0.00906706s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1605
Cache Hits: 0
Skipped backups: 309446
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38201

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -12 (in 10 real visits)
move-west : -15.875 (in 10 real visits)
move-north : -3 (in 474 real visits)
move-east : -14.6 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 29/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 0 

Setting time for this decision to 13.728858974359s.
DP-UCT: Maximal search depth set to 38

Search time: 0.00843s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1569
Cache Hits: 0
Skipped backups: 311882
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38479

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -5.4 (in 10 real visits)
move-west : -12.425 (in 10 real visits)
move-south : -8.65 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -12.8 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 29/30
Current state: 0 0 0 0 0 0 0 1 0 0 0 | 0 

Setting time for this decision to 13.907012987013s.
DP-UCT: Maximal search depth set to 37

Search time: 0.00840497s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1528
Cache Hits: 0
Skipped backups: 313990
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 193 real visits)
move-west : -3 (in 301 real visits)
move-south : -3 (in 7 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 29/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 14.0898552631579s.
DP-UCT: Maximal search depth set to 36

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 36
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 6/40 in round 29/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 14.27768s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 35
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 29/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 14.4705810810811s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 34
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 29/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 14.6687671232877s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 33
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 29/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 14.8724722222222s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 32
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 29/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 15.0819014084507s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 31
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 29/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 15.2973142857143s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 30
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 29/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 15.5189710144928s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 29
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 29/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 15.7471323529412s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 28
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 29/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 15.9821194029851s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 27
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 29/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 16.2242121212121s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 26
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 29/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 16.4737692307692s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 25
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 29/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 16.731125s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 24
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 29/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 16.9966349206349s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 23
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 29/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 17.2707258064516s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 22
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 29/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 17.5538032786885s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 21
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 29/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 17.8463166666667s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 20
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 29/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 18.1487457627119s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 19
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 29/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 18.4616034482759s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 18
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 29/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 18.7854210526316s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 17
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 29/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 19.1208214285714s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 16
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 29/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 19.4684181818182s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 15
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 29/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 19.8288888888889s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 14
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 29/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 20.2029622641509s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 13
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 29/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 20.5914038461538s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 12
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 29/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 20.9950980392157s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 11
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 29/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 21.41494s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 10
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 29/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 21.8519183673469s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 9
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 29/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 22.3071041666667s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 8
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 29/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 22.7816595744681s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 7
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 29/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 23.2768260869565s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 6
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 29/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 23.7940222222222s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 5
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 29/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 24.3347272727273s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 4
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 29/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 24.9005813953488s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 3
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 29/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 25.493380952381s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 2
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 29/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 26.1150975609756s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 38746

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 14500
Accumulated number of search nodes in root state: 48045

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 29 -- REWARD RECEIVED: -4
***********************************************

***********************************************
>>> STARTING ROUND 30 -- REMAINING TIME 1073s
***********************************************
***********************************************
Planning step 1/40 in round 30/30
Current state: 1 0 0 0 0 0 0 0 1 0 0 | 1 

Setting time for this decision to 26.7679s.
DP-UCT: Maximal search depth set to 40

Search time: 0.00885391s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1670
Cache Hits: 0
Skipped backups: 315900
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 39048

Root Node: 
-5.7445 (in 503 real visits)

Q-Value Estimates: 
noop() : -13.183 (in 89 real visits)
move-west : -5.7445 (in 358 real visits)
move-north : -13.4 (in 56 real visits)

Used RAM: 313812

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 30/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 | 1 

Setting time for this decision to 27.453s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0123081s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1690
Cache Hits: 0
Skipped backups: 318064
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 39362

Root Node: 
-5.15185 (in 504 real visits)

Q-Value Estimates: 
noop() : -5.15185 (in 474 real visits)
move-west : -15.875 (in 10 real visits)
move-north : SOLVED with: -39 (in 3 real visits)
move-east : -15.2525 (in 17 real visits)

Used RAM: 313812

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 30/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 | 1 

Setting time for this decision to 28.175052631579s.
DP-UCT: Maximal search depth set to 38

Search time: 0.00883293s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1627
Cache Hits: 0
Skipped backups: 320276
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 39659

Root Node: 
-5.13812 (in 504 real visits)

Q-Value Estimates: 
noop() : -5.13812 (in 459 real visits)
move-west : -14.8417 (in 15 real visits)
move-north : SOLVED with: -38 (in 3 real visits)
move-east : -13.925 (in 27 real visits)

Used RAM: 313812

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 30/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 | 0 

Setting time for this decision to 28.9362432432432s.
DP-UCT: Maximal search depth set to 37

Search time: 0.00900698s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1605
Cache Hits: 0
Skipped backups: 322638
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 39943

Root Node: 
-3 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.6667 (in 10 real visits)
move-west : -14.5708 (in 10 real visits)
move-north : -3 (in 474 real visits)
move-east : -10.7667 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 30/30
Current state: 1 0 0 0 0 0 1 0 0 0 0 | 1 

Setting time for this decision to 29.7396944444444s.
DP-UCT: Maximal search depth set to 36

Search time: 0.00836301s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1582
Cache Hits: 0
Skipped backups: 325108
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40218

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -36 (in 3 real visits)
move-west : -11.875 (in 10 real visits)
move-south : -10.5333 (in 10 real visits)
move-north : -2 (in 472 real visits)
move-east : -12.2 (in 10 real visits)

Used RAM: 313812

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 30/30
Current state: 0 1 0 0 0 0 0 1 0 0 0 | 1 

Setting time for this decision to 30.5890857142857s.
DP-UCT: Maximal search depth set to 35

Search time: 0.00903606s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1539
Cache Hits: 0
Skipped backups: 327652
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -4.25 (in 10 real visits)
move-west : -3 (in 488 real visits)
move-south : SOLVED with: -35 (in 3 real visits)
move-east : SOLVED with: -1 (in 3 real visits)

Used RAM: 313812

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 30/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 31.4884117647059s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 34
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 30/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 32.4425151515152s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 33
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 30/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 33.45625s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 32
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 30/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 34.5354193548387s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 31
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 30/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 35.6865s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 30
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 30/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 36.9169310344828s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 29
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 30/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 38.2352857142857s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 28
StateHashKey: 3074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 30/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 39.6512592592593s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 27
StateHashKey: 3075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 30/30
Current state: 1 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 41.1761923076923s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 26
StateHashKey: 1027
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 30/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 42.82312s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 25
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 30/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 44.6072916666667s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 24
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 30/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 46.5466086956522s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 23
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 30/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 48.6622272727273s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 22
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 30/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 50.9793333333333s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 21
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 30/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 53.5281s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 20
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 30/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 56.3452105263158s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 19
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 30/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 59.4753333333333s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 18
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 30/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 62.9736470588235s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 17
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 30/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 66.9093125s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 16
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 30/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 71.3697333333333s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 15
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 30/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 76.4673571428571s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 14
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 30/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 82.3492307692308s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 13
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 30/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 89.2114166666667s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 12
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 30/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 97.3212727272727s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 11
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 30/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 107.0531s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 10
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 30/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 118.947444444444s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 9
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 30/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 133.8155s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 8
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 30/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 152.931571428571s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 7
StateHashKey: 3072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 30/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 178.419833333333s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 6
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 30/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 1 

Setting time for this decision to 214.1032s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 1
Remaining Steps: 5
StateHashKey: 3073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 30/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 267.62825s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 4
StateHashKey: 1026
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 30/30
Current state: 1 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 356.836666666667s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 3
StateHashKey: 1025
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 30/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 535.253s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x2, y2): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 1

obstacle-at(x3, y2): 0
Remaining Steps: 2
StateHashKey: 1024
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 30/30
Current state: 0 0 0 0 0 0 0 0 0 0 1 | 0 

Setting time for this decision to 1070.503s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 3.30769 (in 52 runs)
  Maximal search depth: 40
  Cache hits: 40482

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 15000
Accumulated number of search nodes in root state: 49715

Used RAM: 313812

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 30 -- REWARD RECEIVED: -6
***********************************************

***********************************************
Immediate rewards:
Round 0: -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -5
Round 1: -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -5
Round 2: -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -6
Round 3: -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -6
Round 4: -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -6
Round 5: -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -4
Round 6: -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -5
Round 7: -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -4
Round 8: -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -4
Round 9: -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -4
Round 10: -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -4
Round 11: -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -5
Round 12: -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -4
Round 13: -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -6
Round 14: -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -5
Round 15: -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -4
Round 16: -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -5
Round 17: -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -4
Round 18: -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -4
Round 19: -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -4
Round 20: -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -4
Round 21: -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -10
Round 22: -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -4
Round 23: -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -4
Round 24: -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -4
Round 25: -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -4
Round 26: -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -4
Round 27: -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -4
Round 28: -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -4
Round 29: -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -6

>>>           TOTAL REWARD: -142
>>>          AVERAGE REWARD: -4.73333333333333
***********************************************
PROST complete running time: 7.15947198867798s
