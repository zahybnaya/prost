learning...
IDS: learning...
IDS: Search Depth 2: 0.000303984 / 200 = 1.51992e-06
IDS: Search Depth 3: 0.00240564 / 200 = 1.20282e-05
IDS: Search Depth 4: 0.00424123 / 200 = 2.12061e-05
IDS: Search Depth 5: 0.00575352 / 200 = 2.87676e-05
IDS: Search Depth 6: 0.00707531 / 200 = 3.53765e-05
IDS: Search Depth 7: 0.00834036 / 200 = 4.17018e-05
IDS: Search Depth 8: 0.00958061 / 200 = 4.79031e-05
IDS: Search Depth 9: 0.0108342 / 200 = 5.41711e-05
IDS: Search Depth 10: 0.0121107 / 200 = 6.05536e-05
IDS: Search Depth 11: 0.0133419 / 200 = 6.67095e-05
IDS: Search Depth 12: 0.0145893 / 200 = 7.29465e-05
IDS: Search Depth 13: 0.0158274 / 200 = 7.91371e-05
IDS: Search Depth 14: 0.0170767 / 200 = 8.53837e-05
IDS: Search Depth 15: 0.0183313 / 200 = 9.16564e-05
IDS: Search Depth 16: 0.0195684 / 200 = 9.78422e-05
IDS: Search Depth 17: 0.0208459 / 200 = 0.000104229
IDS: Search Depth 18: 0.0220838 / 200 = 0.000110419
IDS: Search Depth 19: 0.0233238 / 200 = 0.000116619
IDS: Search Depth 20: 0.02455 / 200 = 0.00012275
IDS: Search Depth 21: 0.0257766 / 200 = 0.000128883
IDS: Search Depth 22: 0.0270021 / 200 = 0.00013501
IDS: Search Depth 23: 0.0282478 / 200 = 0.000141239
IDS: Search Depth 24: 0.0295005 / 200 = 0.000147502
IDS: Search Depth 25: 0.0307257 / 200 = 0.000153629
IDS: Search Depth 26: 0.0319593 / 200 = 0.000159796
IDS: Search Depth 27: 0.0331991 / 200 = 0.000165995
IDS: Search Depth 28: 0.0344336 / 200 = 0.000172168
IDS: Search Depth 29: 0.0356526 / 200 = 0.000178263
IDS: Search Depth 30: 0.0369093 / 200 = 0.000184547
IDS: Search Depth 31: 0.0381415 / 200 = 0.000190707
IDS: Search Depth 32: 0.0393779 / 200 = 0.00019689
IDS: Search Depth 33: 0.0406218 / 200 = 0.000203109
IDS: Search Depth 34: 0.041872 / 200 = 0.00020936
IDS: Search Depth 35: 0.043088 / 200 = 0.00021544
IDS: Search Depth 36: 0.0443473 / 200 = 0.000221736
IDS: Search Depth 37: 0.045598 / 200 = 0.00022799
IDS: Search Depth 38: 0.0468545 / 200 = 0.000234272
IDS: Search Depth 39: 0.048115 / 200 = 0.000240575
IDS: Search Depth 40: 0.0497787 / 200 = 0.000248893
IDS: Setting max search depth to 40!
IDS: ...finished
DP-UCT: learning...
DP-UCT: ...finished
...finished (0.0917602s).

Final task: 
----------------Actions---------------

Action fluents: 
move-east
move-north
move-south
move-west
---------------

Legal Action Combinations: 
noop() : 
Index : 0
Relevant preconditions: 
---------------
move-west : 
Index : 1
Relevant preconditions: 
---------------
move-south : 
Index : 2
Relevant preconditions: 
---------------
move-north : 
Index : 3
Relevant preconditions: 
---------------
move-east : 
Index : 4
Relevant preconditions: 
---------------

-----------------CPFs-----------------

obstacle-at(x1, y2)
  HashIndex: 0, deterministic, caching in vectors, Kleene caching in vectors of size 3.

  Action Hash Key Map: 
  Formula: 
obstacle-at(x2, y2)

  Domain: false true 
  HashKeyBase: 0: 0, 1: 1
  KleeneHashKeyBase: 1

--------------
obstacle-at(x1, y3)
  HashIndex: 1, deterministic, caching in vectors, Kleene caching in vectors of size 3.

  Action Hash Key Map: 
  Formula: 
obstacle-at(x2, y3)

  Domain: false true 
  HashKeyBase: 0: 0, 1: 2
  KleeneHashKeyBase: 3

--------------
obstacle-at(x2, y2)
  HashIndex: 2, deterministic, caching in vectors, Kleene caching in vectors of size 3.

  Action Hash Key Map: 
  Formula: 
obstacle-at(x3, y2)

  Domain: false true 
  HashKeyBase: 0: 0, 1: 4
  KleeneHashKeyBase: 9

--------------
obstacle-at(x2, y3)
  HashIndex: 3, deterministic, caching in vectors, Kleene caching in vectors of size 3.

  Action Hash Key Map: 
  Formula: 
obstacle-at(x3, y3)

  Domain: false true 
  HashKeyBase: 0: 0, 1: 8
  KleeneHashKeyBase: 27

--------------
obstacle-at(x3, y2)
  HashIndex: 4, deterministic, caching in vectors, Kleene caching in vectors of size 3.

  Action Hash Key Map: 
  Formula: 
obstacle-at(x4, y2)

  Domain: false true 
  HashKeyBase: 0: 0, 1: 16
  KleeneHashKeyBase: 81

--------------
obstacle-at(x3, y3)
  HashIndex: 5, deterministic, caching in vectors, Kleene caching in vectors of size 3.

  Action Hash Key Map: 
  Formula: 
obstacle-at(x4, y3)

  Domain: false true 
  HashKeyBase: 0: 0, 1: 32
  KleeneHashKeyBase: 243

--------------
robot-at(x1, y1)
  HashIndex: 6, deterministic, caching in vectors, Kleene caching in vectors of size 1215.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x1, y1))  then 0
case (and move-south robot-at(x1, y2) (not obstacle-at(x1, y2)) )  then 1
case (and move-east robot-at(x1, y1))  then 0
case (and move-west robot-at(x2, y1))  then 1
case 1 then robot-at(x1, y1)


  Domain: false true 
  HashKeyBase: 0: 0, 1: 64
  KleeneHashKeyBase: 729

--------------
robot-at(x1, y2)
  HashIndex: 7, deterministic, caching in vectors, Kleene caching in vectors of size 32805.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x1, y1))  then 1
case (and move-north robot-at(x1, y2))  then 0
case (and move-south robot-at(x1, y3) (not obstacle-at(x1, y3)) )  then 1
case (and move-south robot-at(x1, y2))  then 0
case (and move-east robot-at(x1, y2))  then 0
case (and move-west robot-at(x2, y2) (not obstacle-at(x2, y2)) )  then 1
case 1 then (and robot-at(x1, y2) (not obstacle-at(x1, y2)) ) 


  Domain: false true 
  HashKeyBase: 0: 0, 1: 128
  KleeneHashKeyBase: 2187

--------------
robot-at(x1, y3)
  HashIndex: 8, deterministic, caching in vectors, Kleene caching in vectors of size 32805.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x1, y2) (not obstacle-at(x1, y2)) )  then 1
case (and move-north robot-at(x1, y3))  then 0
case (and move-south robot-at(x1, y4))  then 1
case (and move-south robot-at(x1, y3))  then 0
case (and move-east robot-at(x1, y3))  then 0
case (and move-west robot-at(x2, y3) (not obstacle-at(x2, y3)) )  then 1
case 1 then (and robot-at(x1, y3) (not obstacle-at(x1, y3)) ) 


  Domain: false true 
  HashKeyBase: 0: 0, 1: 256
  KleeneHashKeyBase: 6561

--------------
robot-at(x1, y4)
  HashIndex: 9, deterministic, caching in vectors, Kleene caching in vectors of size 1215.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x1, y3) (not obstacle-at(x1, y3)) )  then 1
case (and move-south robot-at(x1, y4))  then 0
case (and move-east robot-at(x1, y4))  then 0
case (and move-west robot-at(x2, y4))  then 1
case 1 then robot-at(x1, y4)


  Domain: false true 
  HashKeyBase: 0: 0, 1: 512
  KleeneHashKeyBase: 19683

--------------
robot-at(x2, y1)
  HashIndex: 10, deterministic, caching in vectors, Kleene caching in vectors of size 3645.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x2, y1))  then 0
case (and move-south robot-at(x2, y2) (not obstacle-at(x2, y2)) )  then 1
case (and move-east robot-at(x1, y1))  then 1
case (and move-east robot-at(x2, y1))  then 0
case (and move-west robot-at(x3, y1))  then 1
case (and move-west robot-at(x2, y1))  then 0
case 1 then robot-at(x2, y1)


  Domain: false true 
  HashKeyBase: 0: 0, 1: 1024
  KleeneHashKeyBase: 59049

--------------
robot-at(x2, y2)
  HashIndex: 11, deterministic, caching in vectors, Kleene caching in maps.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x2, y1))  then 1
case (and move-north robot-at(x2, y2))  then 0
case (and move-south robot-at(x2, y3) (not obstacle-at(x2, y3)) )  then 1
case (and move-south robot-at(x2, y2))  then 0
case (and move-east robot-at(x1, y2) (not obstacle-at(x1, y2)) )  then 1
case (and move-east robot-at(x2, y2))  then 0
case (and move-west robot-at(x3, y2) (not obstacle-at(x3, y2)) )  then 1
case (and move-west robot-at(x2, y2))  then 0
case 1 then (and robot-at(x2, y2) (not obstacle-at(x2, y2)) ) 


  Domain: false true 
  HashKeyBase: 0: 0, 1: 2048
  KleeneHashKeyBase: 177147

--------------
robot-at(x2, y3)
  HashIndex: 12, deterministic, caching in vectors, Kleene caching in maps.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x2, y2) (not obstacle-at(x2, y2)) )  then 1
case (and move-north robot-at(x2, y3))  then 0
case (and move-south robot-at(x2, y4))  then 1
case (and move-south robot-at(x2, y3))  then 0
case (and move-east robot-at(x1, y3) (not obstacle-at(x1, y3)) )  then 1
case (and move-east robot-at(x2, y3))  then 0
case (and move-west robot-at(x3, y3) (not obstacle-at(x3, y3)) )  then 1
case (and move-west robot-at(x2, y3))  then 0
case 1 then (and robot-at(x2, y3) (not obstacle-at(x2, y3)) ) 


  Domain: false true 
  HashKeyBase: 0: 0, 1: 4096
  KleeneHashKeyBase: 531441

--------------
robot-at(x2, y4)
  HashIndex: 13, deterministic, caching in vectors, Kleene caching in vectors of size 3645.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x2, y3) (not obstacle-at(x2, y3)) )  then 1
case (and move-south robot-at(x2, y4))  then 0
case (and move-east robot-at(x1, y4))  then 1
case (and move-east robot-at(x2, y4))  then 0
case (and move-west robot-at(x3, y4))  then 1
case (and move-west robot-at(x2, y4))  then 0
case 1 then robot-at(x2, y4)


  Domain: false true 
  HashKeyBase: 0: 0, 1: 8192
  KleeneHashKeyBase: 1594323

--------------
robot-at(x3, y1)
  HashIndex: 14, deterministic, caching in vectors, Kleene caching in vectors of size 3645.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x3, y1))  then 0
case (and move-south robot-at(x3, y2) (not obstacle-at(x3, y2)) )  then 1
case (and move-east robot-at(x2, y1))  then 1
case (and move-east robot-at(x3, y1))  then 0
case (and move-west robot-at(x4, y1))  then 1
case (and move-west robot-at(x3, y1))  then 0
case 1 then robot-at(x3, y1)


  Domain: false true 
  HashKeyBase: 0: 0, 1: 16384
  KleeneHashKeyBase: 4782969

--------------
robot-at(x3, y2)
  HashIndex: 15, deterministic, caching in vectors, Kleene caching in maps.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x3, y1))  then 1
case (and move-north robot-at(x3, y2))  then 0
case (and move-south robot-at(x3, y3) (not obstacle-at(x3, y3)) )  then 1
case (and move-south robot-at(x3, y2))  then 0
case (and move-east robot-at(x2, y2) (not obstacle-at(x2, y2)) )  then 1
case (and move-east robot-at(x3, y2))  then 0
case (and move-west robot-at(x4, y2) (not obstacle-at(x4, y2)) )  then 1
case (and move-west robot-at(x3, y2))  then 0
case 1 then (and robot-at(x3, y2) (not obstacle-at(x3, y2)) ) 


  Domain: false true 
  HashKeyBase: 0: 0, 1: 32768
  KleeneHashKeyBase: 14348907

--------------
robot-at(x3, y3)
  HashIndex: 16, deterministic, caching in vectors, Kleene caching in maps.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x3, y2) (not obstacle-at(x3, y2)) )  then 1
case (and move-north robot-at(x3, y3))  then 0
case (and move-south robot-at(x3, y4))  then 1
case (and move-south robot-at(x3, y3))  then 0
case (and move-east robot-at(x2, y3) (not obstacle-at(x2, y3)) )  then 1
case (and move-east robot-at(x3, y3))  then 0
case (and move-west robot-at(x4, y3) (not obstacle-at(x4, y3)) )  then 1
case (and move-west robot-at(x3, y3))  then 0
case 1 then (and robot-at(x3, y3) (not obstacle-at(x3, y3)) ) 


  Domain: false true 
  HashKeyBase: 0: 0, 1: 65536
  KleeneHashKeyBase: 43046721

--------------
robot-at(x3, y4)
  HashIndex: 17, deterministic, caching in vectors, Kleene caching in vectors of size 1215.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x3, y3) (not obstacle-at(x3, y3)) )  then 1
case (and move-south robot-at(x3, y4))  then 0
case (and move-east robot-at(x2, y4))  then 1
case (and move-east robot-at(x3, y4))  then 0
case (and move-west robot-at(x4, y4))  then 1
case (and move-west robot-at(x3, y4))  then 0
case 1 then robot-at(x3, y4)


  Domain: false true 
  HashKeyBase: 0: 0, 1: 131072
  KleeneHashKeyBase: 129140163

--------------
robot-at(x4, y1)
  HashIndex: 18, deterministic, caching in vectors, Kleene caching in vectors of size 1215.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x4, y1))  then 0
case (and move-south robot-at(x4, y2) (not obstacle-at(x4, y2)) )  then 1
case (and move-east robot-at(x3, y1))  then 1
case (and move-west robot-at(x4, y1))  then 0
case 1 then robot-at(x4, y1)


  Domain: false true 
  HashKeyBase: 0: 0, 1: 262144
  KleeneHashKeyBase: 387420489

--------------
robot-at(x4, y2)
  HashIndex: 19, deterministic, caching in vectors, Kleene caching in vectors of size 32805.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x4, y1))  then 1
case (and move-north robot-at(x4, y2))  then 0
case (and move-south robot-at(x4, y3) (not obstacle-at(x4, y3)) )  then 1
case (and move-south robot-at(x4, y2))  then 0
case (and move-east robot-at(x3, y2) (not obstacle-at(x3, y2)) )  then 1
case (and move-west robot-at(x4, y2))  then 0
case 1 then (and robot-at(x4, y2) (not obstacle-at(x4, y2)) ) 


  Domain: false true 
  HashKeyBase: 0: 0, 1: 524288
  KleeneHashKeyBase: 1162261467

--------------
robot-at(x4, y3)
  HashIndex: 20, deterministic, caching in vectors, Kleene caching in vectors of size 10935.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x4, y2) (not obstacle-at(x4, y2)) )  then 1
case (and move-north robot-at(x4, y3))  then 0
case (and move-south robot-at(x4, y4))  then 1
case (and move-south robot-at(x4, y3))  then 0
case (and move-east robot-at(x3, y3) (not obstacle-at(x3, y3)) )  then 1
case (and move-west robot-at(x4, y3))  then 0
case 1 then (and robot-at(x4, y3) (not obstacle-at(x4, y3)) ) 


  Domain: false true 
  HashKeyBase: 0: 0, 1: 1048576
  KleeneHashKeyBase: 3486784401

--------------
robot-at(x4, y4)
  HashIndex: 21, deterministic, caching in vectors, Kleene caching in vectors of size 405.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 1
case robot-at(x4, y4) then 0
case (and move-north robot-at(x4, y3) (not obstacle-at(x4, y3)) )  then 1
case (and move-south robot-at(x4, y4))  then 0
case (and move-east robot-at(x3, y4))  then 1
case (and move-west robot-at(x4, y4))  then 0
case 1 then robot-at(x4, y4)


  Domain: false true 
  HashKeyBase: 0: 0, 1: 2097152
  KleeneHashKeyBase: 10460353203

--------------
obstacle-at(x4, y2)
  HashIndex: 22, probabilistic, caching in vectors, Kleene caching in vectors of size 1.

  Action Hash Key Map: 
  Formula: 
Bernoulli(0.6) 
  Determinized formula: 
1
  Domain: false true 
  HashKeyBase: 0: 0, 1: 4194304
  KleeneHashKeyBase: 31381059609

--------------
obstacle-at(x4, y3)
  HashIndex: 23, probabilistic, caching in vectors, Kleene caching in vectors of size 1.

  Action Hash Key Map: 
  Formula: 
Bernoulli(0.6) 
  Determinized formula: 
1
  Domain: false true 
  HashKeyBase: 0: 0, 1: 8388608
  KleeneHashKeyBase: 94143178827

--------------

Reward CPF:
Reward
  HashIndex: 24, deterministic, caching in vectors, Kleene caching in vectors of size 3.

  Action Hash Key Map: 
  Formula: 
(- 0 (not robot-at(x4, y4)) ) 
Minimal reward: -1
Maximal reward: 0
Is action independent: 1



------State Fluent Hash Key Map-------

a change of deterministic state fluent 0 influences variables 6 (5) 7 (5) 8 (5) 11 (5) 
a change of deterministic state fluent 1 influences variables 7 (10) 8 (10) 9 (5) 12 (5) 
a change of deterministic state fluent 2 influences variables 0 (1) 7 (20) 10 (5) 11 (10) 12 (10) 15 (5) 
a change of deterministic state fluent 3 influences variables 1 (1) 8 (20) 11 (20) 12 (20) 13 (5) 16 (5) 
a change of deterministic state fluent 4 influences variables 2 (1) 11 (40) 14 (5) 15 (10) 16 (10) 19 (5) 
a change of deterministic state fluent 5 influences variables 3 (1) 12 (40) 15 (20) 16 (20) 17 (5) 20 (5) 
a change of deterministic state fluent 6 influences variables 6 (10) 7 (40) 10 (10) 
a change of deterministic state fluent 7 influences variables 6 (20) 7 (80) 8 (40) 11 (80) 
a change of deterministic state fluent 8 influences variables 7 (160) 8 (80) 9 (10) 12 (80) 
a change of deterministic state fluent 9 influences variables 8 (160) 9 (20) 13 (10) 
a change of deterministic state fluent 10 influences variables 6 (40) 10 (20) 11 (160) 14 (10) 
a change of deterministic state fluent 11 influences variables 7 (320) 10 (40) 11 (320) 12 (160) 15 (40) 
a change of deterministic state fluent 12 influences variables 8 (320) 11 (640) 12 (320) 13 (20) 16 (40) 
a change of deterministic state fluent 13 influences variables 9 (40) 12 (640) 13 (40) 17 (10) 
a change of deterministic state fluent 14 influences variables 10 (80) 14 (20) 15 (80) 18 (5) 
a change of deterministic state fluent 15 influences variables 11 (1280) 14 (40) 15 (160) 16 (80) 19 (10) 
a change of deterministic state fluent 16 influences variables 12 (1280) 15 (320) 16 (160) 17 (20) 20 (10) 
a change of deterministic state fluent 17 influences variables 13 (80) 16 (320) 17 (40) 21 (5) 
a change of deterministic state fluent 18 influences variables 14 (80) 18 (10) 19 (20) 
a change of deterministic state fluent 19 influences variables 15 (640) 18 (20) 19 (40) 20 (20) 
a change of deterministic state fluent 20 influences variables 16 (640) 19 (80) 20 (40) 21 (10) 
a change of deterministic state fluent 21 influences variables 6 (80) 7 (640) 8 (640) 9 (80) 10 (160) 11 (2560) 12 (2560) 13 (160) 14 (160) 15 (1280) 16 (1280) 17 (80) 18 (40) 19 (160) 20 (80) 21 (20) 24 (1) 

a change of probabilistic state fluent 0 influences variables 4 (1) 15 (2560) 18 (80) 19 (320) 20 (160) 
a change of probabilistic state fluent 1 influences variables 5 (1) 16 (2560) 19 (640) 20 (320) 21 (40) 


a change of variable 0 influences variables in Kleene states 6 (5) 7 (5) 8 (5) 11 (5) 
a change of variable 1 influences variables in Kleene states 7 (15) 8 (15) 9 (5) 12 (5) 
a change of variable 2 influences variables in Kleene states 0 (1) 7 (45) 10 (5) 11 (15) 12 (15) 15 (5) 
a change of variable 3 influences variables in Kleene states 1 (1) 8 (45) 11 (45) 12 (45) 13 (5) 16 (5) 
a change of variable 4 influences variables in Kleene states 2 (1) 11 (135) 14 (5) 15 (15) 16 (15) 19 (5) 
a change of variable 5 influences variables in Kleene states 3 (1) 12 (135) 15 (45) 16 (45) 17 (5) 20 (5) 
a change of variable 6 influences variables in Kleene states 6 (15) 7 (135) 10 (15) 
a change of variable 7 influences variables in Kleene states 6 (45) 7 (405) 8 (135) 11 (405) 
a change of variable 8 influences variables in Kleene states 7 (1215) 8 (405) 9 (15) 12 (405) 
a change of variable 9 influences variables in Kleene states 8 (1215) 9 (45) 13 (15) 
a change of variable 10 influences variables in Kleene states 6 (135) 10 (45) 11 (1215) 14 (15) 
a change of variable 11 influences variables in Kleene states 7 (3645) 10 (135) 11 (3645) 12 (1215) 15 (135) 
a change of variable 12 influences variables in Kleene states 8 (3645) 11 (10935) 12 (3645) 13 (45) 16 (135) 
a change of variable 13 influences variables in Kleene states 9 (135) 12 (10935) 13 (135) 17 (15) 
a change of variable 14 influences variables in Kleene states 10 (405) 14 (45) 15 (405) 18 (5) 
a change of variable 15 influences variables in Kleene states 11 (32805) 14 (135) 15 (1215) 16 (405) 19 (15) 
a change of variable 16 influences variables in Kleene states 12 (32805) 15 (3645) 16 (1215) 17 (45) 20 (15) 
a change of variable 17 influences variables in Kleene states 13 (405) 16 (3645) 17 (135) 21 (5) 
a change of variable 18 influences variables in Kleene states 14 (405) 18 (15) 19 (45) 
a change of variable 19 influences variables in Kleene states 15 (10935) 18 (45) 19 (135) 20 (45) 
a change of variable 20 influences variables in Kleene states 16 (10935) 19 (405) 20 (135) 21 (15) 
a change of variable 21 influences variables in Kleene states 6 (405) 7 (10935) 8 (10935) 9 (405) 10 (1215) 11 (98415) 12 (98415) 13 (1215) 14 (1215) 15 (32805) 16 (32805) 17 (405) 18 (135) 19 (1215) 20 (405) 21 (45) 24 (1) 
a change of variable 22 influences variables in Kleene states 4 (1) 15 (98415) 18 (405) 19 (3645) 20 (1215) 
a change of variable 23 influences variables in Kleene states 5 (1) 16 (98415) 19 (10935) 20 (3645) 21 (135) 

---------Action Preconditions---------

----------Initial State---------------

obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 1
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 0

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 40
StateHashKey: 4456504

Hashing of States is possible.
Hashing of KleeneStates is possible.
Reward lock detection is enabled for goals and dead ends.
This task contains unreasonable actions.
The final reward is determined by applying NOOP.

***********************************************
>>> STARTING ROUND 1 -- REMAINING TIME 1080s
***********************************************
***********************************************
Planning step 1/40 in round 1/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 0.8975s.
DP-UCT: Maximal search depth set to 40

Search time: 0.117505s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2532
Cache Hits: 0
Skipped backups: 1971
Initialization: 
  Statistics of IDS:
  Average search depth: 31.8231 (in 294 runs)
  Maximal search depth: 40
  Cache hits: 135

Root Node: 
-19.2725 (in 503 real visits)

Q-Value Estimates: 
noop() : -20.6824 (in 148 real visits)
move-west : -19.2725 (in 345 real visits)
move-north : -32.28 (in 10 real visits)

Used RAM: 335616

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 1/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 0.898110091743119s.
DP-UCT: Maximal search depth set to 39

Search time: 0.088279s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2519
Cache Hits: 0
Skipped backups: 3741
Initialization: 
  Statistics of IDS:
  Average search depth: 31.8285 (in 449 runs)
  Maximal search depth: 40
  Cache hits: 412

Root Node: 
-19.2796 (in 504 real visits)

Q-Value Estimates: 
noop() : -19.3504 (in 199 real visits)
move-west : -19.2796 (in 184 real visits)
move-north : SOLVED with: -39 (in 5 real visits)
move-east : -20.4208 (in 116 real visits)

Used RAM: 336548

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 1/30
Current state: 1 1 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 0.898775459098497s.
DP-UCT: Maximal search depth set to 38

Search time: 0.099967s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2598
Cache Hits: 0
Skipped backups: 5439
Initialization: 
  Statistics of IDS:
  Average search depth: 29.5809 (in 661 runs)
  Maximal search depth: 40
  Cache hits: 644

Root Node: 
-17.1904 (in 504 real visits)

Q-Value Estimates: 
noop() : -17.1904 (in 228 real visits)
move-west : -17.2978 (in 179 real visits)
move-north : SOLVED with: -38 (in 5 real visits)
move-east : -18.8281 (in 92 real visits)

Used RAM: 337688

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 1/30
Current state: 1 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 0.899434419381788s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0669761s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2562
Cache Hits: 0
Skipped backups: 6882
Initialization: 
  Statistics of IDS:
  Average search depth: 23.2371 (in 911 runs)
  Maximal search depth: 40
  Cache hits: 798

Root Node: 
-11.0204 (in 504 real visits)

Q-Value Estimates: 
noop() : -18.076 (in 23 real visits)
move-west : -16.5902 (in 38 real visits)
move-north : -11.0204 (in 423 real visits)
move-east : -18.68 (in 20 real visits)

Used RAM: 338716

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 1/30
Current state: 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 0.90011872909699s.
DP-UCT: Maximal search depth set to 36

Search time: 0.023905s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1763
Cache Hits: 0
Skipped backups: 8097
Initialization: 
  Statistics of IDS:
  Average search depth: 21.6505 (in 987 runs)
  Maximal search depth: 40
  Cache hits: 955

Root Node: 
-4.36934 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -36 (in 5 real visits)
move-west : -15.6 (in 14 real visits)
move-south : -18.68 (in 10 real visits)
move-north : -4.36934 (in 471 real visits)
move-east : SOLVED with: -36 (in 5 real visits)

Used RAM: 338744

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 1/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 0.900844351464435s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0200081s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1799
Cache Hits: 0
Skipped backups: 9585
Initialization: 
  Statistics of IDS:
  Average search depth: 20.2813 (in 1063 runs)
  Maximal search depth: 40
  Cache hits: 1118

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -35 (in 5 real visits)
move-west : -14.465 (in 10 real visits)
move-south : SOLVED with: -35 (in 5 real visits)
move-north : -10.75 (in 10 real visits)
move-east : -3 (in 475 real visits)

Used RAM: 338844

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 1/30
Current state: 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 0 

Setting time for this decision to 0.901575376884422s.
DP-UCT: Maximal search depth set to 34

Search time: 0.0181911s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1722
Cache Hits: 0
Skipped backups: 10995
Initialization: 
  Statistics of IDS:
  Average search depth: 19.5632 (in 1108 runs)
  Maximal search depth: 40
  Cache hits: 1299

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -10.752 (in 10 real visits)
move-west : -12.6667 (in 10 real visits)
move-south : SOLVED with: -34 (in 5 real visits)
move-north : -2 (in 470 real visits)
move-east : -21.2 (in 10 real visits)

Used RAM: 338948

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 1/30
Current state: 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 1 

Setting time for this decision to 0.90230846605197s.
DP-UCT: Maximal search depth set to 33

Search time: 0.0159659s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1711
Cache Hits: 0
Skipped backups: 12429
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 484 real visits)
move-west : -9.54467 (in 10 real visits)
move-south : SOLVED with: -33 (in 5 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 339008

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 9/40 in round 1/30
Current state: 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.903044463087248s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 32
StateHashKey: 6291493
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 1/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.903797649034425s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 31
StateHashKey: 6291481
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 1/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.904551260504202s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 6291478
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 1/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.905306980656014s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 10485781
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 1/30
Current state: 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.90606228956229s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 28
StateHashKey: 14680101
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 1/30
Current state: 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.906819713563606s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 27
StateHashKey: 2097209
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 1/30
Current state: 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.907579258010118s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 2097166
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 1/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.908340084388186s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 6291459
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 1/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.90910304054054s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 24
StateHashKey: 10485776
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 1/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.909866441251057s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 6291492
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 1/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.910629441624366s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 22
StateHashKey: 10485785
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 1/30
Current state: 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.911393734123624s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 6291494
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 1/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.912160169491525s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 14680089
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 1/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.912928753180662s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 6291510
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 1/30
Current state: 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.913696943972835s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 14680093
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 1/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.914466440101954s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 10485815
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 1/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.915239795918367s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 2097197
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 1/30
Current state: 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.916015319148936s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 6291467
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 1/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.916792163543441s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 14680082
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 1/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.917570332480818s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 13
StateHashKey: 10485812
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 1/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.918348976109215s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 10485805
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 1/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.919129803586678s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 10485803
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 1/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.919911111111111s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 2097194
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 1/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.920692044482464s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 6291466
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 1/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.921475171232877s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 8
StateHashKey: 14680082
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 1/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.922258783204799s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 7
StateHashKey: 10485812
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 1/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.923044596912521s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 6291501
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 1/30
Current state: 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.923831759656652s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 2097179
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 1/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.924622852233677s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 4
StateHashKey: 14680070
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 1/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.925414445399828s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 14680113
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 1/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.926207401032702s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 14680124
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 1/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.926999138673557s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6749 (in 1169 runs)
  Maximal search depth: 40
  Cache hits: 1459

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 500
Accumulated number of search nodes in root state: 2532

Used RAM: 339096

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 1 -- REWARD RECEIVED: -8
***********************************************

***********************************************
>>> STARTING ROUND 2 -- REMAINING TIME 1079s
***********************************************
***********************************************
Planning step 1/40 in round 2/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 0.92779224137931s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0661209s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2508
Cache Hits: 0
Skipped backups: 14352
Initialization: 
  Statistics of IDS:
  Average search depth: 19.1976 (in 1225 runs)
  Maximal search depth: 40
  Cache hits: 1823

Root Node: 
-19.9571 (in 503 real visits)

Q-Value Estimates: 
noop() : -20.8166 (in 182 real visits)
move-west : -19.9571 (in 309 real visits)
move-north : -31.776 (in 12 real visits)

Used RAM: 339096

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 2/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 0.928499568593615s.
DP-UCT: Maximal search depth set to 39

Search time: 0.069248s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2533
Cache Hits: 0
Skipped backups: 16176
Initialization: 
  Statistics of IDS:
  Average search depth: 19.4984 (in 1264 runs)
  Maximal search depth: 40
  Cache hits: 2209

Root Node: 
-17.8224 (in 504 real visits)

Q-Value Estimates: 
noop() : -17.8224 (in 284 real visits)
move-west : -20.1889 (in 107 real visits)
move-north : SOLVED with: -39 (in 5 real visits)
move-east : -20.1731 (in 108 real visits)

Used RAM: 339356

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 2/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 0.929237478411054s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0671191s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2318
Cache Hits: 0
Skipped backups: 17574
Initialization: 
  Statistics of IDS:
  Average search depth: 19.8101 (in 1432 runs)
  Maximal search depth: 40
  Cache hits: 2391

Root Node: 
-12.6404 (in 504 real visits)

Q-Value Estimates: 
noop() : -18.768 (in 35 real visits)
move-west : -17.006 (in 66 real visits)
move-north : -12.6404 (in 377 real visits)
move-east : -19.76 (in 26 real visits)

Used RAM: 339740

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 2/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 0.929977528089888s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0720649s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2454
Cache Hits: 0
Skipped backups: 19251
Initialization: 
  Statistics of IDS:
  Average search depth: 19.9518 (in 1472 runs)
  Maximal search depth: 40
  Cache hits: 2748

Root Node: 
-17.337 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -37 (in 5 real visits)
move-west : -18.1243 (in 213 real visits)
move-south : -17.337 (in 270 real visits)
move-north : SOLVED with: -37 (in 5 real visits)
move-east : -28.6 (in 12 real visits)

Used RAM: 339836

Submitted action: move-south 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 2/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 0.930715397923875s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0560191s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2364
Cache Hits: 0
Skipped backups: 20835
Initialization: 
  Statistics of IDS:
  Average search depth: 20.0959 (in 1522 runs)
  Maximal search depth: 40
  Cache hits: 3060

Root Node: 
-12.2738 (in 504 real visits)

Q-Value Estimates: 
noop() : -18.5467 (in 30 real visits)
move-west : -17.044 (in 49 real visits)
move-north : -12.2738 (in 399 real visits)
move-east : -19 (in 26 real visits)

Used RAM: 339960

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 2/30
Current state: 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 0.931467532467532s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0659859s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2462
Cache Hits: 0
Skipped backups: 22467
Initialization: 
  Statistics of IDS:
  Average search depth: 20.1507 (in 1533 runs)
  Maximal search depth: 40
  Cache hits: 3450

Root Node: 
-16.2455 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -35 (in 5 real visits)
move-west : -16.9522 (in 246 real visits)
move-south : -16.2455 (in 239 real visits)
move-north : SOLVED with: -35 (in 5 real visits)
move-east : -27.62 (in 10 real visits)

Used RAM: 340016

Submitted action: move-south 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 2/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 0.932212305025997s.
DP-UCT: Maximal search depth set to 34

Search time: 0.0640931s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2518
Cache Hits: 0
Skipped backups: 24225
Initialization: 
  Statistics of IDS:
  Average search depth: 20.1852 (in 1550 runs)
  Maximal search depth: 40
  Cache hits: 3863

Root Node: 
-16.738 (in 504 real visits)

Q-Value Estimates: 
noop() : -16.738 (in 231 real visits)
move-west : -17.647 (in 133 real visits)
move-north : SOLVED with: -34 (in 5 real visits)
move-east : -17.6154 (in 135 real visits)

Used RAM: 340072

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 2/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 0.932960971379011s.
DP-UCT: Maximal search depth set to 33

Search time: 0.0532291s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2356
Cache Hits: 0
Skipped backups: 25758
Initialization: 
  Statistics of IDS:
  Average search depth: 20.2646 (in 1580 runs)
  Maximal search depth: 40
  Cache hits: 4190

Root Node: 
-11.5417 (in 504 real visits)

Q-Value Estimates: 
noop() : -17.068 (in 29 real visits)
move-west : -15.7718 (in 37 real visits)
move-north : -11.5417 (in 417 real visits)
move-east : -17.5 (in 21 real visits)

Used RAM: 340092

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 9/40 in round 2/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 0.933719618055556s.
DP-UCT: Maximal search depth set to 32

Search time: 0.0657959s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2460
Cache Hits: 0
Skipped backups: 27456
Initialization: 
  Statistics of IDS:
  Average search depth: 20.2571 (in 1587 runs)
  Maximal search depth: 40
  Cache hits: 4584

Root Node: 
-15.2929 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -32 (in 5 real visits)
move-west : -15.7475 (in 219 real visits)
move-south : -15.2929 (in 265 real visits)
move-north : SOLVED with: -32 (in 5 real visits)
move-east : -25.28 (in 11 real visits)

Used RAM: 340128

Submitted action: move-south 
Immediate reward: -1
***********************************************

***********************************************
Planning step 10/40 in round 2/30
Current state: 1 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 0.934469157254561s.
DP-UCT: Maximal search depth set to 31

Search time: 0.052819s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2368
Cache Hits: 0
Skipped backups: 28890
Initialization: 
  Statistics of IDS:
  Average search depth: 20.2579 (in 1605 runs)
  Maximal search depth: 40
  Cache hits: 4927

Root Node: 
-11.0473 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.6453 (in 28 real visits)
move-west : -13.3186 (in 84 real visits)
move-north : -11.0473 (in 370 real visits)
move-east : -16.42 (in 22 real visits)

Used RAM: 340140

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 11/40 in round 2/30
Current state: 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 0.935231304347826s.
DP-UCT: Maximal search depth set to 30

Search time: 0.063343s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2411
Cache Hits: 0
Skipped backups: 30459
Initialization: 
  Statistics of IDS:
  Average search depth: 20.2711 (in 1608 runs)
  Maximal search depth: 40
  Cache hits: 5308

Root Node: 
-15.0041 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -30 (in 5 real visits)
move-west : -15.1107 (in 268 real visits)
move-south : -15.0041 (in 214 real visits)
move-north : SOLVED with: -30 (in 5 real visits)
move-east : -23.336 (in 13 real visits)

Used RAM: 340164

Submitted action: move-south 
Immediate reward: -1
***********************************************

***********************************************
Planning step 12/40 in round 2/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 0.935985204525674s.
DP-UCT: Maximal search depth set to 29

Search time: 0.0613482s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2490
Cache Hits: 0
Skipped backups: 32163
Initialization: 
  Statistics of IDS:
  Average search depth: 20.2753 (in 1609 runs)
  Maximal search depth: 40
  Cache hits: 5732

Root Node: 
-14.6444 (in 504 real visits)

Q-Value Estimates: 
noop() : -14.7411 (in 179 real visits)
move-west : -14.6444 (in 194 real visits)
move-north : SOLVED with: -29 (in 5 real visits)
move-east : -15.2672 (in 126 real visits)

Used RAM: 340168

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 13/40 in round 2/30
Current state: 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 0.936742160278746s.
DP-UCT: Maximal search depth set to 28

Search time: 0.070467s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2525
Cache Hits: 0
Skipped backups: 33801
Initialization: 
  Statistics of IDS:
  Average search depth: 20.2677 (in 1614 runs)
  Maximal search depth: 40
  Cache hits: 6156

Root Node: 
-13.7335 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.7335 (in 195 real visits)
move-west : -13.9779 (in 161 real visits)
move-north : SOLVED with: -28 (in 5 real visits)
move-east : -14.154 (in 143 real visits)

Used RAM: 340172

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 14/40 in round 2/30
Current state: 1 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 0.937492589363557s.
DP-UCT: Maximal search depth set to 27

Search time: 0.0725012s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2487
Cache Hits: 0
Skipped backups: 35475
Initialization: 
  Statistics of IDS:
  Average search depth: 20.2269 (in 1631 runs)
  Maximal search depth: 40
  Cache hits: 6562

Root Node: 
-13.081 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.081 (in 255 real visits)
move-west : -13.3071 (in 129 real visits)
move-north : SOLVED with: -27 (in 5 real visits)
move-east : -14.0521 (in 115 real visits)

Used RAM: 340192

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 15/40 in round 2/30
Current state: 1 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 0.938242582897033s.
DP-UCT: Maximal search depth set to 26

Search time: 0.07829s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2638
Cache Hits: 0
Skipped backups: 37179
Initialization: 
  Statistics of IDS:
  Average search depth: 20.1567 (in 1659 runs)
  Maximal search depth: 40
  Cache hits: 6983

Root Node: 
-12.0963 (in 504 real visits)

Q-Value Estimates: 
noop() : -12.0963 (in 264 real visits)
move-west : -12.7541 (in 145 real visits)
move-north : SOLVED with: -26 (in 5 real visits)
move-east : -13.4221 (in 90 real visits)

Used RAM: 340212

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 16/40 in round 2/30
Current state: 1 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 0.938989519650655s.
DP-UCT: Maximal search depth set to 25

Search time: 0.070514s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2438
Cache Hits: 0
Skipped backups: 38562
Initialization: 
  Statistics of IDS:
  Average search depth: 20.1488 (in 1660 runs)
  Maximal search depth: 40
  Cache hits: 7390

Root Node: 
-12.2781 (in 504 real visits)

Q-Value Estimates: 
noop() : -12.2781 (in 156 real visits)
move-west : -12.6165 (in 134 real visits)
move-north : -12.814 (in 111 real visits)
move-east : -12.7696 (in 103 real visits)

Used RAM: 340256

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 17/40 in round 2/30
Current state: 1 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 0.939743881118881s.
DP-UCT: Maximal search depth set to 24

Search time: 0.076015s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2613
Cache Hits: 0
Skipped backups: 40293
Initialization: 
  Statistics of IDS:
  Average search depth: 20.0665 (in 1684 runs)
  Maximal search depth: 40
  Cache hits: 7812

Root Node: 
-11.416 (in 504 real visits)

Q-Value Estimates: 
noop() : -11.416 (in 212 real visits)
move-west : -11.5574 (in 185 real visits)
move-north : SOLVED with: -24 (in 5 real visits)
move-east : -12.2704 (in 102 real visits)

Used RAM: 340256

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 18/40 in round 2/30
Current state: 0 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 0.940495188101487s.
DP-UCT: Maximal search depth set to 23

Search time: 0.067353s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2427
Cache Hits: 0
Skipped backups: 41664
Initialization: 
  Statistics of IDS:
  Average search depth: 20.057 (in 1685 runs)
  Maximal search depth: 40
  Cache hits: 8208

Root Node: 
-11.3536 (in 504 real visits)

Q-Value Estimates: 
noop() : -11.9968 (in 107 real visits)
move-west : -12.0365 (in 104 real visits)
move-north : -11.3536 (in 182 real visits)
move-east : -11.916 (in 111 real visits)

Used RAM: 340292

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 19/40 in round 2/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 0.941254816112084s.
DP-UCT: Maximal search depth set to 22

Search time: 0.0719581s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2358
Cache Hits: 0
Skipped backups: 43482
Initialization: 
  Statistics of IDS:
  Average search depth: 20.0302 (in 1691 runs)
  Maximal search depth: 40
  Cache hits: 8602

Root Node: 
-11.2566 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -22 (in 5 real visits)
move-west : -11.7433 (in 199 real visits)
move-south : -11.2566 (in 291 real visits)
move-north : SOLVED with: -22 (in 5 real visits)
move-east : SOLVED with: -22 (in 5 real visits)

Used RAM: 340292

Submitted action: move-south 
Immediate reward: -1
***********************************************

***********************************************
Planning step 20/40 in round 2/30
Current state: 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 0.94201226993865s.
DP-UCT: Maximal search depth set to 21

Search time: 0.07618s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2600
Cache Hits: 0
Skipped backups: 45120
Initialization: 
  Statistics of IDS:
  Average search depth: 19.9556 (in 1710 runs)
  Maximal search depth: 40
  Cache hits: 9026

Root Node: 
-10.163 (in 504 real visits)

Q-Value Estimates: 
noop() : -10.163 (in 227 real visits)
move-west : -10.3372 (in 182 real visits)
move-north : SOLVED with: -21 (in 5 real visits)
move-east : -11.1306 (in 90 real visits)

Used RAM: 340300

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 21/40 in round 2/30
Current state: 1 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 0.942765789473684s.
DP-UCT: Maximal search depth set to 20

Search time: 0.0758259s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2627
Cache Hits: 0
Skipped backups: 46518
Initialization: 
  Statistics of IDS:
  Average search depth: 19.8608 (in 1731 runs)
  Maximal search depth: 40
  Cache hits: 9434

Root Node: 
-9.40659 (in 504 real visits)

Q-Value Estimates: 
noop() : -9.40659 (in 156 real visits)
move-west : -9.99121 (in 121 real visits)
move-north : -9.92136 (in 142 real visits)
move-east : -10.4007 (in 85 real visits)

Used RAM: 340332

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 22/40 in round 2/30
Current state: 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 0.943523266022827s.
DP-UCT: Maximal search depth set to 19

Search time: 0.067239s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2436
Cache Hits: 0
Skipped backups: 47913
Initialization: 
  Statistics of IDS:
  Average search depth: 19.8608 (in 1731 runs)
  Maximal search depth: 40
  Cache hits: 9829

Root Node: 
-9.99655 (in 504 real visits)

Q-Value Estimates: 
noop() : -10.1182 (in 120 real visits)
move-west : -10.0966 (in 126 real visits)
move-north : -9.99655 (in 147 real visits)
move-east : -10.2141 (in 111 real visits)

Used RAM: 340356

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 23/40 in round 2/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 0.944289103690686s.
DP-UCT: Maximal search depth set to 18

Search time: 0.0626431s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2419
Cache Hits: 0
Skipped backups: 49293
Initialization: 
  Statistics of IDS:
  Average search depth: 19.4821 (in 1792 runs)
  Maximal search depth: 40
  Cache hits: 10138

Root Node: 
-7.78219 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -18 (in 5 real visits)
move-west : -8.94422 (in 87 real visits)
move-south : -8.80279 (in 88 real visits)
move-north : SOLVED with: -18 (in 5 real visits)
move-east : -7.78219 (in 320 real visits)

Used RAM: 340356

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 24/40 in round 2/30
Current state: 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 0.945059806508355s.
DP-UCT: Maximal search depth set to 17

Search time: 0.0234959s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1816
Cache Hits: 0
Skipped backups: 50763
Initialization: 
  Statistics of IDS:
  Average search depth: 19.2555 (in 1824 runs)
  Maximal search depth: 40
  Cache hits: 10346

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -17 (in 5 real visits)
move-west : -7.589 (in 10 real visits)
move-south : -9 (in 10 real visits)
move-north : -3 (in 470 real visits)
move-east : -13.8 (in 10 real visits)

Used RAM: 340432

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 25/40 in round 2/30
Current state: 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 1 

Setting time for this decision to 0.945866197183099s.
DP-UCT: Maximal search depth set to 16

Search time: 0.019031s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1736
Cache Hits: 0
Skipped backups: 52194
Initialization: 
  Statistics of IDS:
  Average search depth: 19.1509 (in 1836 runs)
  Maximal search depth: 40
  Cache hits: 10557

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -16 (in 5 real visits)
move-west : -6.65 (in 10 real visits)
move-south : SOLVED with: -16 (in 5 real visits)
move-north : -2 (in 475 real visits)
move-east : -10.4 (in 10 real visits)

Used RAM: 340464

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 26/40 in round 2/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 0 

Setting time for this decision to 0.946678414096916s.
DP-UCT: Maximal search depth set to 15

Search time: 0.0216219s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1814
Cache Hits: 0
Skipped backups: 53520
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6806 (in 1891 runs)
  Maximal search depth: 40
  Cache hits: 10742

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 479 real visits)
move-west : -4.70667 (in 10 real visits)
move-south : -5.25 (in 10 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 340480

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 27/40 in round 2/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.947489417989418s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 10485773
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6806 (in 1891 runs)
  Maximal search depth: 40
  Cache hits: 10742

Used RAM: 340556

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 2/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.948322153574581s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 13
StateHashKey: 14680099
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6806 (in 1891 runs)
  Maximal search depth: 40
  Cache hits: 10742

Used RAM: 340556

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 2/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.949155477031802s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 10485816
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6806 (in 1891 runs)
  Maximal search depth: 40
  Cache hits: 10742

Used RAM: 340556

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 2/30
Current state: 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.949989389920424s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 14680110
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6806 (in 1891 runs)
  Maximal search depth: 40
  Cache hits: 10742

Used RAM: 340556

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 2/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.950824778761062s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 6291515
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6806 (in 1891 runs)
  Maximal search depth: 40
  Cache hits: 10742

Used RAM: 340556

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 2/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.951661647475642s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 9
StateHashKey: 10485790
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6806 (in 1891 runs)
  Maximal search depth: 40
  Cache hits: 10742

Used RAM: 340556

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 2/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.9525s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 2097191
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6806 (in 1891 runs)
  Maximal search depth: 40
  Cache hits: 10742

Used RAM: 340556

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 2/30
Current state: 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.953340727595386s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 7
StateHashKey: 10485769
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6806 (in 1891 runs)
  Maximal search depth: 40
  Cache hits: 10742

Used RAM: 340556

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 2/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.954182948490231s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 6291490
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6806 (in 1891 runs)
  Maximal search depth: 40
  Cache hits: 10742

Used RAM: 340556

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 2/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.955025777777778s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 5
StateHashKey: 14680088
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6806 (in 1891 runs)
  Maximal search depth: 40
  Cache hits: 10742

Used RAM: 340556

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 2/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.955872775800712s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 6291510
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6806 (in 1891 runs)
  Maximal search depth: 40
  Cache hits: 10742

Used RAM: 340556

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 2/30
Current state: 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.956721282279608s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 14680093
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6806 (in 1891 runs)
  Maximal search depth: 40
  Cache hits: 10742

Used RAM: 340556

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 2/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.957569518716578s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 14680119
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6806 (in 1891 runs)
  Maximal search depth: 40
  Cache hits: 10742

Used RAM: 340556

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 2/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.958418376449598s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.6806 (in 1891 runs)
  Maximal search depth: 40
  Cache hits: 10742

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 1000
Accumulated number of search nodes in root state: 5040

Used RAM: 340556

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 2 -- REWARD RECEIVED: -26
***********************************************

***********************************************
>>> STARTING ROUND 3 -- REMAINING TIME 1077s
***********************************************
***********************************************
Planning step 1/40 in round 3/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 0.959269642857143s.
DP-UCT: Maximal search depth set to 40

Search time: 0.064055s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2559
Cache Hits: 0
Skipped backups: 55536
Initialization: 
  Statistics of IDS:
  Average search depth: 18.7401 (in 1901 runs)
  Maximal search depth: 40
  Cache hits: 11162

Root Node: 
-19.3022 (in 503 real visits)

Q-Value Estimates: 
noop() : -21.1368 (in 123 real visits)
move-west : -19.3022 (in 365 real visits)
move-north : -31.1861 (in 15 real visits)

Used RAM: 340556

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 3/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 0.96003127792672s.
DP-UCT: Maximal search depth set to 39

Search time: 0.063868s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2501
Cache Hits: 0
Skipped backups: 57345
Initialization: 
  Statistics of IDS:
  Average search depth: 18.7401 (in 1901 runs)
  Maximal search depth: 40
  Cache hits: 11587

Root Node: 
-17.4671 (in 504 real visits)

Q-Value Estimates: 
noop() : -17.4671 (in 250 real visits)
move-west : -19.6597 (in 139 real visits)
move-north : SOLVED with: -39 (in 5 real visits)
move-east : -20.1685 (in 110 real visits)

Used RAM: 340604

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 3/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 0.96082915921288s.
DP-UCT: Maximal search depth set to 38

Search time: 0.05058s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2362
Cache Hits: 0
Skipped backups: 59031
Initialization: 
  Statistics of IDS:
  Average search depth: 18.7487 (in 1902 runs)
  Maximal search depth: 40
  Cache hits: 11947

Root Node: 
-13.0039 (in 504 real visits)

Q-Value Estimates: 
noop() : -19.74 (in 17 real visits)
move-west : -18.396 (in 24 real visits)
move-north : -13.0039 (in 446 real visits)
move-east : -19.76 (in 17 real visits)

Used RAM: 340604

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 3/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 0.96163921217547s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0232818s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1904
Cache Hits: 0
Skipped backups: 60528
Initialization: 
  Statistics of IDS:
  Average search depth: 18.585 (in 1930 runs)
  Maximal search depth: 40
  Cache hits: 12175

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -17 (in 10 real visits)
move-west : -15.235 (in 10 real visits)
move-south : -18.42 (in 10 real visits)
move-north : -3 (in 465 real visits)
move-east : -29.18 (in 10 real visits)

Used RAM: 340604

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 3/30
Current state: 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 1 

Setting time for this decision to 0.962475806451613s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0187371s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1731
Cache Hits: 0
Skipped backups: 61920
Initialization: 
  Statistics of IDS:
  Average search depth: 18.5276 (in 1937 runs)
  Maximal search depth: 40
  Cache hits: 12392

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -36 (in 5 real visits)
move-west : -13.5233 (in 10 real visits)
move-south : SOLVED with: -36 (in 5 real visits)
move-north : -2 (in 475 real visits)
move-east : -22.4 (in 10 real visits)

Used RAM: 340624

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 3/30
Current state: 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 1 1 

Setting time for this decision to 0.963317488789238s.
DP-UCT: Maximal search depth set to 35

Search time: 0.017422s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1842
Cache Hits: 0
Skipped backups: 63501
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -6.5 (in 10 real visits)
move-west : -3 (in 484 real visits)
move-south : SOLVED with: -35 (in 5 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 340632

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 3/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.96416157989228s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 34
StateHashKey: 6291516
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 3/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.965024258760108s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 33
StateHashKey: 14680095
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 3/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.965887589928058s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 32
StateHashKey: 14680119
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 3/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.966752475247525s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 31
StateHashKey: 2097213
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 3/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.967618018018018s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 2097167
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 3/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.968485121731289s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 14680067
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 3/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.969353790613719s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 28
StateHashKey: 10485808
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 3/30
Current state: 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.970224028906956s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 10485804
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 3/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.971096745027125s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 26
StateHashKey: 10485803
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 3/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.971971040723982s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 25
StateHashKey: 14680106
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 3/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.972846920289855s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 24
StateHashKey: 14680122
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 3/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.973723481414325s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 23
StateHashKey: 10485822
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 3/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.974602540834846s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 22
StateHashKey: 10485807
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 3/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.975482288828338s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 2097195
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 3/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.976365454545455s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 14680074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 3/30
Current state: 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.977250227479527s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 6291506
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 3/30
Current state: 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.978136612021858s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 14680092
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 3/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.979024612579763s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 17
StateHashKey: 2097207
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 3/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.979915145985402s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 6291469
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 3/30
Current state: 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.980806392694064s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 2097171
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 3/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.981700182815357s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 14680068
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 3/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.9825956084172s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 2097201
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 3/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.983491758241758s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 6291468
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 3/30
Current state: 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.984390467461045s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 2097171
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 3/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.985289908256881s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 2097156
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 3/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.986191919191919s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 9
StateHashKey: 14680065
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 3/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.987094669117647s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 8
StateHashKey: 14680112
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 3/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.988s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 6291516
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 3/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.988906077348066s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 14680095
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 3/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.989814746543779s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 5
StateHashKey: 14680119
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 3/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.990725092250922s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 4
StateHashKey: 14680125
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 3/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.991636195752539s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 14680127
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 3/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.992549907578558s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 2097215
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 3/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.993464384828862s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4093 (in 1952 runs)
  Maximal search depth: 40
  Cache hits: 12627

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 1500
Accumulated number of search nodes in root state: 7599

Used RAM: 340652

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 3 -- REWARD RECEIVED: -6
***********************************************

***********************************************
>>> STARTING ROUND 4 -- REMAINING TIME 1076s
***********************************************
***********************************************
Planning step 1/40 in round 4/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 0.994381481481482s.
DP-UCT: Maximal search depth set to 40

Search time: 0.059041s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2560
Cache Hits: 0
Skipped backups: 65508
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4699 (in 1962 runs)
  Maximal search depth: 40
  Cache hits: 13051

Root Node: 
-19.7393 (in 503 real visits)

Q-Value Estimates: 
noop() : -20.4367 (in 193 real visits)
move-west : -19.7393 (in 298 real visits)
move-north : -31.18 (in 12 real visits)

Used RAM: 340652

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 4/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 0.995210379981464s.
DP-UCT: Maximal search depth set to 39

Search time: 0.063849s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2520
Cache Hits: 0
Skipped backups: 67212
Initialization: 
  Statistics of IDS:
  Average search depth: 18.472 (in 1964 runs)
  Maximal search depth: 40
  Cache hits: 13476

Root Node: 
-19.0013 (in 504 real visits)

Q-Value Estimates: 
noop() : -19.0013 (in 207 real visits)
move-west : -19.1438 (in 190 real visits)
move-north : SOLVED with: -39 (in 5 real visits)
move-east : -20.3392 (in 102 real visits)

Used RAM: 340720

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 4/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 0.996071428571429s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0521169s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2371
Cache Hits: 0
Skipped backups: 68664
Initialization: 
  Statistics of IDS:
  Average search depth: 18.4804 (in 1965 runs)
  Maximal search depth: 40
  Cache hits: 13839

Root Node: 
-12.8924 (in 504 real visits)

Q-Value Estimates: 
noop() : -18.842 (in 25 real visits)
move-west : -16.4701 (in 68 real visits)
move-north : -12.8924 (in 392 real visits)
move-east : -19.88 (in 19 real visits)

Used RAM: 340720

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 4/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 0.996943361188487s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0206249s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1859
Cache Hits: 0
Skipped backups: 70026
Initialization: 
  Statistics of IDS:
  Average search depth: 18.3715 (in 1981 runs)
  Maximal search depth: 40
  Cache hits: 14070

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -14.12 (in 10 real visits)
move-west : -15.191 (in 10 real visits)
move-south : -19 (in 10 real visits)
move-north : -3 (in 465 real visits)
move-east : -28.87 (in 10 real visits)

Used RAM: 340720

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 4/30
Current state: 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 0 

Setting time for this decision to 0.997846654275093s.
DP-UCT: Maximal search depth set to 36

Search time: 0.015795s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1671
Cache Hits: 0
Skipped backups: 71295
Initialization: 
  Statistics of IDS:
  Average search depth: 18.3246 (in 1987 runs)
  Maximal search depth: 40
  Cache hits: 14274

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -10.5 (in 10 real visits)
move-west : -13.46 (in 10 real visits)
move-south : SOLVED with: -36 (in 5 real visits)
move-north : -2 (in 470 real visits)
move-east : -23.64 (in 10 real visits)

Used RAM: 340728

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 4/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 1 

Setting time for this decision to 0.998755348837209s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0159171s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1633
Cache Hits: 0
Skipped backups: 72588
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 484 real visits)
move-west : -8.97333 (in 10 real visits)
move-south : SOLVED with: -35 (in 5 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 340732

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 4/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.999666666666667s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 34
StateHashKey: 6291492
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 4/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.00059459459459s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 33
StateHashKey: 6291481
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 4/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.00152425373134s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 32
StateHashKey: 14680086
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 4/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.00245471521942s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 31
StateHashKey: 10485813
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 4/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.00338691588785s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 30
StateHashKey: 14680109
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 4/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.0043199251637s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 14680123
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 4/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.00525561797753s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 28
StateHashKey: 14680126
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 4/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.00619306466729s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 27
StateHashKey: 6291519
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 4/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.00713227016886s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 26
StateHashKey: 14680095
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 4/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.00807323943662s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 25
StateHashKey: 14680119
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 4/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.00901597744361s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 6291517
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 4/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.00995954844779s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 23
StateHashKey: 14680095
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 4/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.01090583804143s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 22
StateHashKey: 14680119
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 4/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.01185391140434s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 2097213
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 4/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.01280283018868s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 10485775
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 4/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.01375354107649s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 14680099
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 4/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.01470793950851s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 10485816
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 4/30
Current state: 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.01566508987701s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 10485806
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 4/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.0166240530303s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 16
StateHashKey: 14680107
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 4/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.01758483412322s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 15
StateHashKey: 14680122
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 4/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.01854743833017s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 14680126
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 4/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.0195118708452s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 13
StateHashKey: 10485823
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 4/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.02047813688213s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 10485807
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 4/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.0214462416746s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 14680107
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 4/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.02241619047619s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 10
StateHashKey: 14680122
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 4/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.02338798856053s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 9
StateHashKey: 14680126
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 4/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.02436164122137s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 8
StateHashKey: 14680127
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 4/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.02533524355301s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 6291519
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 4/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.02631070745698s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 2097183
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 4/30
Current state: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.02728803827751s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 6291463
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 4/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.0282662835249s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 4
StateHashKey: 14680081
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 4/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.02924736337488s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 10485812
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 4/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.03023032629559s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 14680109
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 4/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.03121517771374s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2708 (in 1994 runs)
  Maximal search depth: 40
  Cache hits: 14471

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 2000
Accumulated number of search nodes in root state: 10159

Used RAM: 340740

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 4 -- REWARD RECEIVED: -6
***********************************************

***********************************************
>>> STARTING ROUND 5 -- REMAINING TIME 1076s
***********************************************
***********************************************
Planning step 1/40 in round 5/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 1.03220288461538s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0623131s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2549
Cache Hits: 0
Skipped backups: 74586
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2913 (in 1998 runs)
  Maximal search depth: 40
  Cache hits: 14897

Root Node: 
-19.5852 (in 503 real visits)

Q-Value Estimates: 
noop() : -20.4996 (in 178 real visits)
move-west : -19.5852 (in 315 real visits)
move-north : -32.32 (in 10 real visits)

Used RAM: 340740

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 5/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.03309817131858s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0655901s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2508
Cache Hits: 0
Skipped backups: 76305
Initialization: 
  Statistics of IDS:
  Average search depth: 18.3038 (in 2001 runs)
  Maximal search depth: 40
  Cache hits: 15322

Root Node: 
-18.6656 (in 504 real visits)

Q-Value Estimates: 
noop() : -18.701 (in 160 real visits)
move-west : -18.6656 (in 229 real visits)
move-north : SOLVED with: -39 (in 5 real visits)
move-east : -20.032 (in 110 real visits)

Used RAM: 340776

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 5/30
Current state: 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.03402601156069s.
DP-UCT: Maximal search depth set to 38

Search time: 0.072037s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2502
Cache Hits: 0
Skipped backups: 77985
Initialization: 
  Statistics of IDS:
  Average search depth: 18.3038 (in 2001 runs)
  Maximal search depth: 40
  Cache hits: 15747

Root Node: 
-17.9114 (in 504 real visits)

Q-Value Estimates: 
noop() : -17.9114 (in 230 real visits)
move-west : -19.0784 (in 118 real visits)
move-north : SOLVED with: -38 (in 5 real visits)
move-east : -18.6008 (in 151 real visits)

Used RAM: 340780

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 5/30
Current state: 1 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.03494985535198s.
DP-UCT: Maximal search depth set to 37

Search time: 0.072001s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2515
Cache Hits: 0
Skipped backups: 79674
Initialization: 
  Statistics of IDS:
  Average search depth: 18.2972 (in 2002 runs)
  Maximal search depth: 40
  Cache hits: 16180

Root Node: 
-17.3369 (in 504 real visits)

Q-Value Estimates: 
noop() : -18.4675 (in 132 real visits)
move-west : -17.3369 (in 244 real visits)
move-north : SOLVED with: -37 (in 5 real visits)
move-east : -18.6244 (in 123 real visits)

Used RAM: 340780

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 5/30
Current state: 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.03587451737452s.
DP-UCT: Maximal search depth set to 36

Search time: 0.07939s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2633
Cache Hits: 0
Skipped backups: 81480
Initialization: 
  Statistics of IDS:
  Average search depth: 18.3265 (in 2006 runs)
  Maximal search depth: 40
  Cache hits: 16625

Root Node: 
-16.1199 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.5897 (in 218 real visits)
move-north : SOLVED with: -36 (in 5 real visits)
move-east : -16.1199 (in 280 real visits)

Used RAM: 340780

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 5/30
Current state: 1 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.03679516908213s.
DP-UCT: Maximal search depth set to 35

Search time: 0.049495s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2469
Cache Hits: 0
Skipped backups: 82740
Initialization: 
  Statistics of IDS:
  Average search depth: 18.175 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 16986

Root Node: 
-9.89314 (in 504 real visits)

Q-Value Estimates: 
noop() : -18.2486 (in 21 real visits)
move-west : -14.8302 (in 59 real visits)
move-north : -9.89314 (in 404 real visits)
move-east : -17.72 (in 20 real visits)

Used RAM: 340788

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 5/30
Current state: 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.03774564796905s.
DP-UCT: Maximal search depth set to 34

Search time: 0.025306s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1957
Cache Hits: 0
Skipped backups: 84090
Initialization: 
  Statistics of IDS:
  Average search depth: 18.0828 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 17243

Root Node: 
-4.16243 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -34 (in 5 real visits)
move-west : -14.792 (in 14 real visits)
move-south : -16.412 (in 10 real visits)
move-north : -4.16243 (in 465 real visits)
move-east : -15.5667 (in 11 real visits)

Used RAM: 340828

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 5/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.03872120038722s.
DP-UCT: Maximal search depth set to 33

Search time: 0.0197458s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1806
Cache Hits: 0
Skipped backups: 85503
Initialization: 
  Statistics of IDS:
  Average search depth: 17.9922 (in 2054 runs)
  Maximal search depth: 40
  Cache hits: 17470

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -12.3333 (in 10 real visits)
move-west : -13.695 (in 10 real visits)
move-south : -17 (in 10 real visits)
move-north : -3 (in 470 real visits)
move-east : SOLVED with: -33 (in 5 real visits)

Used RAM: 340836

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 9/40 in round 5/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.03970445736434s.
DP-UCT: Maximal search depth set to 32

Search time: 0.0171139s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1728
Cache Hits: 0
Skipped backups: 86901
Initialization: 
  Statistics of IDS:
  Average search depth: 17.9713 (in 2057 runs)
  Maximal search depth: 40
  Cache hits: 17695

Root Node: 
-2 (in 504 real visits)

Q-Value Estimates: 
noop() : -9.29733 (in 10 real visits)
move-west : -12.1 (in 10 real visits)
move-south : SOLVED with: -32 (in 5 real visits)
move-east : -2 (in 479 real visits)

Used RAM: 340852

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 10/40 in round 5/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 1 

Setting time for this decision to 1.04069253152279s.
DP-UCT: Maximal search depth set to 31

Search time: 0.018151s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1719
Cache Hits: 0
Skipped backups: 88179
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 43 real visits)
move-west : -3 (in 451 real visits)
move-south : SOLVED with: -31 (in 5 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 340852

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 11/40 in round 5/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.04168058252427s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 30
StateHashKey: 10485807
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 5/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.04268901846453s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 10485803
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 5/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.04370038910506s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 28
StateHashKey: 14680106
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 5/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.04471080817916s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 10485818
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 5/30
Current state: 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.04572319688109s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 2097198
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 5/30
Current state: 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.04673853658537s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 25
StateHashKey: 10485771
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 5/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.0477548828125s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 6291490
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 5/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.04877419354839s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 23
StateHashKey: 14680088
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 5/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.04979549902153s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 2097206
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 5/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.05081978452498s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 21
StateHashKey: 10485773
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 5/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.05184411764706s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 10485795
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 5/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.05287144259078s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 14680104
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 5/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.05390176817289s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 6291514
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 5/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.05493411996067s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 10485790
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 5/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.05596948818898s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 16
StateHashKey: 14680103
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 5/30
Current state: 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.05700591133005s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 2097209
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 5/30
Current state: 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.05804339250493s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 10485774
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 5/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.05908193484699s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 6291491
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 5/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.06012351778656s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 14680088
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 5/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.06116716122651s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 10485814
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 5/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.06221188118812s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 10
StateHashKey: 14680109
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 5/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.06325966303271s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 2097211
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 5/30
Current state: 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.06430853174603s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 8
StateHashKey: 10485774
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 5/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.06536146971202s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 6291491
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 5/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.06641550695825s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 14680088
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 5/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.06747164179104s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 5
StateHashKey: 14680118
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 5/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.06853087649402s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 2097213
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 5/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.06959122632104s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 14680079
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 5/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.07065269461078s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 10485811
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 5/30
Current state: 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.07171728271728s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8582 (in 2073 runs)
  Maximal search depth: 40
  Cache hits: 17902

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 2500
Accumulated number of search nodes in root state: 12708

Used RAM: 340876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 5 -- REWARD RECEIVED: -10
***********************************************

***********************************************
>>> STARTING ROUND 6 -- REMAINING TIME 1075s
***********************************************
***********************************************
Planning step 1/40 in round 6/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 1.072787s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0621302s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2524
Cache Hits: 0
Skipped backups: 90195
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8709 (in 2076 runs)
  Maximal search depth: 40
  Cache hits: 18328

Root Node: 
-19.9176 (in 503 real visits)

Q-Value Estimates: 
noop() : -20.8705 (in 176 real visits)
move-west : -19.9176 (in 315 real visits)
move-north : -31.52 (in 12 real visits)

Used RAM: 340876

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 6/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.07375575575576s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0493848s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2318
Cache Hits: 0
Skipped backups: 91587
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8709 (in 2076 runs)
  Maximal search depth: 40
  Cache hits: 18676

Root Node: 
-13.1607 (in 504 real visits)

Q-Value Estimates: 
noop() : -19.316 (in 27 real visits)
move-west : -17.3155 (in 74 real visits)
move-north : -13.1607 (in 383 real visits)
move-east : -20.5 (in 20 real visits)

Used RAM: 340904

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 6/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.07477755511022s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0476229s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2304
Cache Hits: 0
Skipped backups: 93138
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8792 (in 2077 runs)
  Maximal search depth: 40
  Cache hits: 19018

Root Node: 
-11.7986 (in 505 real visits)

Q-Value Estimates: 
noop() : -11.7986 (in 442 real visits)
move-west : -18.1001 (in 29 real visits)
move-south : -19.368 (in 20 real visits)
move-north : SOLVED with: -38 (in 5 real visits)
move-east : -30.6 (in 9 real visits)

Used RAM: 340904

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 6/30
Current state: 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.07580441323972s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0625141s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2437
Cache Hits: 0
Skipped backups: 94752
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8793 (in 2079 runs)
  Maximal search depth: 40
  Cache hits: 19408

Root Node: 
-17.6417 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -37 (in 5 real visits)
move-west : -18.0142 (in 258 real visits)
move-south : -17.6417 (in 226 real visits)
move-north : SOLVED with: -37 (in 5 real visits)
move-east : -29.18 (in 11 real visits)

Used RAM: 340904

Submitted action: move-south 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 6/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.07681726907631s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0491021s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2322
Cache Hits: 0
Skipped backups: 96162
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8793 (in 2079 runs)
  Maximal search depth: 40
  Cache hits: 19760

Root Node: 
-11.6937 (in 504 real visits)

Q-Value Estimates: 
noop() : -17.708 (in 26 real visits)
move-west : -16.2548 (in 39 real visits)
move-north : -11.6937 (in 421 real visits)
move-east : -18.92 (in 18 real visits)

Used RAM: 340904

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 6/30
Current state: 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.07784522613065s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0608211s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2438
Cache Hits: 0
Skipped backups: 97818
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8793 (in 2079 runs)
  Maximal search depth: 40
  Cache hits: 20153

Root Node: 
-15.0515 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -35 (in 5 real visits)
move-west : -15.0515 (in 275 real visits)
move-south : -17.12 (in 209 real visits)
move-north : SOLVED with: -35 (in 5 real visits)
move-east : -27.33 (in 11 real visits)

Used RAM: 340904

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 6/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.07886418511066s.
DP-UCT: Maximal search depth set to 34

Search time: 0.054518s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2298
Cache Hits: 0
Skipped backups: 99144
Initialization: 
  Statistics of IDS:
  Average search depth: 17.9553 (in 2101 runs)
  Maximal search depth: 40
  Cache hits: 20475

Root Node: 
-11.6748 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -34 (in 5 real visits)
move-west : -15.1408 (in 60 real visits)
move-south : -15.4632 (in 52 real visits)
move-north : SOLVED with: -34 (in 5 real visits)
move-east : -11.6748 (in 383 real visits)

Used RAM: 340904

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 6/30
Current state: 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.07989123867069s.
DP-UCT: Maximal search depth set to 33

Search time: 0.023026s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1878
Cache Hits: 0
Skipped backups: 100599
Initialization: 
  Statistics of IDS:
  Average search depth: 17.9252 (in 2126 runs)
  Maximal search depth: 40
  Cache hits: 20703

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -15.88 (in 10 real visits)
move-west : -13.307 (in 10 real visits)
move-south : -17 (in 10 real visits)
move-north : -3 (in 465 real visits)
move-east : -26.72 (in 10 real visits)

Used RAM: 340928

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 9/40 in round 6/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.08095262096774s.
DP-UCT: Maximal search depth set to 32

Search time: 0.0179691s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1765
Cache Hits: 0
Skipped backups: 101928
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8699 (in 2136 runs)
  Maximal search depth: 40
  Cache hits: 20923

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -9.39093 (in 10 real visits)
move-west : -11.73 (in 10 real visits)
move-south : -14.8 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -21.08 (in 10 real visits)

Used RAM: 340952

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 10/40 in round 6/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 1 

Setting time for this decision to 1.08202119071645s.
DP-UCT: Maximal search depth set to 31

Search time: 0.0173001s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1718
Cache Hits: 0
Skipped backups: 103401
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 484 real visits)
move-west : -8.6 (in 10 real visits)
move-south : SOLVED with: -31 (in 5 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 340960

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 11/40 in round 6/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.08309191919192s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 30
StateHashKey: 10485792
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 6/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.08418301314459s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 14680104
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 6/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.08527631578947s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 28
StateHashKey: 14680122
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 6/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.08637183383992s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 14680126
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 6/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.08746754563895s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 26
StateHashKey: 10485823
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 6/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.08856649746193s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 25
StateHashKey: 10485807
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 6/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.08966768292683s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 24
StateHashKey: 10485803
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 6/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.09077110885046s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 23
StateHashKey: 10485802
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 6/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.09187678207739s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 22
StateHashKey: 14680106
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 6/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.09298470948012s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 6291514
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 6/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.09409489795918s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 20
StateHashKey: 6291486
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 6/30
Current state: 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.09520735444331s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 14680087
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 6/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.09632208588957s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 14680117
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 6/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.09743909928352s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 17
StateHashKey: 6291517
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 6/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.09855840163934s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 16
StateHashKey: 10485791
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 6/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.09968s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 15
StateHashKey: 14680103
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 6/30
Current state: 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.10080390143737s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 10485817
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 6/30
Current state: 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.10193011305242s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 13
StateHashKey: 14680110
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 6/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.10305864197531s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 14680123
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 6/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.1041894953656s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 14680126
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 6/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.10532268041237s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 10
StateHashKey: 14680127
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 6/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.10645820433437s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 2097215
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 6/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.10759504132231s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 2097167
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 6/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.10873629782834s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 2097155
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 6/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.10987888198758s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 10485760
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 6/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.11102383419689s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 5
StateHashKey: 14680096
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 6/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.11217116182573s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 6291512
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 6/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.11332087227414s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 3
StateHashKey: 6291486
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 6/30
Current state: 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.11447193347193s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 10485783
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 6/30
Current state: 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.11562643080125s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8222 (in 2143 runs)
  Maximal search depth: 40
  Cache hits: 21139

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 3000
Accumulated number of search nodes in root state: 15232

Used RAM: 340968

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 6 -- REWARD RECEIVED: -10
***********************************************

***********************************************
>>> STARTING ROUND 7 -- REMAINING TIME 1075s
***********************************************
***********************************************
Planning step 1/40 in round 7/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 1.116784375s.
DP-UCT: Maximal search depth set to 40

Search time: 0.059731s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2541
Cache Hits: 0
Skipped backups: 105384
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8238 (in 2145 runs)
  Maximal search depth: 40
  Cache hits: 21568

Root Node: 
-19.6596 (in 503 real visits)

Q-Value Estimates: 
noop() : -20.9208 (in 155 real visits)
move-west : -19.6596 (in 336 real visits)
move-north : -31.64 (in 12 real visits)

Used RAM: 340968

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 7/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.11784462982273s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0629621s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2505
Cache Hits: 0
Skipped backups: 107070
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8217 (in 2148 runs)
  Maximal search depth: 40
  Cache hits: 21988

Root Node: 
-18.7428 (in 504 real visits)

Q-Value Estimates: 
noop() : -18.7428 (in 212 real visits)
move-west : -19.4184 (in 181 real visits)
move-north : SOLVED with: -39 (in 5 real visits)
move-east : -20.2387 (in 106 real visits)

Used RAM: 340996

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 7/30
Current state: 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.11894154488518s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0665991s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2504
Cache Hits: 0
Skipped backups: 108894
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8217 (in 2148 runs)
  Maximal search depth: 40
  Cache hits: 22416

Root Node: 
-17.8025 (in 504 real visits)

Q-Value Estimates: 
noop() : -18.7048 (in 150 real visits)
move-west : -17.8025 (in 268 real visits)
move-north : SOLVED with: -38 (in 5 real visits)
move-east : -20.0288 (in 81 real visits)

Used RAM: 341000

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 7/30
Current state: 1 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.12003761755486s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0791159s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2640
Cache Hits: 0
Skipped backups: 110514
Initialization: 
  Statistics of IDS:
  Average search depth: 17.971 (in 2205 runs)
  Maximal search depth: 40
  Cache hits: 22808

Root Node: 
-16.2393 (in 504 real visits)

Q-Value Estimates: 
noop() : -16.2393 (in 253 real visits)
move-west : -16.9471 (in 176 real visits)
move-north : SOLVED with: -37 (in 5 real visits)
move-east : -18.5504 (in 70 real visits)

Used RAM: 341000

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 7/30
Current state: 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.12112133891213s.
DP-UCT: Maximal search depth set to 36

Search time: 0.075196s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2627
Cache Hits: 0
Skipped backups: 111930
Initialization: 
  Statistics of IDS:
  Average search depth: 18.0419 (in 2220 runs)
  Maximal search depth: 40
  Cache hits: 23228

Root Node: 
-15.8879 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.8879 (in 204 real visits)
move-west : -16.4876 (in 135 real visits)
move-north : -16.6764 (in 112 real visits)
move-east : -18.4867 (in 53 real visits)

Used RAM: 341068

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 7/30
Current state: 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.12221256544503s.
DP-UCT: Maximal search depth set to 35

Search time: 0.050791s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2546
Cache Hits: 0
Skipped backups: 113277
Initialization: 
  Statistics of IDS:
  Average search depth: 17.9624 (in 2237 runs)
  Maximal search depth: 40
  Cache hits: 23612

Root Node: 
-9.7733 (in 504 real visits)

Q-Value Estimates: 
noop() : -16.9789 (in 28 real visits)
move-west : -15.7656 (in 43 real visits)
move-north : -9.7733 (in 412 real visits)
move-east : -17.864 (in 21 real visits)

Used RAM: 341088

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 7/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.12333123689727s.
DP-UCT: Maximal search depth set to 34

Search time: 0.024646s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1916
Cache Hits: 0
Skipped backups: 114648
Initialization: 
  Statistics of IDS:
  Average search depth: 17.9313 (in 2242 runs)
  Maximal search depth: 40
  Cache hits: 23870

Root Node: 
-4.28685 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -34 (in 5 real visits)
move-west : -14.2125 (in 21 real visits)
move-south : -15.448 (in 12 real visits)
move-north : -4.28685 (in 457 real visits)
move-east : -16.34 (in 10 real visits)

Used RAM: 341112

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 7/30
Current state: 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.1244795383001s.
DP-UCT: Maximal search depth set to 33

Search time: 0.020261s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1801
Cache Hits: 0
Skipped backups: 115968
Initialization: 
  Statistics of IDS:
  Average search depth: 17.8374 (in 2257 runs)
  Maximal search depth: 40
  Cache hits: 24094

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -33 (in 5 real visits)
move-west : -13.625 (in 10 real visits)
move-south : -13.667 (in 10 real visits)
move-north : -3 (in 470 real visits)
move-east : -10.44 (in 10 real visits)

Used RAM: 341112

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 9/40 in round 7/30
Current state: 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.12563550420168s.
DP-UCT: Maximal search depth set to 32

Search time: 0.0179429s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1759
Cache Hits: 0
Skipped backups: 117387
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7876 (in 2265 runs)
  Maximal search depth: 40
  Cache hits: 24318

Root Node: 
-2 (in 504 real visits)

Q-Value Estimates: 
noop() : -9.29733 (in 10 real visits)
move-west : -12.15 (in 10 real visits)
move-south : -12.25 (in 10 real visits)
move-east : -2 (in 474 real visits)

Used RAM: 341128

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 10/40 in round 7/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 1 1 

Setting time for this decision to 1.12679495268139s.
DP-UCT: Maximal search depth set to 31

Search time: 0.0171211s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1725
Cache Hits: 0
Skipped backups: 118800
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 43 real visits)
move-west : -3 (in 451 real visits)
move-south : SOLVED with: -31 (in 5 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 341140

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 11/40 in round 7/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.12795894736842s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 30
StateHashKey: 10485808
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 7/30
Current state: 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.12914330874605s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 14680108
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 7/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.13033122362869s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 28
StateHashKey: 10485819
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 7/30
Current state: 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.13151847940866s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 10485806
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 7/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.13270930232558s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 26
StateHashKey: 14680107
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 7/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.13390264550265s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 25
StateHashKey: 10485818
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 7/30
Current state: 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.13509851694915s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 24
StateHashKey: 14680110
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 7/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.13629798515376s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 2097211
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 7/30
Current state: 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.13749893842887s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 22
StateHashKey: 14680078
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 7/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.13870244420829s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 6291507
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 7/30
Current state: 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.1399085106383s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 14680092
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 7/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.14111714589989s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 14680119
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 7/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.14232942430704s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 6291517
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 7/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.14354322305229s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 14680095
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 7/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.14475961538462s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 16
StateHashKey: 14680119
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 7/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.14597860962567s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 15
StateHashKey: 14680125
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 7/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.14719914346895s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 10485823
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 7/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.14842336548767s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 13
StateHashKey: 10485807
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 7/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.14965021459227s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 2097195
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 7/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.15087969924812s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 2097162
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 7/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.15211290322581s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 2097154
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 7/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.15334768568353s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 9
StateHashKey: 14680064
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 7/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.15458512931034s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 2097200
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 7/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.15582524271845s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 2097164
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 7/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.15706803455724s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 14680067
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 7/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.15831351351351s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 5
StateHashKey: 14680112
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 7/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.15956168831169s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 6291516
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 7/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.16081365113759s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 10485791
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 7/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.162068329718s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 6291495
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 7/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.16332464712269s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24541

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 3500
Accumulated number of search nodes in root state: 17773

Used RAM: 341144

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 7 -- REWARD RECEIVED: -10
***********************************************

***********************************************
>>> STARTING ROUND 8 -- REMAINING TIME 1074s
***********************************************
***********************************************
Planning step 1/40 in round 8/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 1.16458369565217s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0639029s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2571
Cache Hits: 0
Skipped backups: 120822
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7625 (in 2269 runs)
  Maximal search depth: 40
  Cache hits: 24977

Root Node: 
-18.5495 (in 503 real visits)

Q-Value Estimates: 
noop() : -20.1612 (in 121 real visits)
move-west : -18.5495 (in 373 real visits)
move-north : -32.32 (in 9 real visits)

Used RAM: 341144

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 8/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.16573558215452s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0517011s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2345
Cache Hits: 0
Skipped backups: 122334
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7781 (in 2276 runs)
  Maximal search depth: 40
  Cache hits: 25325

Root Node: 
-12.6334 (in 504 real visits)

Q-Value Estimates: 
noop() : -19.8867 (in 23 real visits)
move-west : -17.5173 (in 43 real visits)
move-north : -12.6334 (in 418 real visits)
move-east : -20.38 (in 20 real visits)

Used RAM: 341164

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 8/30
Current state: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.16694444444444s.
DP-UCT: Maximal search depth set to 38

Search time: 0.060946s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2436
Cache Hits: 0
Skipped backups: 123924
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7861 (in 2277 runs)
  Maximal search depth: 40
  Cache hits: 25714

Root Node: 
-18.4464 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -38 (in 5 real visits)
move-west : -18.6036 (in 229 real visits)
move-south : -18.4464 (in 256 real visits)
move-north : SOLVED with: -38 (in 5 real visits)
move-east : -30.72 (in 10 real visits)

Used RAM: 341168

Submitted action: move-south 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 8/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.16814503816794s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0507779s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2367
Cache Hits: 0
Skipped backups: 125337
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7745 (in 2279 runs)
  Maximal search depth: 40
  Cache hits: 26074

Root Node: 
-12.4898 (in 504 real visits)

Q-Value Estimates: 
noop() : -19 (in 28 real visits)
move-west : -16.5619 (in 66 real visits)
move-north : -12.4898 (in 385 real visits)
move-east : -19.42 (in 25 real visits)

Used RAM: 341172

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 8/30
Current state: 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.16936026200873s.
DP-UCT: Maximal search depth set to 36

Search time: 0.060709s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2425
Cache Hits: 0
Skipped backups: 126930
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7745 (in 2279 runs)
  Maximal search depth: 40
  Cache hits: 26465

Root Node: 
-17.7096 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -36 (in 5 real visits)
move-west : -17.7096 (in 270 real visits)
move-south : -17.9682 (in 215 real visits)
move-north : SOLVED with: -36 (in 5 real visits)
move-east : -29.12 (in 10 real visits)

Used RAM: 341172

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 8/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.17056721311475s.
DP-UCT: Maximal search depth set to 35

Search time: 0.072957s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2363
Cache Hits: 0
Skipped backups: 128730
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7803 (in 2280 runs)
  Maximal search depth: 40
  Cache hits: 26867

Root Node: 
-17.0526 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -35 (in 5 real visits)
move-west : -17.0526 (in 243 real visits)
move-south : -17.409 (in 247 real visits)
move-north : SOLVED with: -35 (in 5 real visits)
move-east : SOLVED with: -35 (in 5 real visits)

Used RAM: 341180

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 8/30
Current state: 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.1717636761488s.
DP-UCT: Maximal search depth set to 34

Search time: 0.076304s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2491
Cache Hits: 0
Skipped backups: 130752
Initialization: 
  Statistics of IDS:
  Average search depth: 17.7549 (in 2289 runs)
  Maximal search depth: 40
  Cache hits: 27286

Root Node: 
-15.6566 (in 504 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -34 (in 5 real visits)
move-south : -15.6566 (in 489 real visits)
move-north : SOLVED with: -34 (in 5 real visits)
move-east : SOLVED with: -34 (in 5 real visits)

Used RAM: 341180

Submitted action: move-south 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 8/30
Current state: 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.17295947426068s.
DP-UCT: Maximal search depth set to 33

Search time: 0.0792651s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2603
Cache Hits: 0
Skipped backups: 132435
Initialization: 
  Statistics of IDS:
  Average search depth: 17.6056 (in 2340 runs)
  Maximal search depth: 40
  Cache hits: 27678

Root Node: 
-14.7462 (in 503 real visits)

Q-Value Estimates: 
noop() : -14.7462 (in 286 real visits)
move-north : SOLVED with: -33 (in 5 real visits)
move-east : -15.1868 (in 212 real visits)

Used RAM: 341192

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 9/40 in round 8/30
Current state: 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.17415460526316s.
DP-UCT: Maximal search depth set to 32

Search time: 0.056299s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2344
Cache Hits: 0
Skipped backups: 133809
Initialization: 
  Statistics of IDS:
  Average search depth: 17.3999 (in 2378 runs)
  Maximal search depth: 40
  Cache hits: 28030

Root Node: 
-12.9885 (in 503 real visits)

Q-Value Estimates: 
noop() : -15.3365 (in 70 real visits)
move-north : -12.9885 (in 373 real visits)
move-east : -16.1578 (in 60 real visits)

Used RAM: 341260

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 10/40 in round 8/30
Current state: 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.17537650933041s.
DP-UCT: Maximal search depth set to 31

Search time: 0.041539s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2477
Cache Hits: 0
Skipped backups: 135393
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1782 (in 2418 runs)
  Maximal search depth: 40
  Cache hits: 28394

Root Node: 
-9.01761 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.3265 (in 26 real visits)
move-south : -16.0045 (in 22 real visits)
move-north : -9.01761 (in 451 real visits)
move-east : SOLVED with: -31 (in 5 real visits)

Used RAM: 341296

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 11/40 in round 8/30
Current state: 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.17661758241758s.
DP-UCT: Maximal search depth set to 30

Search time: 0.0208611s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1859
Cache Hits: 0
Skipped backups: 136752
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1386 (in 2425 runs)
  Maximal search depth: 40
  Cache hits: 28643

Root Node: 
-4.31795 (in 504 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -30 (in 5 real visits)
move-south : SOLVED with: -30 (in 5 real visits)
move-north : -10.5845 (in 44 real visits)
move-east : -4.31795 (in 450 real visits)

Used RAM: 341348

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 12/40 in round 8/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.17788448844884s.
DP-UCT: Maximal search depth set to 29

Search time: 0.0188138s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1810
Cache Hits: 0
Skipped backups: 138219
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 28878

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -29 (in 5 real visits)
move-west : -12.155 (in 10 real visits)
move-south : SOLVED with: -29 (in 5 real visits)
move-north : -8.75 (in 14 real visits)
move-east : -3 (in 471 real visits)

Used RAM: 341348

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 13/40 in round 8/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.17915748898678s.
DP-UCT: Maximal search depth set to 28

Search time: 0.0183282s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1735
Cache Hits: 0
Skipped backups: 139716
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29103

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -28 (in 5 real visits)
move-west : -10.7767 (in 10 real visits)
move-south : SOLVED with: -28 (in 5 real visits)
move-north : -2 (in 475 real visits)
move-east : -18.52 (in 10 real visits)

Used RAM: 341348

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 14/40 in round 8/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 1 1 

Setting time for this decision to 1.18043219404631s.
DP-UCT: Maximal search depth set to 27

Search time: 0.016803s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1791
Cache Hits: 0
Skipped backups: 141354
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 484 real visits)
move-west : -8.47667 (in 10 real visits)
move-south : SOLVED with: -27 (in 5 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 341348

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 15/40 in round 8/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.1817119205298s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 26
StateHashKey: 14680124
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

Used RAM: 341348

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 8/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.18301325966851s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 25
StateHashKey: 14680127
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

Used RAM: 341348

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 8/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.18431747787611s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 24
StateHashKey: 14680127
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

Used RAM: 341348

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 8/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.18562458471761s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 2097215
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

Used RAM: 341348

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 8/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.18693458980044s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 22
StateHashKey: 14680079
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

Used RAM: 341348

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 8/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.18824528301887s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 21
StateHashKey: 14680115
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

Used RAM: 341348

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 8/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.18956s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 14680124
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

Used RAM: 341348

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 8/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.19087764182425s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 14680127
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

Used RAM: 341348

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 8/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.19219821826281s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 14680127
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

Used RAM: 341348

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 8/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.19352173913043s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 17
StateHashKey: 6291519
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

Used RAM: 341348

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 8/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.19484933035714s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 2097183
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

Used RAM: 341348

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 8/30
Current state: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.19617877094972s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 6291463
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

Used RAM: 341348

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 8/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.19751006711409s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 10485777
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

Used RAM: 341348

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 8/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.19884546472564s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 6291492
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

Used RAM: 341348

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 8/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.20018497757848s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 6291481
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

Used RAM: 341348

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 8/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.20152749719416s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 2097174
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

Used RAM: 341348

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 8/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.20287078651685s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 10
StateHashKey: 14680069
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

Used RAM: 341348

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 8/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.20421822272216s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 6291505
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

Used RAM: 341348

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 8/30
Current state: 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.20556869369369s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 8
StateHashKey: 10485788
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

Used RAM: 341348

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 8/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.2069222096956s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 7
StateHashKey: 14680103
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

Used RAM: 341348

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 8/30
Current state: 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.20827990970655s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 10485817
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

Used RAM: 341348

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 8/30
Current state: 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.2096395480226s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 2097198
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

Used RAM: 341348

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 8/30
Current state: 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.21100226244344s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 4
StateHashKey: 10485771
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

Used RAM: 341348

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 8/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.21236806342016s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 14680098
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

Used RAM: 341348

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 8/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.2137380952381s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 2097208
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

Used RAM: 341348

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 8/30
Current state: 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.21511010215664s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29344

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 4000
Accumulated number of search nodes in root state: 20344

Used RAM: 341348

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 8 -- REWARD RECEIVED: -14
***********************************************

***********************************************
>>> STARTING ROUND 9 -- REMAINING TIME 1073s
***********************************************
***********************************************
Planning step 1/40 in round 9/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 1.21648522727273s.
DP-UCT: Maximal search depth set to 40

Search time: 0.059999s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2527
Cache Hits: 0
Skipped backups: 143229
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 29765

Root Node: 
-19.7044 (in 503 real visits)

Q-Value Estimates: 
noop() : -20.7072 (in 172 real visits)
move-west : -19.7044 (in 320 real visits)
move-north : -32.32 (in 11 real visits)

Used RAM: 341348

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 9/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.21774971558589s.
DP-UCT: Maximal search depth set to 39

Search time: 0.06531s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2503
Cache Hits: 0
Skipped backups: 144960
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1145 (in 2429 runs)
  Maximal search depth: 40
  Cache hits: 30192

Root Node: 
-17.8117 (in 504 real visits)

Q-Value Estimates: 
noop() : -19.545 (in 160 real visits)
move-west : -17.8117 (in 240 real visits)
move-north : SOLVED with: -39 (in 5 real visits)
move-east : -20.5725 (in 99 real visits)

Used RAM: 341368

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 9/30
Current state: 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.21905808656036s.
DP-UCT: Maximal search depth set to 38

Search time: 0.070817s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2514
Cache Hits: 0
Skipped backups: 146664
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1218 (in 2430 runs)
  Maximal search depth: 40
  Cache hits: 30621

Root Node: 
-18.0417 (in 504 real visits)

Q-Value Estimates: 
noop() : -18.0417 (in 142 real visits)
move-west : -18.6364 (in 163 real visits)
move-north : -38 (in 4 real visits)
move-east : -18.3383 (in 195 real visits)

Used RAM: 341368

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 9/30
Current state: 1 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.22036259977195s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0719421s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2525
Cache Hits: 0
Skipped backups: 148296
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1218 (in 2430 runs)
  Maximal search depth: 40
  Cache hits: 31057

Root Node: 
-17.1725 (in 504 real visits)

Q-Value Estimates: 
noop() : -17.1725 (in 194 real visits)
move-west : -18.2137 (in 170 real visits)
move-north : -37 (in 4 real visits)
move-east : -18.2872 (in 136 real visits)

Used RAM: 341372

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 9/30
Current state: 1 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.22166894977169s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0702479s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2503
Cache Hits: 0
Skipped backups: 149985
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1218 (in 2430 runs)
  Maximal search depth: 40
  Cache hits: 31489

Root Node: 
-17.0061 (in 504 real visits)

Q-Value Estimates: 
noop() : -17.6268 (in 176 real visits)
move-west : -17.0061 (in 198 real visits)
move-north : -36 (in 4 real visits)
move-east : -18.0344 (in 126 real visits)

Used RAM: 341376

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 9/30
Current state: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.22298057142857s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0725539s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2483
Cache Hits: 0
Skipped backups: 151857
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1218 (in 2430 runs)
  Maximal search depth: 40
  Cache hits: 31914

Root Node: 
-17.382 (in 503 real visits)

Q-Value Estimates: 
noop() : -17.382 (in 265 real visits)
move-north : SOLVED with: -35 (in 5 real visits)
move-east : -17.5533 (in 233 real visits)

Used RAM: 341376

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 9/30
Current state: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.22429176201373s.
DP-UCT: Maximal search depth set to 34

Search time: 0.0734329s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2490
Cache Hits: 0
Skipped backups: 153711
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1218 (in 2430 runs)
  Maximal search depth: 40
  Cache hits: 32343

Root Node: 
-16.1428 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.9081 (in 250 real visits)
move-north : SOLVED with: -34 (in 5 real visits)
move-east : -16.1428 (in 248 real visits)

Used RAM: 341376

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 9/30
Current state: 1 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.22560595647194s.
DP-UCT: Maximal search depth set to 33

Search time: 0.0676231s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2516
Cache Hits: 0
Skipped backups: 155373
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1267 (in 2431 runs)
  Maximal search depth: 40
  Cache hits: 32771

Root Node: 
-15.0647 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.1758 (in 86 real visits)
move-west : -16.2381 (in 126 real visits)
move-north : SOLVED with: -33 (in 5 real visits)
move-east : -15.0647 (in 287 real visits)

Used RAM: 341376

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 9/40 in round 9/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.22692889908257s.
DP-UCT: Maximal search depth set to 32

Search time: 0.0617249s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2505
Cache Hits: 0
Skipped backups: 157035
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1267 (in 2431 runs)
  Maximal search depth: 40
  Cache hits: 33196

Root Node: 
-15.8064 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.8064 (in 225 real visits)
move-west : -16.4776 (in 156 real visits)
move-north : SOLVED with: -32 (in 5 real visits)
move-east : -16.8204 (in 118 real visits)

Used RAM: 341376

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 10/40 in round 9/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.22826176808266s.
DP-UCT: Maximal search depth set to 31

Search time: 0.0614281s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2503
Cache Hits: 0
Skipped backups: 158745
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1267 (in 2431 runs)
  Maximal search depth: 40
  Cache hits: 33619

Root Node: 
-15.2642 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.2642 (in 184 real visits)
move-west : -15.6852 (in 190 real visits)
move-north : SOLVED with: -31 (in 5 real visits)
move-east : -16.344 (in 125 real visits)

Used RAM: 341376

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 11/40 in round 9/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.22959885057471s.
DP-UCT: Maximal search depth set to 30

Search time: 0.048167s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2319
Cache Hits: 0
Skipped backups: 160203
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1308 (in 2432 runs)
  Maximal search depth: 40
  Cache hits: 33969

Root Node: 
-10.611 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.656 (in 26 real visits)
move-west : -13.833 (in 48 real visits)
move-north : -10.611 (in 408 real visits)
move-east : -15.88 (in 22 real visits)

Used RAM: 341376

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 12/40 in round 9/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.23095397008055s.
DP-UCT: Maximal search depth set to 29

Search time: 0.0604031s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2419
Cache Hits: 0
Skipped backups: 161817
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1308 (in 2432 runs)
  Maximal search depth: 40
  Cache hits: 34359

Root Node: 
-13.9969 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -29 (in 5 real visits)
move-west : -13.9969 (in 311 real visits)
move-south : -15.0179 (in 172 real visits)
move-north : SOLVED with: -29 (in 5 real visits)
move-east : -22.94 (in 12 real visits)

Used RAM: 341376

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 13/40 in round 9/30
Current state: 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.23229723502304s.
DP-UCT: Maximal search depth set to 28

Search time: 0.0471811s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2229
Cache Hits: 0
Skipped backups: 163134
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1245 (in 2433 runs)
  Maximal search depth: 40
  Cache hits: 34686

Root Node: 
-9.76951 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -28 (in 5 real visits)
move-west : -13.1288 (in 36 real visits)
move-south : -12.8793 (in 39 real visits)
move-north : SOLVED with: -28 (in 5 real visits)
move-east : -9.76951 (in 420 real visits)

Used RAM: 341376

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 14/40 in round 9/30
Current state: 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.23365974625144s.
DP-UCT: Maximal search depth set to 27

Search time: 0.020874s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1916
Cache Hits: 0
Skipped backups: 164730
Initialization: 
  Statistics of IDS:
  Average search depth: 17.103 (in 2438 runs)
  Maximal search depth: 40
  Cache hits: 34944

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -27 (in 5 real visits)
move-west : -11.379 (in 10 real visits)
move-south : -13.58 (in 10 real visits)
move-north : -3 (in 470 real visits)
move-east : -21.92 (in 10 real visits)

Used RAM: 341376

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 15/40 in round 9/30
Current state: 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.23505542725173s.
DP-UCT: Maximal search depth set to 26

Search time: 0.016109s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1692
Cache Hits: 0
Skipped backups: 166068
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0968 (in 2439 runs)
  Maximal search depth: 40
  Cache hits: 35158

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -8.21333 (in 10 real visits)
move-west : -10 (in 10 real visits)
move-south : SOLVED with: -26 (in 5 real visits)
move-north : -2 (in 470 real visits)
move-east : -16.4 (in 10 real visits)

Used RAM: 341376

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 16/40 in round 9/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 1 0 

Setting time for this decision to 1.23645895953757s.
DP-UCT: Maximal search depth set to 25

Search time: 0.017911s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1857
Cache Hits: 0
Skipped backups: 167628
Initialization: 
  Statistics of IDS:
  Average search depth: 17.086 (in 2441 runs)
  Maximal search depth: 40
  Cache hits: 35412

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -3.8 (in 10 real visits)
move-west : -3 (in 479 real visits)
move-south : -8.05 (in 10 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 341376

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 17/40 in round 9/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.23786458333333s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 24
StateHashKey: 14680085
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.086 (in 2441 runs)
  Maximal search depth: 40
  Cache hits: 35412

Used RAM: 341376

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 9/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.2392943221321s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 6291509
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.086 (in 2441 runs)
  Maximal search depth: 40
  Cache hits: 35412

Used RAM: 341376

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 9/30
Current state: 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.24072853828306s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 2097181
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.086 (in 2441 runs)
  Maximal search depth: 40
  Cache hits: 35412

Used RAM: 341376

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 9/30
Current state: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.2421637630662s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 21
StateHashKey: 14680071
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.086 (in 2441 runs)
  Maximal search depth: 40
  Cache hits: 35412

Used RAM: 341376

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 9/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.2436023255814s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 14680113
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.086 (in 2441 runs)
  Maximal search depth: 40
  Cache hits: 35412

Used RAM: 341376

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 9/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.24504423748545s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 2097212
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.086 (in 2441 runs)
  Maximal search depth: 40
  Cache hits: 35412

Used RAM: 341376

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 9/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.24649067599068s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 14680079
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.086 (in 2441 runs)
  Maximal search depth: 40
  Cache hits: 35412

Used RAM: 341376

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 9/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.24793932322054s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 10485811
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.086 (in 2441 runs)
  Maximal search depth: 40
  Cache hits: 35412

Used RAM: 341376

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 9/30
Current state: 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.24939135514019s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 6291500
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.086 (in 2441 runs)
  Maximal search depth: 40
  Cache hits: 35412

Used RAM: 341376

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 9/30
Current state: 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.25084678362573s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 15
StateHashKey: 14680091
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.086 (in 2441 runs)
  Maximal search depth: 40
  Cache hits: 35412

Used RAM: 341376

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 9/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.2523056206089s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 14680118
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.086 (in 2441 runs)
  Maximal search depth: 40
  Cache hits: 35412

Used RAM: 341376

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 9/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.25376787807737s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 13
StateHashKey: 10485821
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.086 (in 2441 runs)
  Maximal search depth: 40
  Cache hits: 35412

Used RAM: 341376

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 9/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.25523474178404s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 2097199
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.086 (in 2441 runs)
  Maximal search depth: 40
  Cache hits: 35412

Used RAM: 341376

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 9/30
Current state: 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.2567027027027s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 10485771
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.086 (in 2441 runs)
  Maximal search depth: 40
  Cache hits: 35412

Used RAM: 341376

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 9/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.25817647058824s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 10
StateHashKey: 14680098
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.086 (in 2441 runs)
  Maximal search depth: 40
  Cache hits: 35412

Used RAM: 341376

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 9/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.25965253239105s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 6291512
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.086 (in 2441 runs)
  Maximal search depth: 40
  Cache hits: 35412

Used RAM: 341376

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 9/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.26113325471698s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 8
StateHashKey: 14680094
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.086 (in 2441 runs)
  Maximal search depth: 40
  Cache hits: 35412

Used RAM: 341376

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 9/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.26261629279811s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 7
StateHashKey: 14680119
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.086 (in 2441 runs)
  Maximal search depth: 40
  Cache hits: 35412

Used RAM: 341376

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 9/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.26410283687943s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 14680125
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.086 (in 2441 runs)
  Maximal search depth: 40
  Cache hits: 35412

Used RAM: 341376

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 9/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.26559289940828s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 2097215
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.086 (in 2441 runs)
  Maximal search depth: 40
  Cache hits: 35412

Used RAM: 341376

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 9/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.26708767772512s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 4
StateHashKey: 14680079
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.086 (in 2441 runs)
  Maximal search depth: 40
  Cache hits: 35412

Used RAM: 341376

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 9/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.26858481613286s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 14680115
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.086 (in 2441 runs)
  Maximal search depth: 40
  Cache hits: 35412

Used RAM: 341376

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 9/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.27008669833729s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 14680124
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.086 (in 2441 runs)
  Maximal search depth: 40
  Cache hits: 35412

Used RAM: 341376

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 9/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.27159096313912s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.086 (in 2441 runs)
  Maximal search depth: 40
  Cache hits: 35412

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 4500
Accumulated number of search nodes in root state: 22871

Used RAM: 341376

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 9 -- REWARD RECEIVED: -16
***********************************************

***********************************************
>>> STARTING ROUND 10 -- REMAINING TIME 1072s
***********************************************
***********************************************
Planning step 1/40 in round 10/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 1.27309880952381s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0617101s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2591
Cache Hits: 0
Skipped backups: 169599
Initialization: 
  Statistics of IDS:
  Average search depth: 17.086 (in 2441 runs)
  Maximal search depth: 40
  Cache hits: 35855

Root Node: 
-18.6664 (in 503 real visits)

Q-Value Estimates: 
noop() : -20.8704 (in 101 real visits)
move-west : -18.6664 (in 393 real visits)
move-north : -32.2 (in 9 real visits)

Used RAM: 341376

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 10/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.27449106078665s.
DP-UCT: Maximal search depth set to 39

Search time: 0.050061s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2383
Cache Hits: 0
Skipped backups: 171024
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2446 runs)
  Maximal search depth: 40
  Cache hits: 36213

Root Node: 
-12.6894 (in 504 real visits)

Q-Value Estimates: 
noop() : -20.004 (in 25 real visits)
move-west : -16.5311 (in 81 real visits)
move-north : -12.6894 (in 376 real visits)
move-east : -20.5 (in 22 real visits)

Used RAM: 341388

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 10/30
Current state: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.27594868735084s.
DP-UCT: Maximal search depth set to 38

Search time: 0.061743s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2401
Cache Hits: 0
Skipped backups: 172698
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2446 runs)
  Maximal search depth: 40
  Cache hits: 36595

Root Node: 
-17.8289 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -38 (in 5 real visits)
move-west : -17.8289 (in 319 real visits)
move-south : -18.6635 (in 167 real visits)
move-north : SOLVED with: -38 (in 5 real visits)
move-east : -30.6 (in 9 real visits)

Used RAM: 341388

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 10/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.27739426523298s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0549109s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2356
Cache Hits: 0
Skipped backups: 174093
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1193 (in 2447 runs)
  Maximal search depth: 40
  Cache hits: 36949

Root Node: 
-12.4398 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -37 (in 5 real visits)
move-west : -17.142 (in 59 real visits)
move-south : -17.0536 (in 60 real visits)
move-north : SOLVED with: -37 (in 5 real visits)
move-east : -12.4398 (in 376 real visits)

Used RAM: 341392

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 10/30
Current state: 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.27885167464115s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0467479s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2323
Cache Hits: 0
Skipped backups: 175593
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1193 (in 2447 runs)
  Maximal search depth: 40
  Cache hits: 37293

Root Node: 
-12.0741 (in 505 real visits)

Q-Value Estimates: 
noop() : -12.0741 (in 436 real visits)
move-west : -17.232 (in 31 real visits)
move-south : -18.048 (in 24 real visits)
move-north : SOLVED with: -36 (in 5 real visits)
move-east : -25.8 (in 9 real visits)

Used RAM: 341392

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 10/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.28032215568862s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0612571s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2424
Cache Hits: 0
Skipped backups: 177249
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1193 (in 2447 runs)
  Maximal search depth: 40
  Cache hits: 37684

Root Node: 
-17.0068 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -35 (in 5 real visits)
move-west : -17.0068 (in 307 real visits)
move-south : -17.988 (in 177 real visits)
move-north : SOLVED with: -35 (in 5 real visits)
move-east : -28.32 (in 11 real visits)

Used RAM: 341392

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 10/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.2817793764988s.
DP-UCT: Maximal search depth set to 34

Search time: 0.0575278s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2386
Cache Hits: 0
Skipped backups: 178632
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1063 (in 2456 runs)
  Maximal search depth: 40
  Cache hits: 38040

Root Node: 
-11.6477 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -34 (in 5 real visits)
move-west : -15.6608 (in 79 real visits)
move-south : -14.8244 (in 107 real visits)
move-north : SOLVED with: -34 (in 5 real visits)
move-east : -11.6477 (in 309 real visits)

Used RAM: 341392

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 10/30
Current state: 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.28324369747899s.
DP-UCT: Maximal search depth set to 33

Search time: 0.0219779s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1938
Cache Hits: 0
Skipped backups: 180210
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1234 (in 2463 runs)
  Maximal search depth: 40
  Cache hits: 38302

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -15.4 (in 10 real visits)
move-west : -13.653 (in 10 real visits)
move-south : -17 (in 10 real visits)
move-north : -3 (in 465 real visits)
move-east : -26.8 (in 10 real visits)

Used RAM: 341400

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 9/40 in round 10/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.28475480769231s.
DP-UCT: Maximal search depth set to 32

Search time: 0.0180309s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1784
Cache Hits: 0
Skipped backups: 181608
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1177 (in 2464 runs)
  Maximal search depth: 40
  Cache hits: 38537

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -32 (in 5 real visits)
move-west : -12.25 (in 10 real visits)
move-south : -14.556 (in 10 real visits)
move-north : -2 (in 470 real visits)
move-east : -20 (in 10 real visits)

Used RAM: 341404

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 10/40 in round 10/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 1 1 

Setting time for this decision to 1.28627436823105s.
DP-UCT: Maximal search depth set to 31

Search time: 0.0171418s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1816
Cache Hits: 0
Skipped backups: 183171
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -4.6 (in 10 real visits)
move-west : -3 (in 484 real visits)
move-south : SOLVED with: -31 (in 5 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 341404

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 11/40 in round 10/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.28779879518072s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 2097208
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 10/30
Current state: 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.28934740651387s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 29
StateHashKey: 6291470
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 10/30
Current state: 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.29090096618357s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 28
StateHashKey: 14680083
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 10/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.29245465538089s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 27
StateHashKey: 2097204
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 10/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.29401331719128s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 26
StateHashKey: 14680077
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 10/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.29557575757576s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 25
StateHashKey: 14680115
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 10/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.2971432038835s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 24
StateHashKey: 10485820
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 10/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.29871324422843s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 2097199
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 10/30
Current state: 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.30028832116788s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 2097163
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 10/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.30186601705238s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 6291458
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 10/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.3034487804878s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 20
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 10/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.30503418803419s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 14680068
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 10/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.30662469437653s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 14680113
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 10/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.30821787025704s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 10485820
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 10/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.30981495098039s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 16
StateHashKey: 14680111
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 10/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.31141595092025s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 15
StateHashKey: 10485819
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 10/30
Current state: 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.31302211302211s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 6291502
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 10/30
Current state: 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.31463099630996s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 13
StateHashKey: 14680091
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 10/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.31624384236453s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 14680118
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 10/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.31786066584464s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 6291517
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 10/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.31948271604938s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 6291487
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 10/30
Current state: 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.32110754017305s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 9
StateHashKey: 14680087
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 10/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.32273638613861s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 8
StateHashKey: 14680117
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 10/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.32436926889715s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 7
StateHashKey: 10485821
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 10/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.32600744416873s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 10485807
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 10/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.32764844720497s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 5
StateHashKey: 14680107
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 10/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.32929353233831s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 4
StateHashKey: 14680122
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 10/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.33094271481943s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 10485822
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 10/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.33259725685786s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 14680111
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 10/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.33425468164794s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 38781

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 5000
Accumulated number of search nodes in root state: 25462

Used RAM: 341404

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 10 -- REWARD RECEIVED: -10
***********************************************

***********************************************
>>> STARTING ROUND 11 -- REMAINING TIME 1071s
***********************************************
***********************************************
Planning step 1/40 in round 11/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 1.3359175s.
DP-UCT: Maximal search depth set to 40

Search time: 0.058023s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2563
Cache Hits: 0
Skipped backups: 185115
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1124 (in 2465 runs)
  Maximal search depth: 40
  Cache hits: 39214

Root Node: 
-19.6876 (in 503 real visits)

Q-Value Estimates: 
noop() : -20.4797 (in 187 real visits)
move-west : -19.6876 (in 304 real visits)
move-north : -31.26 (in 12 real visits)

Used RAM: 341404

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 11/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.33746558197747s.
DP-UCT: Maximal search depth set to 39

Search time: 0.048712s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2299
Cache Hits: 0
Skipped backups: 186579
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1224 (in 2468 runs)
  Maximal search depth: 40
  Cache hits: 39558

Root Node: 
-13.096 (in 504 real visits)

Q-Value Estimates: 
noop() : -19.556 (in 22 real visits)
move-west : -17.5461 (in 40 real visits)
move-north : -13.096 (in 424 real visits)
move-east : -20.3 (in 18 real visits)

Used RAM: 341424

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 11/30
Current state: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.33907644110276s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0200961s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1877
Cache Hits: 0
Skipped backups: 188031
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1529 (in 2472 runs)
  Maximal search depth: 40
  Cache hits: 39804

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -17.3 (in 10 real visits)
move-west : -15.608 (in 10 real visits)
move-south : -19.5 (in 10 real visits)
move-north : -3 (in 465 real visits)
move-east : -27.408 (in 10 real visits)

Used RAM: 341424

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 11/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.3407252195734s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0160229s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1692
Cache Hits: 0
Skipped backups: 189378
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1476 (in 2473 runs)
  Maximal search depth: 40
  Cache hits: 40018

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -37 (in 5 real visits)
move-west : -14 (in 10 real visits)
move-south : -18.1 (in 10 real visits)
move-north : -2 (in 470 real visits)
move-east : -23 (in 10 real visits)

Used RAM: 341424

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 11/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 1 

Setting time for this decision to 1.34238442211055s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0162709s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1761
Cache Hits: 0
Skipped backups: 190848
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -6.03 (in 10 real visits)
move-west : -3 (in 484 real visits)
move-south : SOLVED with: -36 (in 5 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 341424

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 11/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.34404779874214s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 35
StateHashKey: 6291496
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 11/30
Current state: 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.3457355163728s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 34
StateHashKey: 14680090
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 11/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.34742749054224s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 33
StateHashKey: 10485814
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 11/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.34912373737374s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 32
StateHashKey: 2097197
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 11/30
Current state: 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.35082300884956s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 31
StateHashKey: 6291467
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 11/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.3525253164557s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 30
StateHashKey: 14680082
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 11/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.35423447401774s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 29
StateHashKey: 6291508
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 11/30
Current state: 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.35594670050761s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 6291485
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 11/30
Current state: 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.35766200762389s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 27
StateHashKey: 2097175
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 11/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.35938295165394s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 2097157
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 11/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.36110828025478s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 11/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.36283928571429s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 11/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.36457471264368s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 6291472
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 11/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.36631329923274s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 2097172
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 11/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.36805633802817s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 21
StateHashKey: 14680069
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 11/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.36980384615385s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 10485809
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 11/30
Current state: 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.37155712451861s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 14680108
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 11/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.37331491002571s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 14680123
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 11/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.37507593307593s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 14680126
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 11/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.37684149484536s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 6291519
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 11/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.37861161290323s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 6291487
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 11/30
Current state: 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.38038759689922s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 6291479
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 11/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.38216688227684s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 2097173
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 11/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.38395207253886s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 14680069
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 11/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.38574059662776s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 10485809
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 11/30
Current state: 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.38753376623377s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 10
StateHashKey: 14680108
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 11/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.38933159947984s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 9
StateHashKey: 10485819
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 11/30
Current state: 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.39113411458333s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 2097198
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 11/30
Current state: 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.39294263363755s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 2097163
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 11/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.3947545691906s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 6291458
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 11/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.39657254901961s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 5
StateHashKey: 14680080
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 11/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.39839267015707s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 4
StateHashKey: 14680116
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 11/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.40021887287025s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 3
StateHashKey: 6291517
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 11/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.40205118110236s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 6291487
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 11/30
Current state: 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.40388699080158s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.104 (in 2481 runs)
  Maximal search depth: 40
  Cache hits: 40243

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 5500
Accumulated number of search nodes in root state: 28025

Used RAM: 341428

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 11 -- REWARD RECEIVED: -5
***********************************************

***********************************************
>>> STARTING ROUND 12 -- REMAINING TIME 1071s
***********************************************
***********************************************
Planning step 1/40 in round 12/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 1.40572894736842s.
DP-UCT: Maximal search depth set to 40

Search time: 0.058727s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2561
Cache Hits: 0
Skipped backups: 192813
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0918 (in 2483 runs)
  Maximal search depth: 40
  Cache hits: 40675

Root Node: 
-18.2114 (in 503 real visits)

Q-Value Estimates: 
noop() : -20.0926 (in 189 real visits)
move-west : -18.2114 (in 304 real visits)
move-north : -32.2 (in 10 real visits)

Used RAM: 341428

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 12/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.40744664031621s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0484819s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2287
Cache Hits: 0
Skipped backups: 194226
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0918 (in 2483 runs)
  Maximal search depth: 40
  Cache hits: 41018

Root Node: 
-12.9586 (in 504 real visits)

Q-Value Estimates: 
noop() : -20.38 (in 24 real visits)
move-west : -17.7117 (in 54 real visits)
move-north : -12.9586 (in 402 real visits)
move-east : -20.38 (in 24 real visits)

Used RAM: 341456

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 12/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.40923350923483s.
DP-UCT: Maximal search depth set to 38

Search time: 0.018276s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1829
Cache Hits: 0
Skipped backups: 195585
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0801 (in 2485 runs)
  Maximal search depth: 40
  Cache hits: 41257

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -38 (in 5 real visits)
move-west : -15.5 (in 10 real visits)
move-south : -19.8 (in 10 real visits)
move-north : -3 (in 470 real visits)
move-east : -29.72 (in 10 real visits)

Used RAM: 341456

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 12/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.41106605019815s.
DP-UCT: Maximal search depth set to 37

Search time: 0.015099s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1675
Cache Hits: 0
Skipped backups: 196848
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41466

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -37 (in 5 real visits)
move-west : -13.9667 (in 10 real visits)
move-south : SOLVED with: -37 (in 5 real visits)
move-north : -2 (in 475 real visits)
move-east : -24.28 (in 10 real visits)

Used RAM: 341456

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 12/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 1 1 

Setting time for this decision to 1.41290608465608s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0169182s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1814
Cache Hits: 0
Skipped backups: 198426
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -6.03 (in 10 real visits)
move-west : -3 (in 484 real visits)
move-south : SOLVED with: -36 (in 5 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 341456

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 12/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.41475099337748s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 35
StateHashKey: 14680125
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 12/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.41662201591512s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 34
StateHashKey: 2097215
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 12/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.41849800796813s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 33
StateHashKey: 10485775
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 12/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.4203789893617s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 32
StateHashKey: 10485795
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 12/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.42226231691079s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 31
StateHashKey: 6291496
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 12/30
Current state: 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.424152s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 6291482
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 12/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.42604672897196s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 10485782
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 12/30
Current state: 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.42794786096257s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 28
StateHashKey: 14680101
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 12/30
Current state: 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.42985274431058s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 14680121
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 12/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.43176273458445s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 26
StateHashKey: 14680126
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 12/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.43367785234899s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 25
StateHashKey: 14680127
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 12/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.43559811827957s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 24
StateHashKey: 10485823
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 12/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.43752489905787s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 23
StateHashKey: 10485807
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 12/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.43945552560647s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 6291499
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 12/30
Current state: 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.44139136302294s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 6291482
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 12/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.44333243243243s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 14680086
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 12/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.4452801082544s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 14680117
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 12/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.44723306233062s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 10485821
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 12/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.44918995929444s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 14680111
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 12/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.45115217391304s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 2097211
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 12/30
Current state: 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.45311972789116s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 2097166
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 12/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.45509264305177s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 6291459
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 12/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.45707230559345s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 13
StateHashKey: 14680080
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 12/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.45905601092896s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 14680116
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 12/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.46104514363885s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 10485821
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 12/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.4630397260274s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 10
StateHashKey: 10485807
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 12/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.46504115226337s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 9
StateHashKey: 14680107
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 12/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.4670467032967s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 6291514
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 12/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.46905777166437s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 7
StateHashKey: 14680094
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 12/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.47107438016529s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 2097207
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 12/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.47309793103448s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 2097165
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 12/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.47512569060773s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 2097155
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.47715905947441s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 10485760
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 12/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.47919944598338s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 2097184
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 12/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.48124410540915s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.074 (in 2486 runs)
  Maximal search depth: 40
  Cache hits: 41714

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 6000
Accumulated number of search nodes in root state: 30586

Used RAM: 341456

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 12 -- REWARD RECEIVED: -5
***********************************************

***********************************************
>>> STARTING ROUND 13 -- REMAINING TIME 1070s
***********************************************
***********************************************
Planning step 1/40 in round 13/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 1.48329444444444s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0583682s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2526
Cache Hits: 0
Skipped backups: 200397
Initialization: 
  Statistics of IDS:
  Average search depth: 17.082 (in 2487 runs)
  Maximal search depth: 40
  Cache hits: 42136

Root Node: 
-19.4643 (in 503 real visits)

Q-Value Estimates: 
noop() : -20.932 (in 139 real visits)
move-west : -19.4643 (in 354 real visits)
move-north : -32.32 (in 10 real visits)

Used RAM: 341456

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 13/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.48521835883171s.
DP-UCT: Maximal search depth set to 39

Search time: 0.047574s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2253
Cache Hits: 0
Skipped backups: 201780
Initialization: 
  Statistics of IDS:
  Average search depth: 17.082 (in 2487 runs)
  Maximal search depth: 40
  Cache hits: 42472

Root Node: 
-12.5405 (in 504 real visits)

Q-Value Estimates: 
noop() : -18.684 (in 33 real visits)
move-west : -18.4477 (in 43 real visits)
move-north : -12.5405 (in 407 real visits)
move-east : -20.42 (in 21 real visits)

Used RAM: 341468

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 13/30
Current state: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.48721448467967s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0466769s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2254
Cache Hits: 0
Skipped backups: 203160
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0836 (in 2489 runs)
  Maximal search depth: 40
  Cache hits: 42797

Root Node: 
-12.8407 (in 505 real visits)

Q-Value Estimates: 
noop() : -12.8407 (in 411 real visits)
move-west : -16.4137 (in 60 real visits)
move-south : -19.62 (in 20 real visits)
move-north : SOLVED with: -38 (in 5 real visits)
move-east : -29.64 (in 9 real visits)

Used RAM: 341468

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 13/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.4892189679219s.
DP-UCT: Maximal search depth set to 37

Search time: 0.019166s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1887
Cache Hits: 0
Skipped backups: 204666
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1127 (in 2493 runs)
  Maximal search depth: 40
  Cache hits: 43048

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -16.48 (in 10 real visits)
move-west : -15.169 (in 10 real visits)
move-south : -19.12 (in 10 real visits)
move-north : -3 (in 465 real visits)
move-east : -29.18 (in 10 real visits)

Used RAM: 341468

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 13/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.49126536312849s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0143659s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1633
Cache Hits: 0
Skipped backups: 205923
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1127 (in 2493 runs)
  Maximal search depth: 40
  Cache hits: 43250

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -36 (in 5 real visits)
move-west : -13.1183 (in 10 real visits)
move-south : SOLVED with: -36 (in 5 real visits)
move-north : -2 (in 475 real visits)
move-east : -22.4 (in 10 real visits)

Used RAM: 341468

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 13/30
Current state: 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 1 

Setting time for this decision to 1.49332167832168s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0193682s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1790
Cache Hits: 0
Skipped backups: 207423
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -5.6 (in 10 real visits)
move-west : -3 (in 484 real visits)
move-south : SOLVED with: -35 (in 5 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 341468

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 13/30
Current state: 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.49537955182073s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 34
StateHashKey: 6291500
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 13/30
Current state: 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.49747124824684s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 33
StateHashKey: 10485787
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 13/30
Current state: 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.49956882022472s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 32
StateHashKey: 14680102
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 13/30
Current state: 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.50167369901547s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 31
StateHashKey: 14680121
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 13/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.50378309859155s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 6291518
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 13/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.50589985895628s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 10485791
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 13/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.50801836158192s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 6291495
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 13/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.51014427157001s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 27
StateHashKey: 6291481
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 13/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.5122776203966s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 26
StateHashKey: 14680086
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 13/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.5144170212766s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 6291509
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 13/30
Current state: 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.51656107954545s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 2097181
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 13/30
Current state: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.51871266002845s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 6291463
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 13/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.52086894586895s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 6291473
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 13/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.52303138373752s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 2097172
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 13/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.5252s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 14680069
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 13/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.5273748211731s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 10485809
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 13/30
Current state: 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.52955730659026s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 14680108
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 13/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.53174461979914s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 14680123
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 13/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.5339382183908s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 16
StateHashKey: 14680126
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 13/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.5361381294964s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 15
StateHashKey: 14680127
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 13/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.53834582132565s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 6291519
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 13/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.54055844155844s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 6291487
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 13/30
Current state: 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.5427789017341s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 14680087
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 13/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.54500434153401s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 2097205
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 13/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.54723623188406s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 2097165
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 13/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.54947460087083s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 2097155
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.55172093023256s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 13/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.55397379912664s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 6291472
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 13/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.55623177842566s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 6291476
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 13/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.55849635036496s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 6291477
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 13/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.56076754385965s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 4
StateHashKey: 10485781
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 13/30
Current state: 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.56304685212299s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 14680101
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 13/30
Current state: 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.56533137829912s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 14680121
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 13/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.56762261380323s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43490

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 6500
Accumulated number of search nodes in root state: 33112

Used RAM: 341468

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 13 -- REWARD RECEIVED: -6
***********************************************

***********************************************
>>> STARTING ROUND 14 -- REMAINING TIME 1070s
***********************************************
***********************************************
Planning step 1/40 in round 14/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 1.56992058823529s.
DP-UCT: Maximal search depth set to 40

Search time: 0.062381s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2512
Cache Hits: 0
Skipped backups: 209352
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 43913

Root Node: 
-19.2254 (in 503 real visits)

Q-Value Estimates: 
noop() : -20.397 (in 161 real visits)
move-west : -19.2254 (in 332 real visits)
move-north : -32.32 (in 10 real visits)

Used RAM: 341468

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 14/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.5720795287187s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0619922s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2510
Cache Hits: 0
Skipped backups: 211107
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 44337

Root Node: 
-19.3351 (in 504 real visits)

Q-Value Estimates: 
noop() : -19.696 (in 177 real visits)
move-west : -19.3351 (in 217 real visits)
move-north : SOLVED with: -39 (in 5 real visits)
move-east : -20.6512 (in 105 real visits)

Used RAM: 341484

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 14/30
Current state: 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.57430088495575s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0682878s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2487
Cache Hits: 0
Skipped backups: 212757
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 44762

Root Node: 
-18.5976 (in 504 real visits)

Q-Value Estimates: 
noop() : -18.5976 (in 184 real visits)
move-west : -18.7372 (in 169 real visits)
move-north : SOLVED with: -38 (in 5 real visits)
move-east : -19.0136 (in 146 real visits)

Used RAM: 341484

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 14/30
Current state: 1 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.57651994091581s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0683038s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2510
Cache Hits: 0
Skipped backups: 214353
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 45187

Root Node: 
-18.0791 (in 504 real visits)

Q-Value Estimates: 
noop() : -18.3128 (in 153 real visits)
move-west : -18.1037 (in 174 real visits)
move-north : SOLVED with: -37 (in 5 real visits)
move-east : -18.0791 (in 172 real visits)

Used RAM: 341484

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 14/30
Current state: 1 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.57874408284024s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0496721s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2315
Cache Hits: 0
Skipped backups: 215748
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1014 (in 2495 runs)
  Maximal search depth: 40
  Cache hits: 45536

Root Node: 
-12.1227 (in 504 real visits)

Q-Value Estimates: 
noop() : -18.3248 (in 23 real visits)
move-west : -16.0327 (in 61 real visits)
move-north : -12.1227 (in 397 real visits)
move-east : -18.358 (in 23 real visits)

Used RAM: 341484

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 14/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.58100296296296s.
DP-UCT: Maximal search depth set to 35

Search time: 0.020169s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1830
Cache Hits: 0
Skipped backups: 217167
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1141 (in 2497 runs)
  Maximal search depth: 40
  Cache hits: 45776

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -35 (in 5 real visits)
move-west : -14.411 (in 10 real visits)
move-south : -18.18 (in 10 real visits)
move-north : -3 (in 470 real visits)
move-east : -26.34 (in 10 real visits)

Used RAM: 341484

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 14/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.58331305637982s.
DP-UCT: Maximal search depth set to 34

Search time: 0.0169401s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1745
Cache Hits: 0
Skipped backups: 218559
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1081 (in 2498 runs)
  Maximal search depth: 40
  Cache hits: 46000

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -34 (in 5 real visits)
move-west : -12.95 (in 10 real visits)
move-south : -15.7367 (in 10 real visits)
move-north : -2 (in 470 real visits)
move-east : -21.2 (in 10 real visits)

Used RAM: 341484

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 14/30
Current state: 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 1 0 

Setting time for this decision to 1.58563447251114s.
DP-UCT: Maximal search depth set to 33

Search time: 0.016289s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1829
Cache Hits: 0
Skipped backups: 219990
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 38 real visits)
move-west : -3 (in 451 real visits)
move-south : -10.0567 (in 10 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 341484

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 9/40 in round 14/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.58796279761905s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 32
StateHashKey: 2097177
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 14/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.59032339791356s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 31
StateHashKey: 10485766
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 14/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.59269104477612s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 6291489
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 14/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.59506576980568s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 10485784
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 14/30
Current state: 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.59744760479042s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 28
StateHashKey: 14680102
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 14/30
Current state: 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.59983658170915s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 14680121
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 14/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.60223123123123s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 2097214
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 14/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.60463308270677s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 25
StateHashKey: 14680079
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 14/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.6070421686747s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 6291507
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 14/30
Current state: 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.60946003016591s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 6291484
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 14/30
Current state: 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.61188519637462s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 22
StateHashKey: 14680087
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 14/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.61431618759455s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 21
StateHashKey: 14680117
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 14/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.61675606060606s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 10485821
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 14/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.61920182094082s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 10485807
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 14/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.62165501519757s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 6291499
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 14/30
Current state: 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.62411567732116s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 14680090
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 14/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.62658384146341s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 16
StateHashKey: 14680118
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 14/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.62906106870229s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 15
StateHashKey: 10485821
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 14/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.63154434250765s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 10485807
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 14/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.63403522205207s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 13
StateHashKey: 14680107
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 14/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.63653527607362s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 14680122
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 14/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.63904147465438s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 14680126
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 14/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.64155538461538s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 6291519
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 14/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.64407858243451s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 2097183
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 14/30
Current state: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.64660802469136s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 2097159
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 14/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.64914683153014s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 6291457
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 14/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.6516919504644s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 14680080
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 14/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.65424496124031s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 5
StateHashKey: 10485812
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 14/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.65680590062112s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 4
StateHashKey: 10485805
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 14/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.65937636080871s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 3
StateHashKey: 2097195
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 14/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.66195327102804s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 14680074
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 14/30
Current state: 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.66453822152886s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0819 (in 2503 runs)
  Maximal search depth: 40
  Cache hits: 46243

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 7000
Accumulated number of search nodes in root state: 35624

Used RAM: 341484

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 14 -- REWARD RECEIVED: -8
***********************************************

***********************************************
>>> STARTING ROUND 15 -- REMAINING TIME 1069s
***********************************************
***********************************************
Planning step 1/40 in round 15/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 1.66713125s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0585158s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2531
Cache Hits: 0
Skipped backups: 221967
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0699 (in 2505 runs)
  Maximal search depth: 40
  Cache hits: 46672

Root Node: 
-19.0751 (in 503 real visits)

Q-Value Estimates: 
noop() : -20.7976 (in 167 real visits)
move-west : -19.0751 (in 323 real visits)
move-north : -30.88 (in 13 real visits)

Used RAM: 341484

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 15/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.66958215962441s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0621662s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2530
Cache Hits: 0
Skipped backups: 223683
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0699 (in 2505 runs)
  Maximal search depth: 40
  Cache hits: 47101

Root Node: 
-19.1298 (in 504 real visits)

Q-Value Estimates: 
noop() : -19.1298 (in 194 real visits)
move-west : -19.1716 (in 190 real visits)
move-north : SOLVED with: -39 (in 5 real visits)
move-east : -20.152 (in 115 real visits)

Used RAM: 341496

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 15/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.67209561128527s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0488069s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2287
Cache Hits: 0
Skipped backups: 225018
Initialization: 
  Statistics of IDS:
  Average search depth: 17.077 (in 2506 runs)
  Maximal search depth: 40
  Cache hits: 47442

Root Node: 
-12.0336 (in 504 real visits)

Q-Value Estimates: 
noop() : -19.712 (in 26 real visits)
move-west : -17.6302 (in 46 real visits)
move-north : -12.0336 (in 408 real visits)
move-east : -19.88 (in 24 real visits)

Used RAM: 341500

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 15/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.67463736263736s.
DP-UCT: Maximal search depth set to 37

Search time: 0.018688s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1742
Cache Hits: 0
Skipped backups: 226347
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0809 (in 2510 runs)
  Maximal search depth: 40
  Cache hits: 47661

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -37 (in 5 real visits)
move-west : -15.169 (in 10 real visits)
move-south : -18.07 (in 10 real visits)
move-north : -3 (in 470 real visits)
move-east : -28.87 (in 10 real visits)

Used RAM: 341500

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 15/30
Current state: 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.67723427672956s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0165319s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1727
Cache Hits: 0
Skipped backups: 227712
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0749 (in 2511 runs)
  Maximal search depth: 40
  Cache hits: 47882

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -36 (in 5 real visits)
move-west : -13.2633 (in 10 real visits)
move-south : -15.66 (in 10 real visits)
move-north : -2 (in 470 real visits)
move-east : -23.64 (in 10 real visits)

Used RAM: 341500

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 15/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 1 

Setting time for this decision to 1.67984409448819s.
DP-UCT: Maximal search depth set to 35

Search time: 0.015048s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1768
Cache Hits: 0
Skipped backups: 229104
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 43 real visits)
move-west : -3 (in 451 real visits)
move-south : SOLVED with: -35 (in 5 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 341500

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 15/30
Current state: 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.68246372239748s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 34
StateHashKey: 14680105
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 15/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.68511532385466s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 33
StateHashKey: 14680122
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 15/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.6877753164557s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 32
StateHashKey: 14680126
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 15/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.69044374009509s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 31
StateHashKey: 2097215
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 15/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.69312063492063s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 30
StateHashKey: 10485775
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 15/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.69580445151033s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 14680099
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 15/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.69849681528662s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 28
StateHashKey: 14680120
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 15/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.70119776714514s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 27
StateHashKey: 6291518
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 15/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.70390734824281s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 6291487
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 15/30
Current state: 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.7066272s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 25
StateHashKey: 10485783
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 15/30
Current state: 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.70935737179487s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 2097189
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 15/30
Current state: 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.71209470304976s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 23
StateHashKey: 14680073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 15/30
Current state: 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.71484083601286s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 22
StateHashKey: 10485810
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 15/30
Current state: 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.71759420289855s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 21
StateHashKey: 14680108
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 15/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.7203564516129s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 20
StateHashKey: 2097211
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 15/30
Current state: 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.72312762520194s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 14680078
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 15/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.72590938511327s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 14680115
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 15/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.72869854132901s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 14680124
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 15/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.73149675324675s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 16
StateHashKey: 14680127
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 15/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.73430406504065s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 2097215
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 15/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.73712214983713s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 14680079
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 15/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.73994779771615s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 13
StateHashKey: 14680115
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 15/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.74278431372549s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 14680124
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 15/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.74562847790507s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 14680127
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 15/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.74848360655738s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 10
StateHashKey: 14680127
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 15/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.75134646962233s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 2097215
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 15/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.75422039473684s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 8
StateHashKey: 10485775
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 15/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.7571021416804s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 6291491
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 15/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.75999504950495s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 6291480
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 15/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.76289586776859s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 5
StateHashKey: 14680086
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 15/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.76580629139073s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 4
StateHashKey: 10485813
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 15/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.7687263681592s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 3
StateHashKey: 6291501
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 15/30
Current state: 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.7716561461794s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 6291483
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 15/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.77459567387687s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48112

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 7500
Accumulated number of search nodes in root state: 38155

Used RAM: 341500

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 15 -- REWARD RECEIVED: -6
***********************************************

***********************************************
>>> STARTING ROUND 16 -- REMAINING TIME 1069s
***********************************************
***********************************************
Planning step 1/40 in round 16/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 1.777545s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0595372s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2519
Cache Hits: 0
Skipped backups: 231048
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48537

Root Node: 
-19.5622 (in 503 real visits)

Q-Value Estimates: 
noop() : -21.1013 (in 140 real visits)
move-west : -19.5622 (in 349 real visits)
move-north : -31.204 (in 14 real visits)

Used RAM: 341500

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 16/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.78034724540902s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0625s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2480
Cache Hits: 0
Skipped backups: 232869
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0537 (in 2515 runs)
  Maximal search depth: 40
  Cache hits: 48960

Root Node: 
-18.8667 (in 504 real visits)

Q-Value Estimates: 
noop() : -18.8667 (in 253 real visits)
move-west : -19.4368 (in 145 real visits)
move-north : SOLVED with: -39 (in 5 real visits)
move-east : -20.5936 (in 101 real visits)

Used RAM: 341516

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 16/30
Current state: 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.78321237458194s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0616798s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2518
Cache Hits: 0
Skipped backups: 234642
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0608 (in 2516 runs)
  Maximal search depth: 40
  Cache hits: 49385

Root Node: 
-18.2264 (in 504 real visits)

Q-Value Estimates: 
noop() : -18.2264 (in 226 real visits)
move-west : -18.7517 (in 166 real visits)
move-north : SOLVED with: -38 (in 5 real visits)
move-east : -19.5968 (in 107 real visits)

Used RAM: 341516

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 16/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.78609045226131s.
DP-UCT: Maximal search depth set to 37

Search time: 0.061486s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2512
Cache Hits: 0
Skipped backups: 236334
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0608 (in 2516 runs)
  Maximal search depth: 40
  Cache hits: 49813

Root Node: 
-18.3439 (in 504 real visits)

Q-Value Estimates: 
noop() : -18.422 (in 201 real visits)
move-west : -18.3439 (in 192 real visits)
move-north : SOLVED with: -37 (in 5 real visits)
move-east : -19.4489 (in 106 real visits)

Used RAM: 341516

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 16/30
Current state: 1 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.78897651006711s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0755718s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2642
Cache Hits: 0
Skipped backups: 238041
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0671 (in 2517 runs)
  Maximal search depth: 40
  Cache hits: 50264

Root Node: 
-15.7753 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.7753 (in 256 real visits)
move-west : -16.4524 (in 177 real visits)
move-north : SOLVED with: -36 (in 5 real visits)
move-east : -18.1624 (in 66 real visits)

Used RAM: 341516

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 16/30
Current state: 1 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.79185042016807s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0486s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2574
Cache Hits: 0
Skipped backups: 239454
Initialization: 
  Statistics of IDS:
  Average search depth: 17.062 (in 2518 runs)
  Maximal search depth: 40
  Cache hits: 50669

Root Node: 
-10.5881 (in 504 real visits)

Q-Value Estimates: 
noop() : -17.3491 (in 25 real visits)
move-west : -15.7738 (in 47 real visits)
move-north : -10.5881 (in 413 real visits)
move-east : -18.26 (in 19 real visits)

Used RAM: 341516

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 16/30
Current state: 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.79477777777778s.
DP-UCT: Maximal search depth set to 34

Search time: 0.021728s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1793
Cache Hits: 0
Skipped backups: 240708
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0516 (in 2520 runs)
  Maximal search depth: 40
  Cache hits: 50906

Root Node: 
-4.1728 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -34 (in 5 real visits)
move-west : -14.792 (in 17 real visits)
move-south : -17.68 (in 10 real visits)
move-north : -4.1728 (in 468 real visits)
move-east : SOLVED with: -34 (in 5 real visits)

Used RAM: 341516

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 16/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.79776222596965s.
DP-UCT: Maximal search depth set to 33

Search time: 0.0179541s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1844
Cache Hits: 0
Skipped backups: 242172
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0412 (in 2522 runs)
  Maximal search depth: 40
  Cache hits: 51154

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -10.94 (in 10 real visits)
move-west : -13.625 (in 10 real visits)
move-south : SOLVED with: -33 (in 5 real visits)
move-north : -3 (in 470 real visits)
move-east : -9.75 (in 10 real visits)

Used RAM: 341516

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 9/40 in round 16/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.80076182432432s.
DP-UCT: Maximal search depth set to 32

Search time: 0.0173509s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1810
Cache Hits: 0
Skipped backups: 243678
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51397

Root Node: 
-2 (in 504 real visits)

Q-Value Estimates: 
noop() : -8.9 (in 10 real visits)
move-west : -11.72 (in 10 real visits)
move-south : -12 (in 10 real visits)
move-east : -2 (in 474 real visits)

Used RAM: 341516

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 10/40 in round 16/30
Current state: 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 1 

Setting time for this decision to 1.80377157360406s.
DP-UCT: Maximal search depth set to 31

Search time: 0.016196s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1733
Cache Hits: 0
Skipped backups: 245193
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 484 real visits)
move-west : -7 (in 10 real visits)
move-south : SOLVED with: -31 (in 5 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 341516

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 11/40 in round 16/30
Current state: 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.80679491525424s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 6291497
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 16/30
Current state: 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.80985568760611s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 14680090
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 16/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.81292857142857s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 28
StateHashKey: 14680118
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 16/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.81601022146508s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 14680125
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 16/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.81910068259386s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 26
StateHashKey: 10485823
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 16/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.82220170940171s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 25
StateHashKey: 10485807
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 16/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.82531335616438s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 6291499
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 16/30
Current state: 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.82843739279588s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 6291482
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 16/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.8315704467354s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 22
StateHashKey: 14680086
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 16/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.83471600688468s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 21
StateHashKey: 10485813
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 16/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.83787068965517s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 20
StateHashKey: 6291501
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 16/30
Current state: 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.84103799654577s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 10485787
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 16/30
Current state: 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.84421453287197s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 6291494
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 16/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.8474020797227s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 14680089
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 16/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.85060069444444s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 16
StateHashKey: 10485814
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 16/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.85381043478261s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 6291501
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 16/30
Current state: 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.8570331010453s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 2097179
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 16/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.86026527050611s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 13
StateHashKey: 10485766
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 16/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.86351048951049s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 14680097
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 16/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.86676532399299s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 14680120
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 16/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.87003157894737s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 10
StateHashKey: 14680126
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 16/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.87330931458699s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 9
StateHashKey: 10485823
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 16/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.87660035211268s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 8
StateHashKey: 10485807
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 16/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.87990299823633s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 7
StateHashKey: 14680107
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 16/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.88321378091873s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 10485818
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 16/30
Current state: 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.88653805309735s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 5
StateHashKey: 10485806
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 16/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.88987411347518s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 6291499
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 16/30
Current state: 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.89322380106572s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 14680090
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 16/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.89658540925267s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 10485814
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 16/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.89995721925134s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 51624

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 8000
Accumulated number of search nodes in root state: 40674

Used RAM: 341516

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 16 -- REWARD RECEIVED: -10
***********************************************

***********************************************
>>> STARTING ROUND 17 -- REMAINING TIME 1068s
***********************************************
***********************************************
Planning step 1/40 in round 17/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 1.90334107142857s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0581012s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2518
Cache Hits: 0
Skipped backups: 247116
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 52046

Root Node: 
-18.5543 (in 503 real visits)

Q-Value Estimates: 
noop() : -20.9424 (in 111 real visits)
move-west : -18.5543 (in 382 real visits)
move-north : -31.52 (in 10 real visits)

Used RAM: 341516

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 17/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.90656887298748s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0490348s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2310
Cache Hits: 0
Skipped backups: 248541
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 52393

Root Node: 
-12.673 (in 504 real visits)

Q-Value Estimates: 
noop() : -20.18 (in 15 real visits)
move-west : -17.264 (in 44 real visits)
move-north : -12.673 (in 430 real visits)
move-east : -20.38 (in 15 real visits)

Used RAM: 341524

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 17/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.90989068100358s.
DP-UCT: Maximal search depth set to 38

Search time: 0.04843s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2305
Cache Hits: 0
Skipped backups: 249963
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 52737

Root Node: 
-13.1189 (in 505 real visits)

Q-Value Estimates: 
noop() : -13.1189 (in 409 real visits)
move-west : -16.2897 (in 60 real visits)
move-south : -19.488 (in 22 real visits)
move-north : SOLVED with: -38 (in 5 real visits)
move-east : -30.68 (in 9 real visits)

Used RAM: 341524

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 17/30
Current state: 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.91322621184919s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0477719s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2339
Cache Hits: 0
Skipped backups: 251319
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53083

Root Node: 
-12.3831 (in 505 real visits)

Q-Value Estimates: 
noop() : -12.3831 (in 411 real visits)
move-west : -15.9147 (in 58 real visits)
move-south : -18.68 (in 22 real visits)
move-north : SOLVED with: -37 (in 5 real visits)
move-east : -28.87 (in 9 real visits)

Used RAM: 341524

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 17/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.91657374100719s.
DP-UCT: Maximal search depth set to 36

Search time: 0.018568s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1838
Cache Hits: 0
Skipped backups: 252777
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53329

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -36 (in 5 real visits)
move-west : -14.75 (in 10 real visits)
move-south : -18.5 (in 10 real visits)
move-north : -3 (in 470 real visits)
move-east : -28.4 (in 10 real visits)

Used RAM: 341524

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 17/30
Current state: 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.91998558558559s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0164199s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1779
Cache Hits: 0
Skipped backups: 254289
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53563

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -35 (in 5 real visits)
move-west : -13.12 (in 10 real visits)
move-south : SOLVED with: -35 (in 5 real visits)
move-north : -2 (in 475 real visits)
move-east : -21.8 (in 10 real visits)

Used RAM: 341524

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 17/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 1 0 

Setting time for this decision to 1.92341516245487s.
DP-UCT: Maximal search depth set to 34

Search time: 0.017246s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1810
Cache Hits: 0
Skipped backups: 255909
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 479 real visits)
move-west : -9.288 (in 10 real visits)
move-south : -10 (in 10 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 341524

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 17/30
Current state: 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.92685533453888s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 33
StateHashKey: 2097181
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 17/30
Current state: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.93033876811594s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 32
StateHashKey: 14680071
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 17/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.93383666061706s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 31
StateHashKey: 6291505
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 17/30
Current state: 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.93734545454545s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 6291484
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 17/30
Current state: 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.94086338797814s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 29
StateHashKey: 2097175
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 17/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.9443996350365s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 6291461
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 17/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.94794698354662s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 14680081
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 17/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.95151098901099s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 26
StateHashKey: 10485812
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 17/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.95508440366972s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 6291501
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 17/30
Current state: 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.95867279411765s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 6291483
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 17/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.96227255985267s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 6291478
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 17/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.96588745387454s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 22
StateHashKey: 10485781
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 17/30
Current state: 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.96951201478743s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 21
StateHashKey: 10485797
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 17/30
Current state: 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.97315s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 14680105
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 17/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.97680333951763s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 14680122
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 17/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.98046840148699s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 6291518
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 17/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.98414897579143s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 14680095
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 17/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.98784328358209s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 16
StateHashKey: 10485815
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 17/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.99154953271028s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 2097197
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 17/30
Current state: 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.99527153558052s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 2097163
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 17/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.99900562851782s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 13
StateHashKey: 14680066
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 17/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.0027537593985s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 14680112
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 17/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.00651789077213s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 14680124
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 17/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.01029433962264s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 10
StateHashKey: 14680127
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 17/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.01408506616257s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 6291519
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 17/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.01789015151515s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 8
StateHashKey: 14680095
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 17/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.02170777988615s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 7
StateHashKey: 10485815
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 17/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.02554372623574s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 14680109
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 17/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.02939428571429s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 6291515
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 17/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.03325763358779s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 4
StateHashKey: 10485790
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 17/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.03713384321224s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 14680103
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 17/30
Current state: 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.04102873563218s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 14680121
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 17/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.04493857965451s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 53804

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 8500
Accumulated number of search nodes in root state: 43192

Used RAM: 341524

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 17 -- REWARD RECEIVED: -7
***********************************************

***********************************************
>>> STARTING ROUND 18 -- REMAINING TIME 1068s
***********************************************
***********************************************
Planning step 1/40 in round 18/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 2.04886346153846s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0595858s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2572
Cache Hits: 0
Skipped backups: 257871
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 54238

Root Node: 
-19.2138 (in 503 real visits)

Q-Value Estimates: 
noop() : -20.5419 (in 157 real visits)
move-west : -19.2138 (in 336 real visits)
move-north : -32.2 (in 10 real visits)

Used RAM: 341524

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 18/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 2.05261464354528s.
DP-UCT: Maximal search depth set to 39

Search time: 0.065094s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2520
Cache Hits: 0
Skipped backups: 259623
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 54671

Root Node: 
-18.8071 (in 504 real visits)

Q-Value Estimates: 
noop() : -19.2021 (in 169 real visits)
move-west : -18.8071 (in 214 real visits)
move-north : SOLVED with: -39 (in 5 real visits)
move-east : -19.9648 (in 116 real visits)

Used RAM: 341528

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 18/30
Current state: 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.05644401544402s.
DP-UCT: Maximal search depth set to 38

Search time: 0.069881s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2519
Cache Hits: 0
Skipped backups: 261384
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0361 (in 2523 runs)
  Maximal search depth: 40
  Cache hits: 55103

Root Node: 
-17.3209 (in 504 real visits)

Q-Value Estimates: 
noop() : -18.9889 (in 125 real visits)
move-west : -18.4818 (in 161 real visits)
move-north : SOLVED with: -38 (in 5 real visits)
move-east : -17.3209 (in 213 real visits)

Used RAM: 341528

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 18/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 2.06027852998066s.
DP-UCT: Maximal search depth set to 37

Search time: 0.047344s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2291
Cache Hits: 0
Skipped backups: 262869
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0301 (in 2524 runs)
  Maximal search depth: 40
  Cache hits: 55447

Root Node: 
-12.2864 (in 504 real visits)

Q-Value Estimates: 
noop() : -18.68 (in 21 real visits)
move-west : -17.264 (in 38 real visits)
move-north : -12.2864 (in 426 real visits)
move-east : -19.3 (in 19 real visits)

Used RAM: 341528

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 18/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.06417248062016s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0607951s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2375
Cache Hits: 0
Skipped backups: 264477
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0301 (in 2524 runs)
  Maximal search depth: 40
  Cache hits: 55823

Root Node: 
-16.8689 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -36 (in 5 real visits)
move-west : -16.8689 (in 341 real visits)
move-south : -18.0959 (in 144 real visits)
move-north : SOLVED with: -36 (in 5 real visits)
move-east : -28.52 (in 10 real visits)

Used RAM: 341528

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 18/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.06805242718447s.
DP-UCT: Maximal search depth set to 35

Search time: 0.072767s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2350
Cache Hits: 0
Skipped backups: 266223
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0356 (in 2525 runs)
  Maximal search depth: 40
  Cache hits: 56224

Root Node: 
-16.8778 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -35 (in 5 real visits)
move-west : -16.8778 (in 266 real visits)
move-south : -17.3985 (in 224 real visits)
move-north : SOLVED with: -35 (in 5 real visits)
move-east : SOLVED with: -35 (in 5 real visits)

Used RAM: 341528

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 18/30
Current state: 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 2.0719280155642s.
DP-UCT: Maximal search depth set to 34

Search time: 0.0749671s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2439
Cache Hits: 0
Skipped backups: 268398
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0408 (in 2526 runs)
  Maximal search depth: 40
  Cache hits: 56640

Root Node: 
-15.8165 (in 504 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -34 (in 5 real visits)
move-south : -15.8165 (in 489 real visits)
move-north : SOLVED with: -34 (in 5 real visits)
move-east : SOLVED with: -34 (in 5 real visits)

Used RAM: 341528

Submitted action: move-south 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 18/30
Current state: 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.07581286549708s.
DP-UCT: Maximal search depth set to 33

Search time: 0.0733569s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2445
Cache Hits: 0
Skipped backups: 270096
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0408 (in 2526 runs)
  Maximal search depth: 40
  Cache hits: 57058

Root Node: 
-15.8985 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.409 (in 245 real visits)
move-north : SOLVED with: -33 (in 5 real visits)
move-east : -15.8985 (in 253 real visits)

Used RAM: 341528

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 9/40 in round 18/30
Current state: 1 1 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 2.07971484375s.
DP-UCT: Maximal search depth set to 32

Search time: 0.0760791s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2640
Cache Hits: 0
Skipped backups: 271794
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0806 (in 2544 runs)
  Maximal search depth: 40
  Cache hits: 57491

Root Node: 
-14.72 (in 504 real visits)

Q-Value Estimates: 
noop() : -14.72 (in 207 real visits)
move-west : -15.2757 (in 194 real visits)
move-north : SOLVED with: -32 (in 5 real visits)
move-east : -15.888 (in 98 real visits)

Used RAM: 341528

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 10/40 in round 18/30
Current state: 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.0836301369863s.
DP-UCT: Maximal search depth set to 31

Search time: 0.067029s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2393
Cache Hits: 0
Skipped backups: 273105
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0806 (in 2544 runs)
  Maximal search depth: 40
  Cache hits: 57885

Root Node: 
-14.5786 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.3566 (in 105 real visits)
move-west : -14.5786 (in 172 real visits)
move-north : -14.9756 (in 132 real visits)
move-east : -15.5453 (in 95 real visits)

Used RAM: 341552

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 11/40 in round 18/30
Current state: 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 2.08757647058824s.
DP-UCT: Maximal search depth set to 30

Search time: 0.0736811s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2372
Cache Hits: 0
Skipped backups: 274698
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0806 (in 2544 runs)
  Maximal search depth: 40
  Cache hits: 58290

Root Node: 
-14.6416 (in 503 real visits)

Q-Value Estimates: 
noop() : -14.6416 (in 201 real visits)
move-north : -14.9806 (in 158 real visits)
move-east : -15.1163 (in 144 real visits)

Used RAM: 341552

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 12/40 in round 18/30
Current state: 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.09152455795678s.
DP-UCT: Maximal search depth set to 29

Search time: 0.0754521s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2451
Cache Hits: 0
Skipped backups: 276600
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0806 (in 2544 runs)
  Maximal search depth: 40
  Cache hits: 58716

Root Node: 
-13.8426 (in 503 real visits)

Q-Value Estimates: 
noop() : -13.8426 (in 326 real visits)
move-north : SOLVED with: -29 (in 5 real visits)
move-east : -14.7197 (in 172 real visits)

Used RAM: 341552

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 13/40 in round 18/30
Current state: 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 2.09548622047244s.
DP-UCT: Maximal search depth set to 28

Search time: 0.077498s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2643
Cache Hits: 0
Skipped backups: 278415
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0837 (in 2545 runs)
  Maximal search depth: 40
  Cache hits: 59161

Root Node: 
-13.1217 (in 503 real visits)

Q-Value Estimates: 
noop() : -13.8551 (in 186 real visits)
move-north : SOLVED with: -28 (in 5 real visits)
move-east : -13.1217 (in 312 real visits)

Used RAM: 341552

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 14/40 in round 18/30
Current state: 1 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.09945759368836s.
DP-UCT: Maximal search depth set to 27

Search time: 0.0691328s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2446
Cache Hits: 0
Skipped backups: 279831
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0837 (in 2545 runs)
  Maximal search depth: 40
  Cache hits: 59567

Root Node: 
-12.9696 (in 504 real visits)

Q-Value Estimates: 
noop() : -12.9696 (in 192 real visits)
move-west : -14.0794 (in 97 real visits)
move-north : -13.4346 (in 132 real visits)
move-east : -14.1744 (in 83 real visits)

Used RAM: 341556

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 15/40 in round 18/30
Current state: 1 1 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 2.10346442687747s.
DP-UCT: Maximal search depth set to 26

Search time: 0.0709569s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2496
Cache Hits: 0
Skipped backups: 281463
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0837 (in 2545 runs)
  Maximal search depth: 40
  Cache hits: 59993

Root Node: 
-13.0462 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.0462 (in 185 real visits)
move-west : -13.0642 (in 182 real visits)
move-north : SOLVED with: -26 (in 5 real visits)
move-east : -13.4576 (in 132 real visits)

Used RAM: 341556

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 16/40 in round 18/30
Current state: 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 2.10748118811881s.
DP-UCT: Maximal search depth set to 25

Search time: 0.071043s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2484
Cache Hits: 0
Skipped backups: 283071
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0837 (in 2545 runs)
  Maximal search depth: 40
  Cache hits: 60420

Root Node: 
-12.3183 (in 504 real visits)

Q-Value Estimates: 
noop() : -12.9734 (in 155 real visits)
move-west : -12.3183 (in 202 real visits)
move-north : SOLVED with: -25 (in 5 real visits)
move-east : -12.9463 (in 142 real visits)

Used RAM: 341556

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 17/40 in round 18/30
Current state: 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.11151388888889s.
DP-UCT: Maximal search depth set to 24

Search time: 0.0750561s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2461
Cache Hits: 0
Skipped backups: 284895
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0837 (in 2545 runs)
  Maximal search depth: 40
  Cache hits: 60844

Root Node: 
-11.9752 (in 503 real visits)

Q-Value Estimates: 
noop() : -12.1236 (in 294 real visits)
move-north : SOLVED with: -24 (in 5 real visits)
move-east : -11.9752 (in 204 real visits)

Used RAM: 341556

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 18/40 in round 18/30
Current state: 1 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.11555467196819s.
DP-UCT: Maximal search depth set to 23

Search time: 0.0696311s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2487
Cache Hits: 0
Skipped backups: 286431
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0837 (in 2545 runs)
  Maximal search depth: 40
  Cache hits: 61266

Root Node: 
-11.298 (in 504 real visits)

Q-Value Estimates: 
noop() : -11.7398 (in 176 real visits)
move-west : -11.298 (in 162 real visits)
move-north : SOLVED with: -23 (in 5 real visits)
move-east : -11.7364 (in 161 real visits)

Used RAM: 341556

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 19/40 in round 18/30
Current state: 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 2.11962151394422s.
DP-UCT: Maximal search depth set to 22

Search time: 0.0766079s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2648
Cache Hits: 0
Skipped backups: 288258
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0837 (in 2545 runs)
  Maximal search depth: 40
  Cache hits: 61714

Root Node: 
-10.5076 (in 503 real visits)

Q-Value Estimates: 
noop() : -11.1611 (in 157 real visits)
move-north : SOLVED with: -22 (in 5 real visits)
move-east : -10.5076 (in 341 real visits)

Used RAM: 341556

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 20/40 in round 18/30
Current state: 1 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.12369261477046s.
DP-UCT: Maximal search depth set to 21

Search time: 0.067802s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2430
Cache Hits: 0
Skipped backups: 289701
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0837 (in 2545 runs)
  Maximal search depth: 40
  Cache hits: 62114

Root Node: 
-10.645 (in 504 real visits)

Q-Value Estimates: 
noop() : -10.645 (in 146 real visits)
move-west : -10.6488 (in 144 real visits)
move-north : -10.9417 (in 113 real visits)
move-east : -11.0776 (in 101 real visits)

Used RAM: 341556

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 21/40 in round 18/30
Current state: 1 1 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 2.127796s.
DP-UCT: Maximal search depth set to 20

Search time: 0.07745s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2592
Cache Hits: 0
Skipped backups: 291312
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0756 (in 2552 runs)
  Maximal search depth: 40
  Cache hits: 62554

Root Node: 
-9.73474 (in 504 real visits)

Q-Value Estimates: 
noop() : -9.98225 (in 194 real visits)
move-west : -9.73474 (in 200 real visits)
move-north : SOLVED with: -20 (in 5 real visits)
move-east : -10.64 (in 105 real visits)

Used RAM: 341556

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 22/40 in round 18/30
Current state: 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.13189779559118s.
DP-UCT: Maximal search depth set to 19

Search time: 0.072175s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2430
Cache Hits: 0
Skipped backups: 293022
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0756 (in 2552 runs)
  Maximal search depth: 40
  Cache hits: 62963

Root Node: 
-9.14914 (in 503 real visits)

Q-Value Estimates: 
noop() : -10.0614 (in 229 real visits)
move-north : SOLVED with: -19 (in 5 real visits)
move-east : -9.14914 (in 269 real visits)

Used RAM: 341564

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 23/40 in round 18/30
Current state: 1 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.13602409638554s.
DP-UCT: Maximal search depth set to 18

Search time: 0.068109s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2482
Cache Hits: 0
Skipped backups: 294651
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0756 (in 2552 runs)
  Maximal search depth: 40
  Cache hits: 63383

Root Node: 
-9.57416 (in 504 real visits)

Q-Value Estimates: 
noop() : -9.60198 (in 166 real visits)
move-west : -9.78446 (in 152 real visits)
move-north : SOLVED with: -18 (in 5 real visits)
move-east : -9.57416 (in 181 real visits)

Used RAM: 341564

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 24/40 in round 18/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 2.14017706237425s.
DP-UCT: Maximal search depth set to 17

Search time: 0.0554509s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2502
Cache Hits: 0
Skipped backups: 296100
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0756 (in 2552 runs)
  Maximal search depth: 40
  Cache hits: 63775

Root Node: 
-7.56979 (in 504 real visits)

Q-Value Estimates: 
noop() : -9.32816 (in 46 real visits)
move-west : -8.17659 (in 131 real visits)
move-north : -7.56979 (in 286 real visits)
move-east : -9.5 (in 41 real visits)

Used RAM: 341564

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 25/40 in round 18/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.14437298387097s.
DP-UCT: Maximal search depth set to 16

Search time: 0.0607061s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2413
Cache Hits: 0
Skipped backups: 297768
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0756 (in 2552 runs)
  Maximal search depth: 40
  Cache hits: 64163

Root Node: 
-8.63649 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -16 (in 5 real visits)
move-west : -8.63649 (in 250 real visits)
move-south : -8.68709 (in 230 real visits)
move-north : SOLVED with: -16 (in 5 real visits)
move-east : -13.032 (in 15 real visits)

Used RAM: 341564

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 26/40 in round 18/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 2.14857373737374s.
DP-UCT: Maximal search depth set to 15

Search time: 0.0703759s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2327
Cache Hits: 0
Skipped backups: 299517
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0756 (in 2552 runs)
  Maximal search depth: 40
  Cache hits: 64557

Root Node: 
-8.17421 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -15 (in 5 real visits)
move-west : -8.4266 (in 199 real visits)
move-south : -8.17421 (in 291 real visits)
move-north : SOLVED with: -15 (in 5 real visits)
move-east : SOLVED with: -15 (in 5 real visits)

Used RAM: 341564

Submitted action: move-south 
Immediate reward: -1
***********************************************

***********************************************
Planning step 27/40 in round 18/30
Current state: 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.15277327935223s.
DP-UCT: Maximal search depth set to 14

Search time: 0.0691411s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2452
Cache Hits: 0
Skipped backups: 301128
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0756 (in 2552 runs)
  Maximal search depth: 40
  Cache hits: 64972

Root Node: 
-7.54933 (in 504 real visits)

Q-Value Estimates: 
noop() : -7.54933 (in 173 real visits)
move-west : -7.67562 (in 192 real visits)
move-north : SOLVED with: -14 (in 5 real visits)
move-east : -7.8632 (in 134 real visits)

Used RAM: 341564

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 28/40 in round 18/30
Current state: 1 1 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.15699188640974s.
DP-UCT: Maximal search depth set to 13

Search time: 0.068023s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2479
Cache Hits: 0
Skipped backups: 302748
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0756 (in 2552 runs)
  Maximal search depth: 40
  Cache hits: 65392

Root Node: 
-7.23645 (in 504 real visits)

Q-Value Estimates: 
noop() : -7.35013 (in 148 real visits)
move-west : -7.23645 (in 181 real visits)
move-north : SOLVED with: -13 (in 5 real visits)
move-east : -7.25215 (in 170 real visits)

Used RAM: 341564

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 29/40 in round 18/30
Current state: 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 2.16122967479675s.
DP-UCT: Maximal search depth set to 12

Search time: 0.0730269s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2435
Cache Hits: 0
Skipped backups: 304554
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0756 (in 2552 runs)
  Maximal search depth: 40
  Cache hits: 65812

Root Node: 
-6.9573 (in 503 real visits)

Q-Value Estimates: 
noop() : -6.9573 (in 251 real visits)
move-north : SOLVED with: -12 (in 5 real visits)
move-east : -6.96805 (in 247 real visits)

Used RAM: 341564

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 30/40 in round 18/30
Current state: 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.16547454175153s.
DP-UCT: Maximal search depth set to 11

Search time: 0.0720301s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2435
Cache Hits: 0
Skipped backups: 306384
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0756 (in 2552 runs)
  Maximal search depth: 40
  Cache hits: 66228

Root Node: 
-6.39415 (in 503 real visits)

Q-Value Estimates: 
noop() : -6.46909 (in 230 real visits)
move-north : SOLVED with: -11 (in 5 real visits)
move-east : -6.39415 (in 268 real visits)

Used RAM: 341564

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 31/40 in round 18/30
Current state: 1 1 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.1697387755102s.
DP-UCT: Maximal search depth set to 10

Search time: 0.0685618s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2471
Cache Hits: 0
Skipped backups: 307980
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0756 (in 2552 runs)
  Maximal search depth: 40
  Cache hits: 66645

Root Node: 
-5.88507 (in 504 real visits)

Q-Value Estimates: 
noop() : -6.09573 (in 138 real visits)
move-west : -5.88507 (in 197 real visits)
move-north : SOLVED with: -10 (in 5 real visits)
move-east : -5.98155 (in 164 real visits)

Used RAM: 341564

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 32/40 in round 18/30
Current state: 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.17402658486708s.
DP-UCT: Maximal search depth set to 9

Search time: 0.072818s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2438
Cache Hits: 0
Skipped backups: 309873
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0756 (in 2552 runs)
  Maximal search depth: 40
  Cache hits: 67063

Root Node: 
-5.3674 (in 503 real visits)

Q-Value Estimates: 
noop() : -5.69605 (in 208 real visits)
move-north : SOLVED with: -9 (in 5 real visits)
move-east : -5.3674 (in 290 real visits)

Used RAM: 341564

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 33/40 in round 18/30
Current state: 1 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 2.1783237704918s.
DP-UCT: Maximal search depth set to 8

Search time: 0.073061s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2593
Cache Hits: 0
Skipped backups: 311490
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 67503

Root Node: 
-4.87147 (in 504 real visits)

Q-Value Estimates: 
noop() : -4.87147 (in 200 real visits)
move-west : -4.97312 (in 163 real visits)
move-north : SOLVED with: -8 (in 5 real visits)
move-east : -5.05635 (in 136 real visits)

Used RAM: 341564

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 34/40 in round 18/30
Current state: 1 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.1826386036961s.
DP-UCT: Maximal search depth set to 7

Search time: 0.0675871s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2380
Cache Hits: 0
Skipped backups: 312861
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 67897

Root Node: 
-4.40066 (in 504 real visits)

Q-Value Estimates: 
noop() : -4.40723 (in 135 real visits)
move-west : -4.40066 (in 146 real visits)
move-north : -4.5172 (in 108 real visits)
move-east : -4.48781 (in 115 real visits)

Used RAM: 341564

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 35/40 in round 18/30
Current state: 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 2.18698353909465s.
DP-UCT: Maximal search depth set to 6

Search time: 0.074131s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2537
Cache Hits: 0
Skipped backups: 314370
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 68316

Root Node: 
-3.95446 (in 503 real visits)

Q-Value Estimates: 
noop() : -4.13709 (in 132 real visits)
move-north : -4.06499 (in 159 real visits)
move-east : -3.95446 (in 212 real visits)

Used RAM: 341564

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 36/40 in round 18/30
Current state: 0 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.19132989690722s.
DP-UCT: Maximal search depth set to 5

Search time: 0.063344s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2367
Cache Hits: 0
Skipped backups: 315711
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 68700

Root Node: 
-3.52575 (in 504 real visits)

Q-Value Estimates: 
noop() : -3.53888 (in 125 real visits)
move-west : -3.52575 (in 127 real visits)
move-north : -3.526 (in 126 real visits)
move-east : -3.52816 (in 126 real visits)

Used RAM: 341564

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 37/40 in round 18/30
Current state: 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 2.19571900826446s.
DP-UCT: Maximal search depth set to 4

Search time: 0.0252659s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1397
Cache Hits: 0
Skipped backups: 315948
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 68829

Root Node: 
-3.29088 (in 503 real visits)

Q-Value Estimates: 
noop() : -3.43726 (in 134 real visits)
move-north : -3.37774 (in 158 real visits)
move-east : -3.29088 (in 211 real visits)

Used RAM: 341564

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 38/40 in round 18/30
Current state: 0 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 2.2002049689441s.
DP-UCT: Maximal search depth set to 3

Search time: 0.00407195s
Statistics of DP-UCT:
Performed trials: 272
Created SearchNodes: 477
Cache Hits: 0
Skipped backups: 315948
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 68846

Root Node: 
SOLVED with: -3 (in 276 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -3 (in 69 real visits)
move-west : SOLVED with: -3 (in 53 real visits)
move-north : SOLVED with: -3 (in 85 real visits)
move-east : SOLVED with: -3 (in 69 real visits)

Used RAM: 341564

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 39/40 in round 18/30
Current state: 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 2.2047510373444s.
DP-UCT: Maximal search depth set to 2

Search time: 0.000596046s
Statistics of DP-UCT:
Performed trials: 12
Created SearchNodes: 22
Cache Hits: 0
Skipped backups: 315948
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 68847

Root Node: 
SOLVED with: -2 (in 15 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -2 (in 5 real visits)
move-north : SOLVED with: -2 (in 5 real visits)
move-east : SOLVED with: -2 (in 5 real visits)

Used RAM: 341564

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 40/40 in round 18/30
Current state: 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.2093264033264s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 68847

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 3
Accumulated number of trials in root state: 9000
Accumulated number of search nodes in root state: 45764

Used RAM: 341564

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
>>> END OF ROUND 18 -- REWARD RECEIVED: -40
***********************************************

***********************************************
>>> STARTING ROUND 19 -- REMAINING TIME 1065s
***********************************************
***********************************************
Planning step 1/40 in round 19/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 2.21392083333333s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0599971s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2536
Cache Hits: 0
Skipped backups: 317931
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 69277

Root Node: 
-19.7071 (in 503 real visits)

Q-Value Estimates: 
noop() : -20.9736 (in 150 real visits)
move-west : -19.7071 (in 333 real visits)
move-north : -28.9413 (in 20 real visits)

Used RAM: 341564

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 19/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 2.21832567849687s.
DP-UCT: Maximal search depth set to 39

Search time: 0.045445s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2274
Cache Hits: 0
Skipped backups: 319416
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 69616

Root Node: 
-12.8923 (in 504 real visits)

Q-Value Estimates: 
noop() : -19.8867 (in 20 real visits)
move-west : -18.2652 (in 30 real visits)
move-north : -12.8923 (in 436 real visits)
move-east : -20.42 (in 18 real visits)

Used RAM: 341572

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 19/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 2.22286192468619s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0203681s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1858
Cache Hits: 0
Skipped backups: 320898
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 69864

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -38 (in 5 real visits)
move-west : -15.548 (in 10 real visits)
move-south : -19.5 (in 10 real visits)
move-north : -3 (in 470 real visits)
move-east : -30.6 (in 10 real visits)

Used RAM: 341572

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 19/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.22746960167715s.
DP-UCT: Maximal search depth set to 37

Search time: 0.015729s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1715
Cache Hits: 0
Skipped backups: 322320
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70086

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -37 (in 5 real visits)
move-west : -13.6667 (in 10 real visits)
move-south : SOLVED with: -37 (in 5 real visits)
move-north : -2 (in 475 real visits)
move-east : -23 (in 10 real visits)

Used RAM: 341572

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 19/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 0 

Setting time for this decision to 2.23210924369748s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0159161s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1749
Cache Hits: 0
Skipped backups: 323625
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -5.1 (in 10 real visits)
move-west : -6.42 (in 10 real visits)
move-south : -3 (in 479 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 341572

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 19/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.23676631578947s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 35
StateHashKey: 14680077
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 19/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.24147890295359s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 34
StateHashKey: 2097203
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 19/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.24621141649049s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 33
StateHashKey: 14680076
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 19/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.25096398305085s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 32
StateHashKey: 6291507
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 19/30
Current state: 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.25573885350318s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 31
StateHashKey: 10485788
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 19/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.26053191489362s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 6291495
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 19/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.26534328358209s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 29
StateHashKey: 6291481
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 19/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.27017521367521s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 28
StateHashKey: 10485782
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 19/30
Current state: 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.27502569593148s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 14680101
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 19/30
Current state: 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.2798991416309s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 6291513
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 19/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.28479139784946s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 25
StateHashKey: 14680094
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 19/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.28970474137931s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 24
StateHashKey: 10485815
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 19/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.29463930885529s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 23
StateHashKey: 14680109
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 19/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.29959523809524s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 22
StateHashKey: 14680123
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 19/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.3045748373102s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 21
StateHashKey: 10485822
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 19/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.30957608695652s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 10485807
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 19/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.31459912854031s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 6291499
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 19/30
Current state: 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.31964192139738s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 14680090
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 19/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.3247067833698s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 10485814
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 19/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.32979385964912s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 16
StateHashKey: 10485805
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 19/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.33490549450549s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 6291499
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 19/30
Current state: 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.34003744493392s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 14680090
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 19/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.34519426048565s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 6291510
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 19/30
Current state: 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.35037389380531s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 14680093
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 19/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.35557649667406s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 14680119
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 19/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.3608s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 6291517
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 19/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.36604899777283s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 6291487
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 19/30
Current state: 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.37131919642857s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 6291479
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 19/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.3766129753915s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 7
StateHashKey: 14680085
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 19/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.38193273542601s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 10485813
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 19/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.38727415730337s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 2097197
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 19/30
Current state: 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.39264189189189s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 4
StateHashKey: 14680075
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 19/30
Current state: 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.3980316027088s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 14680114
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 19/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.40344796380091s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 2097212
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 19/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.40888662131519s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70311

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 3
Accumulated number of trials in root state: 9500
Accumulated number of search nodes in root state: 48300

Used RAM: 341572

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 19 -- REWARD RECEIVED: -5
***********************************************

***********************************************
>>> STARTING ROUND 20 -- REMAINING TIME 1065s
***********************************************
***********************************************
Planning step 1/40 in round 20/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 2.41435227272727s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0591629s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2531
Cache Hits: 0
Skipped backups: 325578
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 70740

Root Node: 
-18.9646 (in 503 real visits)

Q-Value Estimates: 
noop() : -20.7494 (in 135 real visits)
move-west : -18.9646 (in 357 real visits)
move-north : -31.64 (in 11 real visits)

Used RAM: 341572

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 20/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 2.4196264236902s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0477059s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2280
Cache Hits: 0
Skipped backups: 327015
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71085

Root Node: 
-13.0871 (in 504 real visits)

Q-Value Estimates: 
noop() : -20.5 (in 26 real visits)
move-west : -18.0543 (in 51 real visits)
move-north : -13.0871 (in 402 real visits)
move-east : -20.5 (in 25 real visits)

Used RAM: 341580

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 20/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 2.42503424657534s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0184951s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1838
Cache Hits: 0
Skipped backups: 328503
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71328

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -38 (in 5 real visits)
move-west : -15.62 (in 10 real visits)
move-south : -19.5 (in 10 real visits)
move-north : -3 (in 470 real visits)
move-east : -30.6 (in 10 real visits)

Used RAM: 341580

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 20/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.43053089244851s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0156579s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1692
Cache Hits: 0
Skipped backups: 329853
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71545

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -37 (in 5 real visits)
move-west : -13.6667 (in 10 real visits)
move-south : SOLVED with: -37 (in 5 real visits)
move-north : -2 (in 475 real visits)
move-east : -23 (in 10 real visits)

Used RAM: 341580

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 20/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 1 1 

Setting time for this decision to 2.4360619266055s.
DP-UCT: Maximal search depth set to 36

Search time: 0.015754s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1754
Cache Hits: 0
Skipped backups: 331392
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 484 real visits)
move-west : -9.74667 (in 10 real visits)
move-south : SOLVED with: -36 (in 5 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 341580

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 20/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.44161609195402s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 35
StateHashKey: 6291517
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 20/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.44723271889401s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 34
StateHashKey: 14680095
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 20/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.4528752886836s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 33
StateHashKey: 6291511
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 20/30
Current state: 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.45854398148148s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 32
StateHashKey: 2097181
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 20/30
Current state: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.46423897911833s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 31
StateHashKey: 14680071
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 20/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.46996046511628s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 30
StateHashKey: 10485809
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 20/30
Current state: 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.47570862470862s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 10485804
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 20/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.48148364485981s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 28
StateHashKey: 10485803
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 20/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.48728571428571s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 10485802
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 20/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.49311502347418s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 26
StateHashKey: 10485802
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 20/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.49897176470588s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 25
StateHashKey: 10485802
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 20/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.50485613207547s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 6291498
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 20/30
Current state: 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.510768321513s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 23
StateHashKey: 14680090
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 20/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.51670853080569s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 22
StateHashKey: 10485814
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 20/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.52267695961995s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 6291501
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 20/30
Current state: 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.52867380952381s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 20
StateHashKey: 6291483
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 20/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.53469928400955s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 2097174
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 20/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.54075358851675s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 14680069
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 20/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.54683693045564s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 14680113
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 20/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.55294951923077s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 16
StateHashKey: 14680124
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 20/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.55909156626506s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 15
StateHashKey: 10485823
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 20/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.56526328502415s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 10485807
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 20/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.57146489104116s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 6291499
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 20/30
Current state: 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.57769660194175s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 14680090
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 20/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.58395863746959s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 14680118
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 20/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.59025121951219s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 10
StateHashKey: 10485821
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 20/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.59657457212714s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 9
StateHashKey: 14680111
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 20/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.60292647058824s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 8
StateHashKey: 14680123
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 20/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.60930712530713s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 7
StateHashKey: 10485822
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 20/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.61572167487685s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 14680111
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 20/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.62216790123457s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 5
StateHashKey: 14680123
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 20/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.62864603960396s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 4
StateHashKey: 10485822
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 20/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.63515632754342s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 10485807
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 20/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.64169900497512s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 10485803
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 20/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.64827680798005s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 71776

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 3
Accumulated number of trials in root state: 10000
Accumulated number of search nodes in root state: 50831

Used RAM: 341580

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 20 -- REWARD RECEIVED: -5
***********************************************

***********************************************
>>> STARTING ROUND 21 -- REMAINING TIME 1064s
***********************************************
***********************************************
Planning step 1/40 in round 21/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 2.654885s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0597529s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2526
Cache Hits: 0
Skipped backups: 333324
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0709 (in 2553 runs)
  Maximal search depth: 40
  Cache hits: 72200

Root Node: 
-19.3775 (in 503 real visits)

Q-Value Estimates: 
noop() : -21.0178 (in 134 real visits)
move-west : -19.3775 (in 359 real visits)
move-north : -32.2 (in 10 real visits)

Used RAM: 341580

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 21/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.66128320802005s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0627658s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2488
Cache Hits: 0
Skipped backups: 335067
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0783 (in 2554 runs)
  Maximal search depth: 40
  Cache hits: 72623

Root Node: 
-19.143 (in 504 real visits)

Q-Value Estimates: 
noop() : -19.6802 (in 170 real visits)
move-west : -19.143 (in 216 real visits)
move-north : SOLVED with: -39 (in 5 real visits)
move-east : -20.429 (in 113 real visits)

Used RAM: 341580

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 21/30
Current state: 1 1 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 2.66779899497487s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0741692s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2633
Cache Hits: 0
Skipped backups: 336870
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 73069

Root Node: 
-17.0937 (in 504 real visits)

Q-Value Estimates: 
noop() : -17.0937 (in 270 real visits)
move-west : -18.1215 (in 144 real visits)
move-north : SOLVED with: -38 (in 5 real visits)
move-east : -19.1456 (in 85 real visits)

Used RAM: 341580

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 21/30
Current state: 1 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.67432493702771s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0661662s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2428
Cache Hits: 0
Skipped backups: 338283
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 73468

Root Node: 
-17.8889 (in 504 real visits)

Q-Value Estimates: 
noop() : -18.0138 (in 147 real visits)
move-west : -17.8889 (in 150 real visits)
move-north : -19.1895 (in 77 real visits)
move-east : -17.9783 (in 130 real visits)

Used RAM: 341584

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 21/30
Current state: 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 2.68090151515152s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0749118s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2615
Cache Hits: 0
Skipped backups: 339819
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 73902

Root Node: 
-15.8398 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.739 (in 120 real visits)
move-north : -16.3616 (in 140 real visits)
move-east : -15.8398 (in 243 real visits)

Used RAM: 341584

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 21/30
Current state: 0 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 2.68748860759494s.
DP-UCT: Maximal search depth set to 35

Search time: 0.073211s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2648
Cache Hits: 0
Skipped backups: 341313
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 74339

Root Node: 
-15.6621 (in 504 real visits)

Q-Value Estimates: 
noop() : -16.0058 (in 139 real visits)
move-west : -16.1895 (in 124 real visits)
move-north : -15.6621 (in 171 real visits)
move-east : -17.3432 (in 70 real visits)

Used RAM: 341584

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 21/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 2.6941116751269s.
DP-UCT: Maximal search depth set to 34

Search time: 0.053915s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2389
Cache Hits: 0
Skipped backups: 342681
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 74699

Root Node: 
-11.8243 (in 505 real visits)

Q-Value Estimates: 
noop() : -16.3108 (in 55 real visits)
move-west : -16.5589 (in 39 real visits)
move-south : -16.3708 (in 42 real visits)
move-north : SOLVED with: -34 (in 5 real visits)
move-east : -11.8243 (in 364 real visits)

Used RAM: 341584

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 21/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 2.70081933842239s.
DP-UCT: Maximal search depth set to 33

Search time: 0.0179269s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1714
Cache Hits: 0
Skipped backups: 343914
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 74916

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -33 (in 5 real visits)
move-west : -13.512 (in 10 real visits)
move-south : -17.18 (in 10 real visits)
move-north : -3 (in 470 real visits)
move-east : -25.44 (in 10 real visits)

Used RAM: 341584

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 9/40 in round 21/30
Current state: 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 0 

Setting time for this decision to 2.7076556122449s.
DP-UCT: Maximal search depth set to 32

Search time: 0.0169291s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1801
Cache Hits: 0
Skipped backups: 345444
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75160

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -9.5 (in 10 real visits)
move-west : -12.25 (in 10 real visits)
move-south : SOLVED with: -32 (in 5 real visits)
move-north : -2 (in 470 real visits)
move-east : -20 (in 10 real visits)

Used RAM: 341584

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 10/40 in round 21/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 1 0 

Setting time for this decision to 2.71452685421995s.
DP-UCT: Maximal search depth set to 31

Search time: 0.0158651s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1839
Cache Hits: 0
Skipped backups: 346812
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 140 real visits)
move-west : -3 (in 351 real visits)
move-south : -9.25 (in 8 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 341584

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 11/40 in round 21/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.7214358974359s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 30
StateHashKey: 14680085
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 21/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.72842159383033s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 29
StateHashKey: 6291509
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 21/30
Current state: 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.73544329896907s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 28
StateHashKey: 10485789
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 21/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.74250129198966s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 14680103
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 21/30
Current state: 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.74959585492228s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 26
StateHashKey: 14680121
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 21/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.75672467532468s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 25
StateHashKey: 14680126
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 21/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.763890625s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 6291519
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 21/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.77109660574413s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 23
StateHashKey: 14680095
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 21/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.77834031413613s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 6291511
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 21/30
Current state: 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.78561942257218s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 21
StateHashKey: 10485789
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 21/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.79293947368421s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 20
StateHashKey: 6291495
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 21/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.8002981530343s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 10485785
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 21/30
Current state: 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.80769312169312s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 6291494
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 21/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.81512732095491s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 17
StateHashKey: 6291481
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 21/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.82260106382979s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 2097174
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 21/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.83011733333333s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 6291461
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 21/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.83767112299465s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 10485777
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 21/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.84526809651475s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 13
StateHashKey: 10485796
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 21/30
Current state: 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.85290322580645s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 14680105
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 21/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.86058221024259s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 14680122
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 21/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.8683s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 10
StateHashKey: 10485822
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 21/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.87605962059621s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 9
StateHashKey: 10485807
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 21/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.88386413043478s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 8
StateHashKey: 14680107
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 21/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.89170844686649s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 7
StateHashKey: 14680122
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 21/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.89959836065574s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 14680126
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 21/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.90753150684932s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 5
StateHashKey: 14680127
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 21/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.91550549450549s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 2097215
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 21/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.92352341597796s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 14680079
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 21/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.93158563535912s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 6291507
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 21/30
Current state: 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.93969529085873s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75409

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 3
Accumulated number of trials in root state: 10500
Accumulated number of search nodes in root state: 53357

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 21 -- REWARD RECEIVED: -10
***********************************************

***********************************************
>>> STARTING ROUND 22 -- REMAINING TIME 1064s
***********************************************
***********************************************
Planning step 1/40 in round 22/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 2.94784722222222s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0588479s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2539
Cache Hits: 0
Skipped backups: 348672
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 75834

Root Node: 
-18.4926 (in 503 real visits)

Q-Value Estimates: 
noop() : -20.9952 (in 108 real visits)
move-west : -18.4926 (in 383 real visits)
move-north : -30.5 (in 12 real visits)

Used RAM: 341584

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 22/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 2.95577437325905s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0489309s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2348
Cache Hits: 0
Skipped backups: 350124
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0853 (in 2555 runs)
  Maximal search depth: 40
  Cache hits: 76191

Root Node: 
-12.9846 (in 504 real visits)

Q-Value Estimates: 
noop() : -20.124 (in 25 real visits)
move-west : -18.1913 (in 47 real visits)
move-north : -12.9846 (in 409 real visits)
move-east : -20.38 (in 23 real visits)

Used RAM: 341584

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 22/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 2.96388268156425s.
DP-UCT: Maximal search depth set to 38

Search time: 0.018492s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1813
Cache Hits: 0
Skipped backups: 351501
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0927 (in 2556 runs)
  Maximal search depth: 40
  Cache hits: 76425

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -15.656 (in 10 real visits)
move-west : -15.572 (in 10 real visits)
move-south : -18.9 (in 10 real visits)
move-north : -3 (in 465 real visits)
move-east : -29.72 (in 10 real visits)

Used RAM: 341584

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 22/30
Current state: 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 1 

Setting time for this decision to 2.97212324929972s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0153871s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1653
Cache Hits: 0
Skipped backups: 352686
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76628

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -37 (in 5 real visits)
move-west : -13.1467 (in 10 real visits)
move-south : -14.52 (in 10 real visits)
move-north : -2 (in 470 real visits)
move-east : -23 (in 10 real visits)

Used RAM: 341584

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 22/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 1 

Setting time for this decision to 2.98041573033708s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0155909s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1726
Cache Hits: 0
Skipped backups: 354150
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 484 real visits)
move-west : -8.88 (in 10 real visits)
move-south : SOLVED with: -36 (in 5 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 341584

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 22/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.98875774647887s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 35
StateHashKey: 2097192
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 22/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.99718926553672s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 34
StateHashKey: 10485770
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 22/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 3.00566855524079s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 33
StateHashKey: 10485794
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 22/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.01419886363636s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 32
StateHashKey: 14680104
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 22/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 3.02277207977208s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 31
StateHashKey: 10485818
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 22/30
Current state: 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.03139428571429s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 6291502
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 22/30
Current state: 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 3.0400659025788s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 10485787
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 22/30
Current state: 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.04878735632184s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 28
StateHashKey: 14680102
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 22/30
Current state: 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.05756195965418s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 14680121
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 22/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.06638439306358s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 6291518
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 22/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.07526086956522s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 2097183
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 22/30
Current state: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.08418895348837s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 24
StateHashKey: 14680071
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 22/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.09316618075802s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 6291505
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 22/30
Current state: 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.10219590643275s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 6291484
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 22/30
Current state: 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.11128152492669s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 21
StateHashKey: 14680087
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 22/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.12041764705882s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 14680117
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 22/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.12960766961652s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 2097213
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 22/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.1388550295858s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 14680079
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 22/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.14815727002967s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 17
StateHashKey: 6291507
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 22/30
Current state: 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.15751488095238s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 16
StateHashKey: 14680092
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 22/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.16693134328358s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 15
StateHashKey: 14680119
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 22/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.17640119760479s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 2097213
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 22/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.18592792792793s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 13
StateHashKey: 14680079
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 22/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.19551807228916s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 2097203
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 22/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.20516012084592s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 14680076
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 22/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.21486060606061s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 6291507
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 22/30
Current state: 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.2246170212766s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 6291484
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 22/30
Current state: 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.23443292682927s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 8
StateHashKey: 14680087
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 22/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.24430886850153s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 2097205
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 22/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.25424846625767s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 14680077
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 22/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 3.26424923076923s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 5
StateHashKey: 10485811
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 22/30
Current state: 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.27431172839506s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 6291500
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 22/30
Current state: 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.28443343653251s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 3
StateHashKey: 6291483
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 22/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.29461801242236s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 14680086
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 22/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.3048691588785s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 17.1001 (in 2557 runs)
  Maximal search depth: 40
  Cache hits: 76853

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 3
Accumulated number of trials in root state: 11000
Accumulated number of search nodes in root state: 55896

Used RAM: 341584

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 22 -- REWARD RECEIVED: -5
***********************************************

***********************************************
>>> STARTING ROUND 23 -- REMAINING TIME 1063s
***********************************************
***********************************************
Planning step 1/40 in round 23/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 3.31518125s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0625451s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2566
Cache Hits: 0
Skipped backups: 356115
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0942 (in 2558 runs)
  Maximal search depth: 40
  Cache hits: 77288

Root Node: 
-19.2756 (in 503 real visits)

Q-Value Estimates: 
noop() : -20.2402 (in 173 real visits)
move-west : -19.2756 (in 319 real visits)
move-north : -31.18 (in 11 real visits)

Used RAM: 341584

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 23/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 3.32524764890282s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0484769s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2319
Cache Hits: 0
Skipped backups: 357582
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0942 (in 2558 runs)
  Maximal search depth: 40
  Cache hits: 77640

Root Node: 
-12.4016 (in 504 real visits)

Q-Value Estimates: 
noop() : -20.3 (in 22 real visits)
move-west : -17.672 (in 51 real visits)
move-north : -12.4016 (in 409 real visits)
move-east : -20.38 (in 22 real visits)

Used RAM: 341592

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 23/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 3.33554088050314s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0625081s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2416
Cache Hits: 0
Skipped backups: 359247
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0942 (in 2558 runs)
  Maximal search depth: 40
  Cache hits: 78030

Root Node: 
-17.9557 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -38 (in 5 real visits)
move-west : -17.9557 (in 306 real visits)
move-south : -18.7284 (in 179 real visits)
move-north : SOLVED with: -38 (in 5 real visits)
move-east : -30.288 (in 10 real visits)

Used RAM: 341592

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 23/30
Current state: 1 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 3.34585488958991s.
DP-UCT: Maximal search depth set to 37

Search time: 0.071919s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2400
Cache Hits: 0
Skipped backups: 361002
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0942 (in 2558 runs)
  Maximal search depth: 40
  Cache hits: 78438

Root Node: 
-18.2748 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -37 (in 5 real visits)
move-west : -18.2748 (in 235 real visits)
move-south : -18.3344 (in 255 real visits)
move-north : SOLVED with: -37 (in 5 real visits)
move-east : SOLVED with: -37 (in 5 real visits)

Used RAM: 341592

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 23/30
Current state: 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 3.35620253164557s.
DP-UCT: Maximal search depth set to 36

Search time: 0.078043s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2518
Cache Hits: 0
Skipped backups: 363048
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0993 (in 2569 runs)
  Maximal search depth: 40
  Cache hits: 78859

Root Node: 
-17.2756 (in 504 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -36 (in 5 real visits)
move-south : -17.2756 (in 489 real visits)
move-north : SOLVED with: -36 (in 5 real visits)
move-east : SOLVED with: -36 (in 5 real visits)

Used RAM: 341592

Submitted action: move-south 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 23/30
Current state: 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 3.36659682539683s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0720019s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2431
Cache Hits: 0
Skipped backups: 364674
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0913 (in 2575 runs)
  Maximal search depth: 40
  Cache hits: 79272

Root Node: 
-15.3174 (in 503 real visits)

Q-Value Estimates: 
noop() : -15.3174 (in 388 real visits)
move-north : SOLVED with: -35 (in 5 real visits)
move-east : -17.0213 (in 110 real visits)

Used RAM: 341604

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 23/30
Current state: 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 3.37707643312102s.
DP-UCT: Maximal search depth set to 34

Search time: 0.0509851s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2363
Cache Hits: 0
Skipped backups: 366204
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0608 (in 2581 runs)
  Maximal search depth: 40
  Cache hits: 79667

Root Node: 
-13.6109 (in 503 real visits)

Q-Value Estimates: 
noop() : -17.447 (in 42 real visits)
move-north : -13.6109 (in 411 real visits)
move-east : -17.3586 (in 50 real visits)

Used RAM: 341612

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 23/30
Current state: 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 3.38769329073482s.
DP-UCT: Maximal search depth set to 33

Search time: 0.028723s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2062
Cache Hits: 0
Skipped backups: 367371
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0104 (in 2591 runs)
  Maximal search depth: 40
  Cache hits: 79978

Root Node: 
-8.06282 (in 504 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -33 (in 5 real visits)
move-south : -14.7931 (in 36 real visits)
move-north : -8.06282 (in 458 real visits)
move-east : SOLVED with: -33 (in 5 real visits)

Used RAM: 341616

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 9/40 in round 23/30
Current state: 1 0 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 3.39844551282051s.
DP-UCT: Maximal search depth set to 32

Search time: 0.017072s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1651
Cache Hits: 0
Skipped backups: 368589
Initialization: 
  Statistics of IDS:
  Average search depth: 17.0104 (in 2591 runs)
  Maximal search depth: 40
  Cache hits: 80189

Root Node: 
-4.0576 (in 504 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -32 (in 5 real visits)
move-south : SOLVED with: -32 (in 5 real visits)
move-north : -4.0576 (in 489 real visits)
move-east : SOLVED with: -32 (in 5 real visits)

Used RAM: 341620

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 10/40 in round 23/30
Current state: 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 3.40930546623794s.
DP-UCT: Maximal search depth set to 31

Search time: 0.018997s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1867
Cache Hits: 0
Skipped backups: 370272
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80443

Root Node: 
-3 (in 503 real visits)

Q-Value Estimates: 
noop() : -11.9 (in 10 real visits)
move-south : SOLVED with: -31 (in 5 real visits)
move-east : -3 (in 488 real visits)

Used RAM: 341620

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 11/40 in round 23/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 3.42022903225806s.
DP-UCT: Maximal search depth set to 30

Search time: 0.0176671s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1848
Cache Hits: 0
Skipped backups: 371904
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80697

Root Node: 
-2 (in 504 real visits)

Q-Value Estimates: 
noop() : -9.136 (in 10 real visits)
move-west : -11.55 (in 10 real visits)
move-south : -11.55 (in 10 real visits)
move-east : -2 (in 474 real visits)

Used RAM: 341624

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 12/40 in round 23/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 1 1 

Setting time for this decision to 3.43122977346278s.
DP-UCT: Maximal search depth set to 29

Search time: 0.0161951s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1829
Cache Hits: 0
Skipped backups: 373476
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 484 real visits)
move-west : -4.38 (in 10 real visits)
move-south : SOLVED with: -29 (in 5 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 341624

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 13/40 in round 23/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.44230519480519s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 28
StateHashKey: 14680124
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 23/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.45350488599349s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 27
StateHashKey: 6291519
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 23/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.46477777777778s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 26
StateHashKey: 14680095
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 23/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.47612459016393s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 6291511
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 23/30
Current state: 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.48754276315789s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 24
StateHashKey: 14680093
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 23/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.49903630363036s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 23
StateHashKey: 14680119
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 23/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.51060927152318s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 22
StateHashKey: 14680125
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 23/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 3.52225581395349s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 21
StateHashKey: 10485823
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 23/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 3.53398333333333s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 10485807
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 23/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.54578929765886s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 14680107
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 23/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.5576711409396s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 14680122
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 23/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.569632996633s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 14680126
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 23/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.58167905405405s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 2097215
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 23/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.59380677966102s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 6291471
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 23/30
Current state: 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.60601700680272s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 14680083
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 23/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.61830716723549s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 13
StateHashKey: 14680116
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 23/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.63068493150685s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 14680125
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 23/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.64314432989691s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 6291519
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 23/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.65569310344828s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 6291487
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 23/30
Current state: 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.66832525951557s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 9
StateHashKey: 14680087
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 23/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 3.68104513888889s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 8
StateHashKey: 10485813
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 23/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.69385714285714s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 7
StateHashKey: 14680109
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 23/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.70675874125874s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 2097211
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 23/30
Current state: 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.71974736842105s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 2097166
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 23/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.73283098591549s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 4
StateHashKey: 14680067
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 23/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.74600706713781s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 14680112
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 23/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 3.75927304964539s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 10485820
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 23/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.7726334519573s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 80941

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 3
Accumulated number of trials in root state: 11500
Accumulated number of search nodes in root state: 58462

Used RAM: 341624

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 23 -- REWARD RECEIVED: -12
***********************************************

***********************************************
>>> STARTING ROUND 24 -- REMAINING TIME 1063s
***********************************************
***********************************************
Planning step 1/40 in round 24/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 3.78609285714286s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0584381s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2549
Cache Hits: 0
Skipped backups: 375411
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 81368

Root Node: 
-18.7965 (in 503 real visits)

Q-Value Estimates: 
noop() : -21.0374 (in 111 real visits)
move-west : -18.7965 (in 382 real visits)
move-north : -32.2 (in 10 real visits)

Used RAM: 341624

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 24/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 3.7993082437276s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0487139s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2309
Cache Hits: 0
Skipped backups: 376776
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 81715

Root Node: 
-12.4574 (in 504 real visits)

Q-Value Estimates: 
noop() : -20.084 (in 25 real visits)
move-west : -17.3464 (in 58 real visits)
move-north : -12.4574 (in 397 real visits)
move-east : -20.3 (in 24 real visits)

Used RAM: 341640

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 24/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 3.81278776978417s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0443718s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2253
Cache Hits: 0
Skipped backups: 378168
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82048

Root Node: 
-12.8117 (in 505 real visits)

Q-Value Estimates: 
noop() : -12.8117 (in 421 real visits)
move-west : -16.8354 (in 44 real visits)
move-south : -18.792 (in 26 real visits)
move-north : SOLVED with: -38 (in 5 real visits)
move-east : -30.6 (in 9 real visits)

Used RAM: 341640

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 24/30
Current state: 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 3.82637906137184s.
DP-UCT: Maximal search depth set to 37

Search time: 0.01826s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1887
Cache Hits: 0
Skipped backups: 379701
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82303

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -37 (in 5 real visits)
move-west : -15.125 (in 10 real visits)
move-south : -19.2 (in 10 real visits)
move-north : -3 (in 470 real visits)
move-east : -28.87 (in 10 real visits)

Used RAM: 341640

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 24/30
Current state: 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 0 

Setting time for this decision to 3.84015942028986s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0148339s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1641
Cache Hits: 0
Skipped backups: 380853
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82506

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -10.8467 (in 10 real visits)
move-west : -13.3233 (in 10 real visits)
move-south : SOLVED with: -36 (in 5 real visits)
move-north : -2 (in 470 real visits)
move-east : -23.64 (in 10 real visits)

Used RAM: 341640

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 24/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 1 

Setting time for this decision to 3.85405818181818s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0151901s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1691
Cache Hits: 0
Skipped backups: 382233
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 484 real visits)
move-west : -9.01733 (in 10 real visits)
move-south : SOLVED with: -35 (in 5 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 341640

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 24/30
Current state: 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.86805474452555s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 34
StateHashKey: 6291493
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 24/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.88220879120879s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 33
StateHashKey: 14680089
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 24/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.89646691176471s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 32
StateHashKey: 14680118
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 24/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.91083025830258s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 31
StateHashKey: 6291517
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 24/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 3.9253s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 30
StateHashKey: 10485791
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 24/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.93987732342007s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 14680103
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 24/30
Current state: 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.95456343283582s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 6291513
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 24/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.96935580524345s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 27
StateHashKey: 6291486
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 24/30
Current state: 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.98425939849624s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 6291479
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 24/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.99927924528302s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 25
StateHashKey: 14680085
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 24/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 4.01440909090909s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 24
StateHashKey: 10485813
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 24/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 4.02965779467681s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 23
StateHashKey: 14680109
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 24/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 4.04501908396947s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 22
StateHashKey: 14680123
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 24/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.06048659003831s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 2097214
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 24/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 4.07608461538462s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 10485775
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 24/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 4.09180308880309s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 10485795
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 24/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 4.10764341085271s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 10485800
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 24/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 4.12360700389105s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 14680106
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 24/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 4.13969921875s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 6291514
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 24/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 4.1559137254902s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 15
StateHashKey: 14680094
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 24/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 4.17225984251968s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 6291511
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 24/30
Current state: 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 4.18873122529644s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 6291485
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 24/30
Current state: 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.2053373015873s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 2097175
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 24/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 4.22207569721116s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 14680069
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 24/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 4.238948s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 10
StateHashKey: 10485809
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 24/30
Current state: 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 4.25595180722892s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 9
StateHashKey: 14680108
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 24/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 4.27309274193548s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 8
StateHashKey: 10485819
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 24/30
Current state: 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 4.29037246963563s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 6291502
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 24/30
Current state: 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 4.30779268292683s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 10485787
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 24/30
Current state: 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 4.32535510204082s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 5
StateHashKey: 14680102
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 24/30
Current state: 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 4.34306147540984s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 6291513
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 24/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 4.36091769547325s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 14680094
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 24/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 4.3789173553719s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 14680119
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 24/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 4.39706639004149s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 82723

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 3
Accumulated number of trials in root state: 12000
Accumulated number of search nodes in root state: 61011

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 24 -- REWARD RECEIVED: -6
***********************************************

***********************************************
>>> STARTING ROUND 25 -- REMAINING TIME 1062s
***********************************************
***********************************************
Planning step 1/40 in round 25/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 4.41537083333333s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0600741s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2518
Cache Hits: 0
Skipped backups: 384135
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 83150

Root Node: 
-18.6588 (in 503 real visits)

Q-Value Estimates: 
noop() : -20.7467 (in 142 real visits)
move-west : -18.6588 (in 351 real visits)
move-north : -32.2 (in 10 real visits)

Used RAM: 341640

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 25/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 4.43341422594142s.
DP-UCT: Maximal search depth set to 39

Search time: 0.047976s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2306
Cache Hits: 0
Skipped backups: 385578
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 83498

Root Node: 
-13.2765 (in 504 real visits)

Q-Value Estimates: 
noop() : -19.76 (in 22 real visits)
move-west : -17.2086 (in 54 real visits)
move-north : -13.2765 (in 409 real visits)
move-east : -20.3 (in 19 real visits)

Used RAM: 341640

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 25/30
Current state: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 4.45182352941177s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0597649s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2397
Cache Hits: 0
Skipped backups: 387150
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 83882

Root Node: 
-18.128 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -38 (in 5 real visits)
move-west : -18.128 (in 297 real visits)
move-south : -18.775 (in 188 real visits)
move-north : SOLVED with: -38 (in 5 real visits)
move-east : -29.96 (in 10 real visits)

Used RAM: 341640

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 25/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 4.47033755274262s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0466731s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2285
Cache Hits: 0
Skipped backups: 388623
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84219

Root Node: 
-11.8656 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -37 (in 5 real visits)
move-west : -17.98 (in 26 real visits)
move-south : -17.956 (in 26 real visits)
move-north : SOLVED with: -37 (in 5 real visits)
move-east : -11.8656 (in 443 real visits)

Used RAM: 341640

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 25/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 4.48906779661017s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0178249s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1749
Cache Hits: 0
Skipped backups: 389898
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84440

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -36 (in 5 real visits)
move-west : -14.75 (in 10 real visits)
move-south : -18.5 (in 10 real visits)
move-north : -3 (in 470 real visits)
move-east : -29.12 (in 10 real visits)

Used RAM: 341640

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 25/30
Current state: 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 1 

Setting time for this decision to 4.50807659574468s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0156171s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1746
Cache Hits: 0
Skipped backups: 391389
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84670

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -35 (in 5 real visits)
move-west : -13 (in 10 real visits)
move-south : SOLVED with: -35 (in 5 real visits)
move-north : -2 (in 475 real visits)
move-east : -21.8 (in 10 real visits)

Used RAM: 341640

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 25/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 1 1 

Setting time for this decision to 4.52726068376068s.
DP-UCT: Maximal search depth set to 34

Search time: 0.0151439s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1716
Cache Hits: 0
Skipped backups: 392871
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 484 real visits)
move-west : -8.848 (in 10 real visits)
move-south : SOLVED with: -34 (in 5 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 341640

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 25/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 4.54660515021459s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 33
StateHashKey: 6291517
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 25/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 4.56618965517241s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 32
StateHashKey: 6291487
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 25/30
Current state: 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 4.58593939393939s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 31
StateHashKey: 10485783
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 25/30
Current state: 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 4.60586086956522s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 30
StateHashKey: 14680101
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 25/30
Current state: 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 4.62595633187773s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 29
StateHashKey: 6291513
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 25/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 4.64622368421053s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 28
StateHashKey: 10485790
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 25/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 4.66667400881057s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 14680103
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 25/30
Current state: 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 4.68730088495575s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 6291513
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 25/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.70811111111111s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 2097182
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 25/30
Current state: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.72911160714286s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 2097159
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 25/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 4.75029596412556s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 23
StateHashKey: 14680065
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 25/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 4.77167567567568s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 22
StateHashKey: 14680112
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 25/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 4.79324886877828s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 21
StateHashKey: 10485820
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 25/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.81501818181818s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 20
StateHashKey: 2097199
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 25/30
Current state: 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 4.83698173515982s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 6291467
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 25/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 4.85914678899083s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 14680082
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 25/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 4.88152073732719s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 14680116
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 25/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 4.90409722222222s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 6291517
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 25/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 4.92688372093023s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 15
StateHashKey: 14680095
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 25/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 4.94988785046729s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 14680119
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 25/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 4.97310798122066s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 6291517
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 25/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 4.99654716981132s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 10485791
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 25/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 5.02020379146919s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 10485799
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 25/30
Current state: 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 5.04408571428571s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 6291497
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 25/30
Current state: 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 5.0682009569378s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 6291482
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 25/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 5.09254326923077s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 8
StateHashKey: 14680086
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 25/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 5.11712077294686s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 7
StateHashKey: 14680117
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 25/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 5.14194174757282s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 14680125
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 25/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 5.16700487804878s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 6291519
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 25/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 5.1923137254902s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 4
StateHashKey: 10485791
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 25/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 5.21786699507389s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 14680103
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 25/30
Current state: 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 5.24367326732673s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 10485817
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 25/30
Current state: 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 5.26974129353234s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 84893

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 3
Accumulated number of trials in root state: 12500
Accumulated number of search nodes in root state: 63529

Used RAM: 341640

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 25 -- REWARD RECEIVED: -7
***********************************************

***********************************************
>>> STARTING ROUND 26 -- REMAINING TIME 1062s
***********************************************
***********************************************
Planning step 1/40 in round 26/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 5.296065s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0610142s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2557
Cache Hits: 0
Skipped backups: 394908
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 85327

Root Node: 
-19.7161 (in 503 real visits)

Q-Value Estimates: 
noop() : -20.3679 (in 197 real visits)
move-west : -19.7161 (in 295 real visits)
move-north : -32.32 (in 11 real visits)

Used RAM: 341640

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 26/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 5.3221608040201s.
DP-UCT: Maximal search depth set to 39

Search time: 0.061945s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2510
Cache Hits: 0
Skipped backups: 396666
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 85755

Root Node: 
-18.4766 (in 504 real visits)

Q-Value Estimates: 
noop() : -19.5581 (in 171 real visits)
move-west : -18.4766 (in 215 real visits)
move-north : SOLVED with: -39 (in 5 real visits)
move-east : -20.4208 (in 113 real visits)

Used RAM: 341644

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 26/30
Current state: 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 5.34871212121212s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0696421s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2503
Cache Hits: 0
Skipped backups: 398415
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 86183

Root Node: 
-17.4525 (in 504 real visits)

Q-Value Estimates: 
noop() : -18.6179 (in 147 real visits)
move-west : -17.4525 (in 229 real visits)
move-north : SOLVED with: -38 (in 5 real visits)
move-east : -18.9688 (in 123 real visits)

Used RAM: 341644

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 26/30
Current state: 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 5.37548730964467s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0719049s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2483
Cache Hits: 0
Skipped backups: 400254
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 86608

Root Node: 
-18.1504 (in 503 real visits)

Q-Value Estimates: 
noop() : -18.1504 (in 301 real visits)
move-north : SOLVED with: -37 (in 5 real visits)
move-east : -18.6084 (in 197 real visits)

Used RAM: 341644

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 26/30
Current state: 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 5.4025306122449s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0733099s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2476
Cache Hits: 0
Skipped backups: 402003
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 87034

Root Node: 
-17.3225 (in 503 real visits)

Q-Value Estimates: 
noop() : -17.3834 (in 243 real visits)
move-north : SOLVED with: -36 (in 5 real visits)
move-east : -17.3225 (in 255 real visits)

Used RAM: 341644

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 26/30
Current state: 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 5.42984102564102s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0739019s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2643
Cache Hits: 0
Skipped backups: 403728
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 87484

Root Node: 
-16.2115 (in 504 real visits)

Q-Value Estimates: 
noop() : -16.2115 (in 208 real visits)
move-west : -16.2567 (in 194 real visits)
move-north : SOLVED with: -35 (in 5 real visits)
move-east : -17.4587 (in 97 real visits)

Used RAM: 341644

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 26/30
Current state: 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 5.45742783505155s.
DP-UCT: Maximal search depth set to 34

Search time: 0.0715399s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2611
Cache Hits: 0
Skipped backups: 405141
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9804 (in 2597 runs)
  Maximal search depth: 40
  Cache hits: 87911

Root Node: 
-14.3401 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.2579 (in 148 real visits)
move-west : -16.0926 (in 83 real visits)
move-north : -14.3401 (in 234 real visits)
move-east : -17.744 (in 39 real visits)

Used RAM: 341644

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 26/30
Current state: 1 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 5.48531606217617s.
DP-UCT: Maximal search depth set to 33

Search time: 0.058362s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2457
Cache Hits: 0
Skipped backups: 406329
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9746 (in 2598 runs)
  Maximal search depth: 40
  Cache hits: 88288

Root Node: 
-11.9096 (in 505 real visits)

Q-Value Estimates: 
noop() : -14.3997 (in 91 real visits)
move-west : -14.5109 (in 105 real visits)
move-south : -16.224 (in 40 real visits)
move-north : SOLVED with: -33 (in 5 real visits)
move-east : -11.9096 (in 264 real visits)

Used RAM: 341644

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 9/40 in round 26/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 5.5135625s.
DP-UCT: Maximal search depth set to 32

Search time: 0.048064s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2321
Cache Hits: 0
Skipped backups: 407730
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9746 (in 2598 runs)
  Maximal search depth: 40
  Cache hits: 88632

Root Node: 
-11.1171 (in 505 real visits)

Q-Value Estimates: 
noop() : -11.1171 (in 373 real visits)
move-west : -13.9398 (in 84 real visits)
move-south : -15.5 (in 35 real visits)
move-north : SOLVED with: -32 (in 5 real visits)
move-east : -25.02 (in 8 real visits)

Used RAM: 341644

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 10/40 in round 26/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 5.54215706806283s.
DP-UCT: Maximal search depth set to 31

Search time: 0.0605459s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2422
Cache Hits: 0
Skipped backups: 409332
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9688 (in 2599 runs)
  Maximal search depth: 40
  Cache hits: 89019

Root Node: 
-14.9578 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -31 (in 5 real visits)
move-west : -14.9578 (in 228 real visits)
move-south : -15.2218 (in 256 real visits)
move-north : SOLVED with: -31 (in 5 real visits)
move-east : -24.6328 (in 11 real visits)

Used RAM: 341644

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 11/40 in round 26/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 5.57098421052632s.
DP-UCT: Maximal search depth set to 30

Search time: 0.0699439s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2335
Cache Hits: 0
Skipped backups: 411087
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9688 (in 2599 runs)
  Maximal search depth: 40
  Cache hits: 89412

Root Node: 
-14.9079 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -30 (in 5 real visits)
move-west : -15.3103 (in 205 real visits)
move-south : -14.9079 (in 285 real visits)
move-north : SOLVED with: -30 (in 5 real visits)
move-east : SOLVED with: -30 (in 5 real visits)

Used RAM: 341644

Submitted action: move-south 
Immediate reward: -1
***********************************************

***********************************************
Planning step 12/40 in round 26/30
Current state: 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 5.60007407407407s.
DP-UCT: Maximal search depth set to 29

Search time: 0.0694458s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2470
Cache Hits: 0
Skipped backups: 412740
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9688 (in 2599 runs)
  Maximal search depth: 40
  Cache hits: 89834

Root Node: 
-14.5525 (in 504 real visits)

Q-Value Estimates: 
noop() : -14.9753 (in 154 real visits)
move-west : -14.5525 (in 203 real visits)
move-north : SOLVED with: -29 (in 5 real visits)
move-east : -15.0601 (in 142 real visits)

Used RAM: 341644

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 13/40 in round 26/30
Current state: 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 5.62946808510638s.
DP-UCT: Maximal search depth set to 28

Search time: 0.073015s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2465
Cache Hits: 0
Skipped backups: 414597
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9688 (in 2599 runs)
  Maximal search depth: 40
  Cache hits: 90262

Root Node: 
-14.1646 (in 503 real visits)

Q-Value Estimates: 
noop() : -14.206 (in 244 real visits)
move-north : SOLVED with: -28 (in 5 real visits)
move-east : -14.1646 (in 254 real visits)

Used RAM: 341644

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 14/40 in round 26/30
Current state: 1 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 5.65916042780749s.
DP-UCT: Maximal search depth set to 27

Search time: 0.0745869s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2649
Cache Hits: 0
Skipped backups: 416250
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9796 (in 2603 runs)
  Maximal search depth: 40
  Cache hits: 90709

Root Node: 
-12.5595 (in 504 real visits)

Q-Value Estimates: 
noop() : -12.5595 (in 219 real visits)
move-west : -13.1321 (in 148 real visits)
move-north : SOLVED with: -27 (in 5 real visits)
move-east : -13.1732 (in 132 real visits)

Used RAM: 341644

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 15/40 in round 26/30
Current state: 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 5.68916666666667s.
DP-UCT: Maximal search depth set to 26

Search time: 0.0677691s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2382
Cache Hits: 0
Skipped backups: 417564
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9796 (in 2603 runs)
  Maximal search depth: 40
  Cache hits: 91102

Root Node: 
-12.5206 (in 504 real visits)

Q-Value Estimates: 
noop() : -12.9232 (in 130 real visits)
move-west : -12.5206 (in 166 real visits)
move-north : -13.1396 (in 108 real visits)
move-east : -13.2657 (in 100 real visits)

Used RAM: 341648

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 16/40 in round 26/30
Current state: 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 5.71952972972973s.
DP-UCT: Maximal search depth set to 25

Search time: 0.07796s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2615
Cache Hits: 0
Skipped backups: 419190
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9754 (in 2604 runs)
  Maximal search depth: 40
  Cache hits: 91541

Root Node: 
-11.91 (in 503 real visits)

Q-Value Estimates: 
noop() : -11.91 (in 165 real visits)
move-north : -11.9996 (in 166 real visits)
move-east : -12.1086 (in 172 real visits)

Used RAM: 341648

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 17/40 in round 26/30
Current state: 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 5.75016847826087s.
DP-UCT: Maximal search depth set to 24

Search time: 0.07797s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2604
Cache Hits: 0
Skipped backups: 420792
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9754 (in 2604 runs)
  Maximal search depth: 40
  Cache hits: 91982

Root Node: 
-10.9925 (in 503 real visits)

Q-Value Estimates: 
noop() : -11.6289 (in 204 real visits)
move-north : SOLVED with: -24 (in 5 real visits)
move-east : -10.9925 (in 294 real visits)

Used RAM: 341648

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 18/40 in round 26/30
Current state: 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 5.78114754098361s.
DP-UCT: Maximal search depth set to 23

Search time: 0.06673s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2403
Cache Hits: 0
Skipped backups: 422094
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9754 (in 2604 runs)
  Maximal search depth: 40
  Cache hits: 92379

Root Node: 
-11.5907 (in 504 real visits)

Q-Value Estimates: 
noop() : -11.7151 (in 123 real visits)
move-west : -11.7367 (in 115 real visits)
move-north : -11.5907 (in 165 real visits)
move-east : -11.984 (in 101 real visits)

Used RAM: 341648

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 19/40 in round 26/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 5.81252197802198s.
DP-UCT: Maximal search depth set to 22

Search time: 0.049479s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2262
Cache Hits: 0
Skipped backups: 423468
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9762 (in 2605 runs)
  Maximal search depth: 40
  Cache hits: 92714

Root Node: 
-8.37113 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -22 (in 5 real visits)
move-west : -10.778 (in 44 real visits)
move-south : -10.2143 (in 62 real visits)
move-north : SOLVED with: -22 (in 5 real visits)
move-east : -8.37113 (in 389 real visits)

Used RAM: 341648

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 20/40 in round 26/30
Current state: 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 5.84434254143646s.
DP-UCT: Maximal search depth set to 21

Search time: 0.060683s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2424
Cache Hits: 0
Skipped backups: 425187
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9705 (in 2606 runs)
  Maximal search depth: 40
  Cache hits: 93102

Root Node: 
-10.8477 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -21 (in 5 real visits)
move-west : -10.8477 (in 284 real visits)
move-south : -11.1688 (in 199 real visits)
move-north : SOLVED with: -21 (in 5 real visits)
move-east : -17.08 (in 12 real visits)

Used RAM: 341648

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 21/40 in round 26/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 5.87645s.
DP-UCT: Maximal search depth set to 20

Search time: 0.051702s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2409
Cache Hits: 0
Skipped backups: 426588
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9705 (in 2606 runs)
  Maximal search depth: 40
  Cache hits: 93466

Root Node: 
-8.33741 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -20 (in 5 real visits)
move-west : -9.45624 (in 86 real visits)
move-south : -9.77672 (in 66 real visits)
move-north : SOLVED with: -20 (in 5 real visits)
move-east : -8.33741 (in 343 real visits)

Used RAM: 341648

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 22/40 in round 26/30
Current state: 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 5.90897206703911s.
DP-UCT: Maximal search depth set to 19

Search time: 0.0463252s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2349
Cache Hits: 0
Skipped backups: 428016
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9701 (in 2607 runs)
  Maximal search depth: 40
  Cache hits: 93812

Root Node: 
-7.92636 (in 505 real visits)

Q-Value Estimates: 
noop() : -7.92636 (in 395 real visits)
move-west : -9.732 (in 52 real visits)
move-south : -10.0704 (in 45 real visits)
move-north : SOLVED with: -19 (in 5 real visits)
move-east : -15.4 (in 8 real visits)

Used RAM: 341648

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 23/40 in round 26/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 5.94188764044944s.
DP-UCT: Maximal search depth set to 18

Search time: 0.0209179s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1909
Cache Hits: 0
Skipped backups: 429555
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9651 (in 2608 runs)
  Maximal search depth: 40
  Cache hits: 94070

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -9.8 (in 10 real visits)
move-west : -8 (in 10 real visits)
move-south : -9.8 (in 10 real visits)
move-north : -3 (in 465 real visits)
move-east : -14.24 (in 10 real visits)

Used RAM: 341648

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 24/40 in round 26/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 0 

Setting time for this decision to 5.97531638418079s.
DP-UCT: Maximal search depth set to 17

Search time: 0.0181808s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1853
Cache Hits: 0
Skipped backups: 431052
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9479 (in 2611 runs)
  Maximal search depth: 40
  Cache hits: 94314

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -5.84333 (in 10 real visits)
move-west : -7 (in 10 real visits)
move-south : SOLVED with: -17 (in 5 real visits)
move-north : -2 (in 470 real visits)
move-east : -11 (in 10 real visits)

Used RAM: 341648

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 25/40 in round 26/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 1 0 

Setting time for this decision to 6.00914204545454s.
DP-UCT: Maximal search depth set to 16

Search time: 0.0180919s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1889
Cache Hits: 0
Skipped backups: 432540
Initialization: 
  Statistics of IDS:
  Average search depth: 16.938 (in 2613 runs)
  Maximal search depth: 40
  Cache hits: 94575

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 479 real visits)
move-west : -5.08 (in 10 real visits)
move-south : -5.1 (in 10 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 341648

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 26/40 in round 26/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 6.04335428571429s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 6291476
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.938 (in 2613 runs)
  Maximal search depth: 40
  Cache hits: 94575

Used RAM: 341648

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 26/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 6.07806896551724s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 14680085
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.938 (in 2613 runs)
  Maximal search depth: 40
  Cache hits: 94575

Used RAM: 341648

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 26/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 6.11318497109827s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 2097205
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.938 (in 2613 runs)
  Maximal search depth: 40
  Cache hits: 94575

Used RAM: 341648

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 26/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 6.14870348837209s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 10485773
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.938 (in 2613 runs)
  Maximal search depth: 40
  Cache hits: 94575

Used RAM: 341648

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 26/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 6.18463157894737s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 6291491
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.938 (in 2613 runs)
  Maximal search depth: 40
  Cache hits: 94575

Used RAM: 341648

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 26/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 6.22098235294118s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 2097176
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.938 (in 2613 runs)
  Maximal search depth: 40
  Cache hits: 94575

Used RAM: 341648

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 26/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 6.25776923076923s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 6291462
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.938 (in 2613 runs)
  Maximal search depth: 40
  Cache hits: 94575

Used RAM: 341648

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 26/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 6.29498809523809s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 6291473
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.938 (in 2613 runs)
  Maximal search depth: 40
  Cache hits: 94575

Used RAM: 341648

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 26/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 6.33265269461078s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 6291476
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.938 (in 2613 runs)
  Maximal search depth: 40
  Cache hits: 94575

Used RAM: 341648

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 26/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 6.37077710843374s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 6291477
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.938 (in 2613 runs)
  Maximal search depth: 40
  Cache hits: 94575

Used RAM: 341648

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 26/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 6.40936363636364s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 2097173
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.938 (in 2613 runs)
  Maximal search depth: 40
  Cache hits: 94575

Used RAM: 341648

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 26/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 6.44842073170732s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 4
StateHashKey: 10485765
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.938 (in 2613 runs)
  Maximal search depth: 40
  Cache hits: 94575

Used RAM: 341648

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 26/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 6.4879509202454s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 10485793
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.938 (in 2613 runs)
  Maximal search depth: 40
  Cache hits: 94575

Used RAM: 341648

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 26/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 6.52796913580247s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 14680104
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.938 (in 2613 runs)
  Maximal search depth: 40
  Cache hits: 94575

Used RAM: 341648

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 26/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 6.56849068322981s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.938 (in 2613 runs)
  Maximal search depth: 40
  Cache hits: 94575

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 3
Accumulated number of trials in root state: 13000
Accumulated number of search nodes in root state: 66086

Used RAM: 341648

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 26 -- REWARD RECEIVED: -25
***********************************************

***********************************************
>>> STARTING ROUND 27 -- REMAINING TIME 1060s
***********************************************
***********************************************
Planning step 1/40 in round 27/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 6.6095125s.
DP-UCT: Maximal search depth set to 40

Search time: 0.061131s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2537
Cache Hits: 0
Skipped backups: 434484
Initialization: 
  Statistics of IDS:
  Average search depth: 16.938 (in 2613 runs)
  Maximal search depth: 40
  Cache hits: 95005

Root Node: 
-18.6383 (in 503 real visits)

Q-Value Estimates: 
noop() : -20.8043 (in 154 real visits)
move-west : -18.6383 (in 338 real visits)
move-north : -32.32 (in 11 real visits)

Used RAM: 341648

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 27/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 6.65042767295597s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0646682s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2515
Cache Hits: 0
Skipped backups: 436194
Initialization: 
  Statistics of IDS:
  Average search depth: 16.938 (in 2613 runs)
  Maximal search depth: 40
  Cache hits: 95434

Root Node: 
-17.8203 (in 504 real visits)

Q-Value Estimates: 
noop() : -19.2432 (in 172 real visits)
move-west : -17.8203 (in 224 real visits)
move-north : SOLVED with: -39 (in 5 real visits)
move-east : -20.0293 (in 103 real visits)

Used RAM: 341660

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 27/30
Current state: 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 6.69208227848101s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0708132s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2481
Cache Hits: 0
Skipped backups: 437838
Initialization: 
  Statistics of IDS:
  Average search depth: 16.938 (in 2613 runs)
  Maximal search depth: 40
  Cache hits: 95861

Root Node: 
-17.7146 (in 504 real visits)

Q-Value Estimates: 
noop() : -18.6531 (in 135 real visits)
move-west : -17.7146 (in 217 real visits)
move-north : SOLVED with: -38 (in 5 real visits)
move-east : -18.638 (in 147 real visits)

Used RAM: 341660

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 27/30
Current state: 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 6.73422929936306s.
DP-UCT: Maximal search depth set to 37

Search time: 0.074759s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2441
Cache Hits: 0
Skipped backups: 439593
Initialization: 
  Statistics of IDS:
  Average search depth: 16.938 (in 2613 runs)
  Maximal search depth: 40
  Cache hits: 96284

Root Node: 
-17.6557 (in 503 real visits)

Q-Value Estimates: 
noop() : -17.6557 (in 289 real visits)
move-north : SOLVED with: -37 (in 5 real visits)
move-east : -18.3536 (in 209 real visits)

Used RAM: 341660

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 27/30
Current state: 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 6.77689743589744s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0764971s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2642
Cache Hits: 0
Skipped backups: 441438
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9358 (in 2616 runs)
  Maximal search depth: 40
  Cache hits: 96728

Root Node: 
-15.8431 (in 503 real visits)

Q-Value Estimates: 
noop() : -15.8431 (in 161 real visits)
move-north : SOLVED with: -36 (in 5 real visits)
move-east : -16.1651 (in 337 real visits)

Used RAM: 341660

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 27/30
Current state: 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 6.82010322580645s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0778389s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2571
Cache Hits: 0
Skipped backups: 443028
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9358 (in 2616 runs)
  Maximal search depth: 40
  Cache hits: 97163

Root Node: 
-15.6898 (in 503 real visits)

Q-Value Estimates: 
noop() : -15.6898 (in 274 real visits)
move-north : SOLVED with: -35 (in 5 real visits)
move-east : -16.0482 (in 224 real visits)

Used RAM: 341664

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 27/30
Current state: 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 6.86386363636364s.
DP-UCT: Maximal search depth set to 34

Search time: 0.0708618s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2339
Cache Hits: 0
Skipped backups: 444432
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9358 (in 2616 runs)
  Maximal search depth: 40
  Cache hits: 97551

Root Node: 
-16.703 (in 503 real visits)

Q-Value Estimates: 
noop() : -17.0297 (in 149 real visits)
move-north : -16.703 (in 172 real visits)
move-east : -16.7606 (in 182 real visits)

Used RAM: 341664

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 27/30
Current state: 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 6.90823529411765s.
DP-UCT: Maximal search depth set to 33

Search time: 0.073915s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2550
Cache Hits: 0
Skipped backups: 446061
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9408 (in 2617 runs)
  Maximal search depth: 40
  Cache hits: 97970

Root Node: 
-14.7681 (in 504 real visits)

Q-Value Estimates: 
noop() : -14.7681 (in 334 real visits)
move-south : -15.9856 (in 160 real visits)
move-north : SOLVED with: -33 (in 5 real visits)
move-east : SOLVED with: -33 (in 5 real visits)

Used RAM: 341664

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 9/40 in round 27/30
Current state: 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 6.95317763157895s.
DP-UCT: Maximal search depth set to 32

Search time: 0.0728738s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2538
Cache Hits: 0
Skipped backups: 447594
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9362 (in 2618 runs)
  Maximal search depth: 40
  Cache hits: 98378

Root Node: 
-14.5587 (in 504 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -32 (in 5 real visits)
move-south : -15.1976 (in 182 real visits)
move-north : SOLVED with: -32 (in 5 real visits)
move-east : -14.5587 (in 312 real visits)

Used RAM: 341664

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 10/40 in round 27/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 6.99871523178808s.
DP-UCT: Maximal search depth set to 31

Search time: 0.0544119s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2540
Cache Hits: 0
Skipped backups: 448899
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9402 (in 2625 runs)
  Maximal search depth: 40
  Cache hits: 98759

Root Node: 
-10.7652 (in 505 real visits)

Q-Value Estimates: 
noop() : -12.0328 (in 172 real visits)
move-west : -13.903 (in 50 real visits)
move-south : -15.2104 (in 29 real visits)
move-north : SOLVED with: -31 (in 5 real visits)
move-east : -10.7652 (in 249 real visits)

Used RAM: 341664

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 11/40 in round 27/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 7.04498666666667s.
DP-UCT: Maximal search depth set to 30

Search time: 0.061028s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2422
Cache Hits: 0
Skipped backups: 450471
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9402 (in 2625 runs)
  Maximal search depth: 40
  Cache hits: 99145

Root Node: 
-14.4747 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -30 (in 5 real visits)
move-west : -14.4747 (in 294 real visits)
move-south : -15.0002 (in 191 real visits)
move-north : SOLVED with: -30 (in 5 real visits)
move-east : -24.2 (in 10 real visits)

Used RAM: 341672

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 12/40 in round 27/30
Current state: 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 7.0918322147651s.
DP-UCT: Maximal search depth set to 29

Search time: 0.0512891s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2317
Cache Hits: 0
Skipped backups: 451812
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9402 (in 2625 runs)
  Maximal search depth: 40
  Cache hits: 99492

Root Node: 
-10.7202 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -29 (in 5 real visits)
move-west : -13.0302 (in 76 real visits)
move-south : -13.4165 (in 61 real visits)
move-north : SOLVED with: -29 (in 5 real visits)
move-east : -10.7202 (in 358 real visits)

Used RAM: 341672

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 13/40 in round 27/30
Current state: 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 7.13937837837838s.
DP-UCT: Maximal search depth set to 28

Search time: 0.0202169s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1891
Cache Hits: 0
Skipped backups: 453288
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9402 (in 2625 runs)
  Maximal search depth: 40
  Cache hits: 99747

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -12.1952 (in 10 real visits)
move-west : -11.75 (in 10 real visits)
move-south : -14.5 (in 10 real visits)
move-north : -3 (in 465 real visits)
move-east : -22.6 (in 10 real visits)

Used RAM: 341672

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 14/40 in round 27/30
Current state: 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 0 

Setting time for this decision to 7.18778231292517s.
DP-UCT: Maximal search depth set to 27

Search time: 0.0165892s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1742
Cache Hits: 0
Skipped backups: 454737
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9402 (in 2625 runs)
  Maximal search depth: 40
  Cache hits: 99975

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -8.31267 (in 10 real visits)
move-west : -10.5 (in 10 real visits)
move-south : SOLVED with: -27 (in 5 real visits)
move-north : -2 (in 470 real visits)
move-east : -17.88 (in 10 real visits)

Used RAM: 341672

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 15/40 in round 27/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 0 

Setting time for this decision to 7.2368698630137s.
DP-UCT: Maximal search depth set to 26

Search time: 0.0165398s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1836
Cache Hits: 0
Skipped backups: 456111
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100221

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 140 real visits)
move-west : -8.53333 (in 8 real visits)
move-south : -3 (in 351 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 341672

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 16/40 in round 27/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 7.28664137931035s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 6291460
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100221

Used RAM: 341672

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 27/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 7.33721527777778s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 6291473
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100221

Used RAM: 341672

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 27/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 7.3884965034965s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 23
StateHashKey: 14680084
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100221

Used RAM: 341672

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 27/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 7.44048591549296s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 22
StateHashKey: 10485813
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100221

Used RAM: 341672

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 27/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 7.49323404255319s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 21
StateHashKey: 10485805
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100221

Used RAM: 341672

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 27/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 7.54673571428571s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 14680107
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100221

Used RAM: 341672

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 27/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 7.6010071942446s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 14680122
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100221

Used RAM: 341672

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 27/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 7.6560652173913s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 14680126
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100221

Used RAM: 341672

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 27/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 7.7119197080292s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 10485823
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100221

Used RAM: 341672

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 27/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 7.76858823529412s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 16
StateHashKey: 14680111
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100221

Used RAM: 341672

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 27/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 7.8261037037037s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 15
StateHashKey: 14680123
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100221

Used RAM: 341672

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 27/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 7.8844776119403s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 2097214
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100221

Used RAM: 341672

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 27/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 7.94372180451128s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 13
StateHashKey: 14680079
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100221

Used RAM: 341672

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 27/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 8.00387121212121s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 14680115
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100221

Used RAM: 341672

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 27/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 8.06493129770992s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 14680124
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100221

Used RAM: 341672

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 27/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 8.12693846153846s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 10
StateHashKey: 14680127
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100221

Used RAM: 341672

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 27/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 8.18990697674419s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 9
StateHashKey: 14680127
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100221

Used RAM: 341672

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 27/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 8.2538515625s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 8
StateHashKey: 10485823
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100221

Used RAM: 341672

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 27/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 8.3188031496063s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 7
StateHashKey: 10485807
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100221

Used RAM: 341672

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 27/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 8.38479365079365s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 14680107
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100221

Used RAM: 341672

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 27/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 8.451832s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 5
StateHashKey: 10485818
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100221

Used RAM: 341672

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 27/30
Current state: 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 8.51995967741935s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 2097198
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100221

Used RAM: 341672

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 27/30
Current state: 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 8.58919512195122s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 3
StateHashKey: 2097163
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100221

Used RAM: 341672

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 27/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 8.65956557377049s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 14680066
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100221

Used RAM: 341672

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 27/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 8.73109917355372s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100221

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 3
Accumulated number of trials in root state: 13500
Accumulated number of search nodes in root state: 68623

Used RAM: 341672

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 27 -- REWARD RECEIVED: -15
***********************************************

***********************************************
>>> STARTING ROUND 28 -- REMAINING TIME 1059s
***********************************************
***********************************************
Planning step 1/40 in round 28/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 8.80381666666667s.
DP-UCT: Maximal search depth set to 40

Search time: 0.058502s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2528
Cache Hits: 0
Skipped backups: 458046
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 100649

Root Node: 
-19.4322 (in 503 real visits)

Q-Value Estimates: 
noop() : -20.9222 (in 146 real visits)
move-west : -19.4322 (in 346 real visits)
move-north : -32.2 (in 11 real visits)

Used RAM: 341672

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 28/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 8.87695798319328s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0688589s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2523
Cache Hits: 0
Skipped backups: 459729
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 101079

Root Node: 
-18.5948 (in 504 real visits)

Q-Value Estimates: 
noop() : -18.8678 (in 185 real visits)
move-west : -18.5948 (in 216 real visits)
move-north : SOLVED with: -39 (in 5 real visits)
move-east : -20.1976 (in 98 real visits)

Used RAM: 341680

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 28/30
Current state: 1 1 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 8.9515593220339s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0739241s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2631
Cache Hits: 0
Skipped backups: 461451
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 101526

Root Node: 
-16.5849 (in 504 real visits)

Q-Value Estimates: 
noop() : -16.5849 (in 248 real visits)
move-west : -17.6817 (in 153 real visits)
move-north : SOLVED with: -38 (in 5 real visits)
move-east : -18.4118 (in 98 real visits)

Used RAM: 341680

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 28/30
Current state: 1 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 9.02741025641026s.
DP-UCT: Maximal search depth set to 37

Search time: 0.073472s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2631
Cache Hits: 0
Skipped backups: 462885
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 101962

Root Node: 
-16.5798 (in 504 real visits)

Q-Value Estimates: 
noop() : -16.7211 (in 158 real visits)
move-west : -17.2332 (in 115 real visits)
move-north : -16.5798 (in 159 real visits)
move-east : -18.3624 (in 72 real visits)

Used RAM: 341680

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 28/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 9.10456034482759s.
DP-UCT: Maximal search depth set to 36

Search time: 0.044852s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2460
Cache Hits: 0
Skipped backups: 464238
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 102344

Root Node: 
-10.1625 (in 505 real visits)

Q-Value Estimates: 
noop() : -10.1625 (in 425 real visits)
move-west : -15.8976 (in 50 real visits)
move-south : -18.4267 (in 20 real visits)
move-north : SOLVED with: -36 (in 5 real visits)
move-east : SOLVED with: -36 (in 5 real visits)

Used RAM: 341680

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 28/30
Current state: 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 9.18331304347826s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0211399s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1867
Cache Hits: 0
Skipped backups: 465609
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9239 (in 2628 runs)
  Maximal search depth: 40
  Cache hits: 102600

Root Node: 
-4.6953 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -35 (in 5 real visits)
move-west : -15.2 (in 13 real visits)
move-south : -15.0715 (in 10 real visits)
move-north : -4.6953 (in 472 real visits)
move-east : SOLVED with: -35 (in 5 real visits)

Used RAM: 341680

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 28/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 9.26364912280702s.
DP-UCT: Maximal search depth set to 34

Search time: 0.0199459s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1975
Cache Hits: 0
Skipped backups: 467298
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9125 (in 2630 runs)
  Maximal search depth: 40
  Cache hits: 102876

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -11.5167 (in 10 real visits)
move-west : -14 (in 10 real visits)
move-south : SOLVED with: -34 (in 5 real visits)
move-north : -10 (in 11 real visits)
move-east : -3 (in 469 real visits)

Used RAM: 341680

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 28/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 1 

Setting time for this decision to 9.34541592920354s.
DP-UCT: Maximal search depth set to 33

Search time: 0.0146389s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1609
Cache Hits: 0
Skipped backups: 468576
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9069 (in 2631 runs)
  Maximal search depth: 40
  Cache hits: 103072

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -33 (in 5 real visits)
move-west : -12.44 (in 10 real visits)
move-south : SOLVED with: -33 (in 5 real visits)
move-north : -2 (in 475 real visits)
move-east : -21.72 (in 10 real visits)

Used RAM: 341680

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 9/40 in round 28/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 0 

Setting time for this decision to 9.42869642857143s.
DP-UCT: Maximal search depth set to 32

Search time: 0.0169208s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1890
Cache Hits: 0
Skipped backups: 469992
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 140 real visits)
move-west : -5 (in 8 real visits)
move-south : -3 (in 351 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 341680

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 10/40 in round 28/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 9.51345045045045s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 31
StateHashKey: 10485773
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 28/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 9.59990909090909s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 30
StateHashKey: 14680099
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 28/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 9.68794495412844s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 14680120
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 28/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 9.77761111111111s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 28
StateHashKey: 10485822
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 28/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 9.86895327102804s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 14680111
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 28/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 9.96202830188679s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 26
StateHashKey: 10485819
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 28/30
Current state: 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 10.0568571428571s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 6291502
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 28/30
Current state: 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 10.1535096153846s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 6291483
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 28/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 10.2520485436893s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 6291478
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 28/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 10.3525196078431s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 22
StateHashKey: 10485781
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 28/30
Current state: 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 10.4549702970297s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 21
StateHashKey: 14680101
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 28/30
Current state: 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 10.55947s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 14680121
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 28/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 10.6660808080808s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 10485822
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 28/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 10.7748673469388s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 6291503
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 28/30
Current state: 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 10.8859072164948s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 14680091
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 28/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 10.99925s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 2097206
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 28/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 11.1149894736842s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 15
StateHashKey: 14680077
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 28/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 11.2331914893617s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 14680115
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 28/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 11.3539247311828s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 13
StateHashKey: 10485820
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 28/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 11.4772826086957s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 6291503
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 28/30
Current state: 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 11.6033626373626s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 2097179
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 28/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 11.7322333333333s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 6291462
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 28/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 11.864s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 9
StateHashKey: 14680081
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 28/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 11.9987727272727s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 6291508
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 28/30
Current state: 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 12.1366436781609s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 2097181
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 28/30
Current state: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 12.2777209302326s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 10485767
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 28/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 12.4221058823529s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 6291489
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 28/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 12.5699404761905s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 6291480
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 28/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 12.7213373493976s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 14680086
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 28/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 12.8764146341463s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 6291509
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 28/30
Current state: 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 13.0353333333333s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103330

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 3
Accumulated number of trials in root state: 14000
Accumulated number of search nodes in root state: 71151

Used RAM: 341680

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 28 -- REWARD RECEIVED: -9
***********************************************

***********************************************
>>> STARTING ROUND 29 -- REMAINING TIME 1058s
***********************************************
***********************************************
Planning step 1/40 in round 29/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 13.198225s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0586128s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2562
Cache Hits: 0
Skipped backups: 472017
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 103764

Root Node: 
-18.1552 (in 503 real visits)

Q-Value Estimates: 
noop() : -20.8162 (in 159 real visits)
move-west : -18.1552 (in 331 real visits)
move-north : -30.88 (in 13 real visits)

Used RAM: 341680

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 29/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 13.364s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0638521s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2500
Cache Hits: 0
Skipped backups: 473796
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 104190

Root Node: 
-18.8712 (in 504 real visits)

Q-Value Estimates: 
noop() : -19.3887 (in 165 real visits)
move-west : -18.8712 (in 221 real visits)
move-north : SOLVED with: -39 (in 5 real visits)
move-east : -20.1808 (in 113 real visits)

Used RAM: 341684

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 29/30
Current state: 1 1 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 13.5344743589744s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0722919s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2622
Cache Hits: 0
Skipped backups: 475503
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 104632

Root Node: 
-17.0228 (in 504 real visits)

Q-Value Estimates: 
noop() : -17.0228 (in 246 real visits)
move-west : -18.079 (in 128 real visits)
move-north : SOLVED with: -38 (in 5 real visits)
move-east : -18.1107 (in 125 real visits)

Used RAM: 341684

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 29/30
Current state: 1 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 13.7092597402597s.
DP-UCT: Maximal search depth set to 37

Search time: 0.069133s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2457
Cache Hits: 0
Skipped backups: 476949
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 105044

Root Node: 
-17.6313 (in 504 real visits)

Q-Value Estimates: 
noop() : -17.6313 (in 143 real visits)
move-west : -17.873 (in 137 real visits)
move-north : -18.3052 (in 135 real visits)
move-east : -18.7976 (in 89 real visits)

Used RAM: 341688

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 29/30
Current state: 1 1 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 13.8886842105263s.
DP-UCT: Maximal search depth set to 36

Search time: 0.073493s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2636
Cache Hits: 0
Skipped backups: 478614
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 105489

Root Node: 
-16.4294 (in 504 real visits)

Q-Value Estimates: 
noop() : -16.4294 (in 223 real visits)
move-west : -16.7534 (in 169 real visits)
move-north : SOLVED with: -36 (in 5 real visits)
move-east : -17.5584 (in 107 real visits)

Used RAM: 341688

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 29/30
Current state: 0 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 14.07284s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0657699s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2442
Cache Hits: 0
Skipped backups: 480042
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 105895

Root Node: 
-16.866 (in 504 real visits)

Q-Value Estimates: 
noop() : -18.1359 (in 86 real visits)
move-west : -17.4965 (in 116 real visits)
move-north : -16.866 (in 171 real visits)
move-east : -17.1512 (in 131 real visits)

Used RAM: 341688

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 29/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 14.2620810810811s.
DP-UCT: Maximal search depth set to 34

Search time: 0.0700331s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2417
Cache Hits: 0
Skipped backups: 481797
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 106305

Root Node: 
-16.0356 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -34 (in 5 real visits)
move-west : -17.3563 (in 105 real visits)
move-south : -16.0356 (in 385 real visits)
move-north : SOLVED with: -34 (in 5 real visits)
move-east : SOLVED with: -34 (in 5 real visits)

Used RAM: 341688

Submitted action: move-south 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 29/30
Current state: 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 14.4564383561644s.
DP-UCT: Maximal search depth set to 33

Search time: 0.071125s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2590
Cache Hits: 0
Skipped backups: 483465
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 106740

Root Node: 
-14.8304 (in 504 real visits)

Q-Value Estimates: 
noop() : -14.8304 (in 288 real visits)
move-west : -16.0385 (in 119 real visits)
move-north : SOLVED with: -33 (in 5 real visits)
move-east : -16.5952 (in 92 real visits)

Used RAM: 341688

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 9/40 in round 29/30
Current state: 1 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 14.6561805555556s.
DP-UCT: Maximal search depth set to 32

Search time: 0.0690889s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2476
Cache Hits: 0
Skipped backups: 484839
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 107154

Root Node: 
-15.3716 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.6965 (in 119 real visits)
move-west : -15.6605 (in 119 real visits)
move-north : -15.3716 (in 141 real visits)
move-east : -15.5862 (in 125 real visits)

Used RAM: 341688

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 10/40 in round 29/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 14.8615774647887s.
DP-UCT: Maximal search depth set to 31

Search time: 0.072298s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2339
Cache Hits: 0
Skipped backups: 486669
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 107556

Root Node: 
-15.2167 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -31 (in 5 real visits)
move-west : -15.2167 (in 268 real visits)
move-south : -15.7093 (in 222 real visits)
move-north : SOLVED with: -31 (in 5 real visits)
move-east : SOLVED with: -31 (in 5 real visits)

Used RAM: 341688

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 11/40 in round 29/30
Current state: 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 15.0728s.
DP-UCT: Maximal search depth set to 30

Search time: 0.074264s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2458
Cache Hits: 0
Skipped backups: 488832
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 107978

Root Node: 
-14.6723 (in 504 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -30 (in 5 real visits)
move-south : -14.6723 (in 489 real visits)
move-north : SOLVED with: -30 (in 5 real visits)
move-east : SOLVED with: -30 (in 5 real visits)

Used RAM: 341688

Submitted action: move-south 
Immediate reward: -1
***********************************************

***********************************************
Planning step 12/40 in round 29/30
Current state: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 15.290115942029s.
DP-UCT: Maximal search depth set to 29

Search time: 0.0744488s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2466
Cache Hits: 0
Skipped backups: 490629
Initialization: 
  Statistics of IDS:
  Average search depth: 16.902 (in 2632 runs)
  Maximal search depth: 40
  Cache hits: 108404

Root Node: 
-14.4978 (in 503 real visits)

Q-Value Estimates: 
noop() : -14.4978 (in 305 real visits)
move-north : SOLVED with: -29 (in 5 real visits)
move-east : -14.8765 (in 193 real visits)

Used RAM: 341688

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 13/40 in round 29/30
Current state: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 15.5138235294118s.
DP-UCT: Maximal search depth set to 28

Search time: 0.0769911s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2594
Cache Hits: 0
Skipped backups: 492462
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9051 (in 2633 runs)
  Maximal search depth: 40
  Cache hits: 108847

Root Node: 
-13.0511 (in 503 real visits)

Q-Value Estimates: 
noop() : -13.5212 (in 222 real visits)
move-north : SOLVED with: -28 (in 5 real visits)
move-east : -13.0511 (in 276 real visits)

Used RAM: 341688

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 14/40 in round 29/30
Current state: 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 15.7441791044776s.
DP-UCT: Maximal search depth set to 27

Search time: 0.06725s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2391
Cache Hits: 0
Skipped backups: 493788
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9051 (in 2633 runs)
  Maximal search depth: 40
  Cache hits: 109244

Root Node: 
-13.3721 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.4043 (in 140 real visits)
move-west : -13.3721 (in 149 real visits)
move-north : -13.7263 (in 113 real visits)
move-east : -13.9011 (in 102 real visits)

Used RAM: 341688

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 15/40 in round 29/30
Current state: 1 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 15.9816515151515s.
DP-UCT: Maximal search depth set to 26

Search time: 0.0720119s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2367
Cache Hits: 0
Skipped backups: 495453
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9051 (in 2633 runs)
  Maximal search depth: 40
  Cache hits: 109648

Root Node: 
-12.6704 (in 503 real visits)

Q-Value Estimates: 
noop() : -12.6704 (in 236 real visits)
move-north : -13.61 (in 130 real visits)
move-east : -13.4912 (in 137 real visits)

Used RAM: 341688

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 16/40 in round 29/30
Current state: 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 16.2263538461538s.
DP-UCT: Maximal search depth set to 25

Search time: 0.0741019s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2444
Cache Hits: 0
Skipped backups: 497265
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9051 (in 2633 runs)
  Maximal search depth: 40
  Cache hits: 110070

Root Node: 
-12.4254 (in 503 real visits)

Q-Value Estimates: 
noop() : -12.4254 (in 293 real visits)
move-north : SOLVED with: -25 (in 5 real visits)
move-east : -12.8494 (in 205 real visits)

Used RAM: 341688

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 17/40 in round 29/30
Current state: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 16.478671875s.
DP-UCT: Maximal search depth set to 24

Search time: 0.0721428s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2491
Cache Hits: 0
Skipped backups: 499107
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9051 (in 2633 runs)
  Maximal search depth: 40
  Cache hits: 110496

Root Node: 
-12.2502 (in 503 real visits)

Q-Value Estimates: 
noop() : -12.577 (in 205 real visits)
move-north : SOLVED with: -24 (in 5 real visits)
move-east : -12.2502 (in 293 real visits)

Used RAM: 341688

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 18/40 in round 29/30
Current state: 1 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 16.7390317460317s.
DP-UCT: Maximal search depth set to 23

Search time: 0.068819s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2504
Cache Hits: 0
Skipped backups: 500760
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9051 (in 2633 runs)
  Maximal search depth: 40
  Cache hits: 110921

Root Node: 
-11.8537 (in 504 real visits)

Q-Value Estimates: 
noop() : -11.9177 (in 162 real visits)
move-west : -11.9806 (in 155 real visits)
move-north : SOLVED with: -23 (in 5 real visits)
move-east : -11.8537 (in 182 real visits)

Used RAM: 341688

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 19/40 in round 29/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 17.0078548387097s.
DP-UCT: Maximal search depth set to 22

Search time: 0.0618482s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2502
Cache Hits: 0
Skipped backups: 502548
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9051 (in 2633 runs)
  Maximal search depth: 40
  Cache hits: 111346

Root Node: 
-11.4308 (in 504 real visits)

Q-Value Estimates: 
noop() : -11.4308 (in 198 real visits)
move-west : -11.534 (in 179 real visits)
move-north : SOLVED with: -22 (in 5 real visits)
move-east : -11.9827 (in 122 real visits)

Used RAM: 341688

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 20/40 in round 29/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 17.2855901639344s.
DP-UCT: Maximal search depth set to 21

Search time: 0.049082s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2325
Cache Hits: 0
Skipped backups: 504000
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9055 (in 2634 runs)
  Maximal search depth: 40
  Cache hits: 111699

Root Node: 
-8.39155 (in 504 real visits)

Q-Value Estimates: 
noop() : -11.192 (in 33 real visits)
move-west : -10.0707 (in 61 real visits)
move-north : -8.39155 (in 382 real visits)
move-east : -11.42 (in 28 real visits)

Used RAM: 341688

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 21/40 in round 29/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 17.5728166666667s.
DP-UCT: Maximal search depth set to 20

Search time: 0.0199668s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1855
Cache Hits: 0
Skipped backups: 505410
Initialization: 
  Statistics of IDS:
  Average search depth: 16.9055 (in 2634 runs)
  Maximal search depth: 40
  Cache hits: 111946

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -9.5 (in 10 real visits)
move-west : -8.726 (in 10 real visits)
move-south : -10.62 (in 10 real visits)
move-north : -3 (in 465 real visits)
move-east : -16.32 (in 10 real visits)

Used RAM: 341688

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 22/40 in round 29/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 0 

Setting time for this decision to 17.8702542372881s.
DP-UCT: Maximal search depth set to 19

Search time: 0.016721s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1775
Cache Hits: 0
Skipped backups: 506871
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 112180

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -6.43 (in 10 real visits)
move-west : -7.66667 (in 10 real visits)
move-south : SOLVED with: -19 (in 5 real visits)
move-north : -2 (in 470 real visits)
move-east : -12.2 (in 10 real visits)

Used RAM: 341688

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 23/40 in round 29/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 1 1 

Setting time for this decision to 18.178s.
DP-UCT: Maximal search depth set to 18

Search time: 0.019495s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1824
Cache Hits: 0
Skipped backups: 508302
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 112428

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 143 real visits)
move-west : -3 (in 351 real visits)
move-south : SOLVED with: -18 (in 5 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 341688

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 24/40 in round 29/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 18.4964912280702s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 17
StateHashKey: 6291508
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 112428

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 29/30
Current state: 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 18.8267142857143s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 6291485
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 112428

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 29/30
Current state: 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 19.1689454545455s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 15
StateHashKey: 14680087
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 112428

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 29/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 19.5238333333333s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 2097205
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 112428

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 29/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 19.8921320754717s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 6291469
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 112428

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 29/30
Current state: 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 20.2745961538462s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 2097171
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 112428

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 29/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 20.6720392156863s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 14680068
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 112428

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 29/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 21.0854s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 6291505
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 112428

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 29/30
Current state: 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 21.515612244898s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 9
StateHashKey: 14680092
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 112428

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 29/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 21.9637708333333s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 8
StateHashKey: 14680119
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 112428

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 29/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 22.431s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 6291517
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 112428

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 29/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 22.9185217391304s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 2097183
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 112428

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 29/30
Current state: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 23.4277333333333s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 6291463
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 112428

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 29/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 23.9600909090909s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 4
StateHashKey: 14680081
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 112428

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 29/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 24.5171860465116s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 14680116
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 112428

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 29/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 25.1008333333333s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 14680125
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 112428

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 29/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 25.7129512195122s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 112428

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 3
Accumulated number of trials in root state: 14500
Accumulated number of search nodes in root state: 73713

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 29 -- REWARD RECEIVED: -23
***********************************************

***********************************************
>>> STARTING ROUND 30 -- REMAINING TIME 1057s
***********************************************
***********************************************
Planning step 1/40 in round 30/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 1 0 

Setting time for this decision to 26.355675s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0586939s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2551
Cache Hits: 0
Skipped backups: 510231
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 112858

Root Node: 
-19.4795 (in 503 real visits)

Q-Value Estimates: 
noop() : -20.3552 (in 175 real visits)
move-west : -19.4795 (in 316 real visits)
move-north : -30.872 (in 12 real visits)

Used RAM: 341688

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 30/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 27.0289487179487s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0448s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2244
Cache Hits: 0
Skipped backups: 511620
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113190

Root Node: 
-13.0331 (in 504 real visits)

Q-Value Estimates: 
noop() : -19.31 (in 22 real visits)
move-west : -17.7188 (in 34 real visits)
move-north : -13.0331 (in 431 real visits)
move-east : -20.42 (in 17 real visits)

Used RAM: 341688

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 30/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 27.7389736842105s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0174389s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1725
Cache Hits: 0
Skipped backups: 512862
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113409

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -38 (in 5 real visits)
move-west : -15.5 (in 10 real visits)
move-south : -19.68 (in 10 real visits)
move-north : -3 (in 470 real visits)
move-east : -28.56 (in 10 real visits)

Used RAM: 341688

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 30/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 0 

Setting time for this decision to 28.4881081081081s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0156648s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1756
Cache Hits: 0
Skipped backups: 514272
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113640

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -8.89 (in 10 real visits)
move-west : -13.02 (in 10 real visits)
move-south : SOLVED with: -37 (in 5 real visits)
move-north : -2 (in 470 real visits)
move-east : -23 (in 10 real visits)

Used RAM: 341688

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 30/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 1 1 

Setting time for this decision to 29.2788888888889s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0157042s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1713
Cache Hits: 0
Skipped backups: 515547
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 93 real visits)
move-west : -3 (in 401 real visits)
move-south : SOLVED with: -36 (in 5 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 341688

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 30/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 30.1148857142857s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 35
StateHashKey: 6291509
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 30/30
Current state: 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 31.0005s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 34
StateHashKey: 6291485
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 30/30
Current state: 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 31.9398181818182s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 33
StateHashKey: 14680087
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 30/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 32.93784375s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 32
StateHashKey: 14680117
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 30/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 34.0001935483871s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 31
StateHashKey: 14680125
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 30/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 35.1333666666667s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 30
StateHashKey: 14680127
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 30/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 36.344724137931s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 14680127
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 30/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 37.6426071428571s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 2097215
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 30/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 39.0366296296296s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 14680079
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 30/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 40.5378846153846s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 6291507
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 30/30
Current state: 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 42.15924s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 25
StateHashKey: 14680092
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 30/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 43.9157083333333s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 2097207
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 30/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 45.8249130434783s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 23
StateHashKey: 10485773
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 30/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 47.9076818181818s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 6291491
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 30/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 50.1888095238095s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 6291480
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 30/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 52.69805s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 14680086
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 30/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 55.4714210526316s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 6291509
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 30/30
Current state: 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 58.5529444444444s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 14680093
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 30/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 61.997s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 17
StateHashKey: 2097207
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 30/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 65.8715625s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 6291469
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 30/30
Current state: 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 70.2626666666667s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 15
StateHashKey: 10485779
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 30/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 75.2811428571429s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 14680100
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 30/30
Current state: 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 81.0716923076923s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 13
StateHashKey: 10485817
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 30/30
Current state: 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 87.8273333333333s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 6291502
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 30/30
Current state: 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 95.8112727272727s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 2097179
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 30/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 105.392s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 6291462
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 30/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 117.101777777778s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 9
StateHashKey: 14680081
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 30/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 131.739s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 6291508
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 30/30
Current state: 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 150.558285714286s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 7
StateHashKey: 14680093
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 30/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 175.650666666667s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 10485815
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 30/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 210.78s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 5
StateHashKey: 14680109
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 30/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 263.474s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 4
StateHashKey: 14680123
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 30/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 351.297333333333s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 14680126
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 30/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 526.944s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 14680127
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 30/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1053.884s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 16.8998 (in 2635 runs)
  Maximal search depth: 40
  Cache hits: 113862

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 3
Accumulated number of trials in root state: 15000
Accumulated number of search nodes in root state: 76264

Used RAM: 341688

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 30 -- REWARD RECEIVED: -5
***********************************************

***********************************************
Immediate rewards:
Round 0: -1 -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -8
Round 1: -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -26
Round 2: -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -6
Round 3: -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -6
Round 4: -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -10
Round 5: -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -10
Round 6: -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -10
Round 7: -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -14
Round 8: -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -16
Round 9: -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -10
Round 10: -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -5
Round 11: -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -5
Round 12: -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -6
Round 13: -1 -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -8
Round 14: -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -6
Round 15: -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -10
Round 16: -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -7
Round 17: -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  = -40
Round 18: -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -5
Round 19: -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -5
Round 20: -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -10
Round 21: -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -5
Round 22: -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -12
Round 23: -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -6
Round 24: -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -7
Round 25: -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -25
Round 26: -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -15
Round 27: -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -9
Round 28: -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -23
Round 29: -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -5

>>>           TOTAL REWARD: -330
>>>          AVERAGE REWARD: -11
***********************************************
PROST complete running time: 23.9509949684143s
