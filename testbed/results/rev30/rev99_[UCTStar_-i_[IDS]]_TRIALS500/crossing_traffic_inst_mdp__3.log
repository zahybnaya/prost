learning...
IDS: learning...
IDS: Search Depth 2: 0.000316381 / 200 = 1.58191e-06
IDS: Search Depth 3: 0.00277305 / 200 = 1.38652e-05
IDS: Search Depth 4: 0.00456405 / 200 = 2.28202e-05
IDS: Search Depth 5: 0.00594878 / 200 = 2.97439e-05
IDS: Search Depth 6: 0.00727963 / 200 = 3.63982e-05
IDS: Search Depth 7: 0.00862718 / 200 = 4.31359e-05
IDS: Search Depth 8: 0.00992155 / 200 = 4.96078e-05
IDS: Search Depth 9: 0.01124 / 200 = 5.62e-05
IDS: Search Depth 10: 0.0125401 / 200 = 6.27005e-05
IDS: Search Depth 11: 0.0138361 / 200 = 6.91807e-05
IDS: Search Depth 12: 0.0151134 / 200 = 7.55668e-05
IDS: Search Depth 13: 0.0164368 / 200 = 8.21841e-05
IDS: Search Depth 14: 0.0177226 / 200 = 8.8613e-05
IDS: Search Depth 15: 0.019022 / 200 = 9.51099e-05
IDS: Search Depth 16: 0.0203001 / 200 = 0.000101501
IDS: Search Depth 17: 0.0215905 / 200 = 0.000107952
IDS: Search Depth 18: 0.0228641 / 200 = 0.000114321
IDS: Search Depth 19: 0.0241361 / 200 = 0.00012068
IDS: Search Depth 20: 0.0254192 / 200 = 0.000127096
IDS: Search Depth 21: 0.0267012 / 200 = 0.000133506
IDS: Search Depth 22: 0.0280068 / 200 = 0.000140034
IDS: Search Depth 23: 0.02929 / 200 = 0.00014645
IDS: Search Depth 24: 0.0305614 / 200 = 0.000152807
IDS: Search Depth 25: 0.0318527 / 200 = 0.000159264
IDS: Search Depth 26: 0.0331585 / 200 = 0.000165793
IDS: Search Depth 27: 0.0344315 / 200 = 0.000172157
IDS: Search Depth 28: 0.0357251 / 200 = 0.000178626
IDS: Search Depth 29: 0.0370111 / 200 = 0.000185056
IDS: Search Depth 30: 0.0382941 / 200 = 0.00019147
IDS: Search Depth 31: 0.0395749 / 200 = 0.000197874
IDS: Search Depth 32: 0.0408368 / 200 = 0.000204184
IDS: Search Depth 33: 0.0421357 / 200 = 0.000210679
IDS: Search Depth 34: 0.0434246 / 200 = 0.000217123
IDS: Search Depth 35: 0.0447202 / 200 = 0.000223601
IDS: Search Depth 36: 0.0460291 / 200 = 0.000230145
IDS: Search Depth 37: 0.0472877 / 200 = 0.000236439
IDS: Search Depth 38: 0.0485716 / 200 = 0.000242858
IDS: Search Depth 39: 0.0498531 / 200 = 0.000249265
IDS: Search Depth 40: 0.0512853 / 200 = 0.000256426
IDS: Setting max search depth to 40!
IDS: ...finished
DP-UCT: learning...
DP-UCT: ...finished
...finished (0.0924859s).

Final task: 
----------------Actions---------------

Action fluents: 
move-east
move-north
move-south
move-west
---------------

Legal Action Combinations: 
noop() : 
Index : 0
Relevant preconditions: 
---------------
move-west : 
Index : 1
Relevant preconditions: 
---------------
move-south : 
Index : 2
Relevant preconditions: 
---------------
move-north : 
Index : 3
Relevant preconditions: 
---------------
move-east : 
Index : 4
Relevant preconditions: 
---------------

-----------------CPFs-----------------

obstacle-at(x1, y2)
  HashIndex: 0, deterministic, caching in vectors, Kleene caching in vectors of size 3.

  Action Hash Key Map: 
  Formula: 
obstacle-at(x2, y2)

  Domain: false true 
  HashKeyBase: 0: 0, 1: 1
  KleeneHashKeyBase: 1

--------------
obstacle-at(x1, y3)
  HashIndex: 1, deterministic, caching in vectors, Kleene caching in vectors of size 3.

  Action Hash Key Map: 
  Formula: 
obstacle-at(x2, y3)

  Domain: false true 
  HashKeyBase: 0: 0, 1: 2
  KleeneHashKeyBase: 3

--------------
obstacle-at(x2, y2)
  HashIndex: 2, deterministic, caching in vectors, Kleene caching in vectors of size 3.

  Action Hash Key Map: 
  Formula: 
obstacle-at(x3, y2)

  Domain: false true 
  HashKeyBase: 0: 0, 1: 4
  KleeneHashKeyBase: 9

--------------
obstacle-at(x2, y3)
  HashIndex: 3, deterministic, caching in vectors, Kleene caching in vectors of size 3.

  Action Hash Key Map: 
  Formula: 
obstacle-at(x3, y3)

  Domain: false true 
  HashKeyBase: 0: 0, 1: 8
  KleeneHashKeyBase: 27

--------------
obstacle-at(x3, y2)
  HashIndex: 4, deterministic, caching in vectors, Kleene caching in vectors of size 3.

  Action Hash Key Map: 
  Formula: 
obstacle-at(x4, y2)

  Domain: false true 
  HashKeyBase: 0: 0, 1: 16
  KleeneHashKeyBase: 81

--------------
obstacle-at(x3, y3)
  HashIndex: 5, deterministic, caching in vectors, Kleene caching in vectors of size 3.

  Action Hash Key Map: 
  Formula: 
obstacle-at(x4, y3)

  Domain: false true 
  HashKeyBase: 0: 0, 1: 32
  KleeneHashKeyBase: 243

--------------
robot-at(x1, y1)
  HashIndex: 6, deterministic, caching in vectors, Kleene caching in vectors of size 1215.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x1, y1))  then 0
case (and move-south robot-at(x1, y2) (not obstacle-at(x1, y2)) )  then 1
case (and move-east robot-at(x1, y1))  then 0
case (and move-west robot-at(x2, y1))  then 1
case 1 then robot-at(x1, y1)


  Domain: false true 
  HashKeyBase: 0: 0, 1: 64
  KleeneHashKeyBase: 729

--------------
robot-at(x1, y2)
  HashIndex: 7, deterministic, caching in vectors, Kleene caching in vectors of size 32805.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x1, y1))  then 1
case (and move-north robot-at(x1, y2))  then 0
case (and move-south robot-at(x1, y3) (not obstacle-at(x1, y3)) )  then 1
case (and move-south robot-at(x1, y2))  then 0
case (and move-east robot-at(x1, y2))  then 0
case (and move-west robot-at(x2, y2) (not obstacle-at(x2, y2)) )  then 1
case 1 then (and robot-at(x1, y2) (not obstacle-at(x1, y2)) ) 


  Domain: false true 
  HashKeyBase: 0: 0, 1: 128
  KleeneHashKeyBase: 2187

--------------
robot-at(x1, y3)
  HashIndex: 8, deterministic, caching in vectors, Kleene caching in vectors of size 32805.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x1, y2) (not obstacle-at(x1, y2)) )  then 1
case (and move-north robot-at(x1, y3))  then 0
case (and move-south robot-at(x1, y4))  then 1
case (and move-south robot-at(x1, y3))  then 0
case (and move-east robot-at(x1, y3))  then 0
case (and move-west robot-at(x2, y3) (not obstacle-at(x2, y3)) )  then 1
case 1 then (and robot-at(x1, y3) (not obstacle-at(x1, y3)) ) 


  Domain: false true 
  HashKeyBase: 0: 0, 1: 256
  KleeneHashKeyBase: 6561

--------------
robot-at(x1, y4)
  HashIndex: 9, deterministic, caching in vectors, Kleene caching in vectors of size 1215.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x1, y3) (not obstacle-at(x1, y3)) )  then 1
case (and move-south robot-at(x1, y4))  then 0
case (and move-east robot-at(x1, y4))  then 0
case (and move-west robot-at(x2, y4))  then 1
case 1 then robot-at(x1, y4)


  Domain: false true 
  HashKeyBase: 0: 0, 1: 512
  KleeneHashKeyBase: 19683

--------------
robot-at(x2, y1)
  HashIndex: 10, deterministic, caching in vectors, Kleene caching in vectors of size 3645.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x2, y1))  then 0
case (and move-south robot-at(x2, y2) (not obstacle-at(x2, y2)) )  then 1
case (and move-east robot-at(x1, y1))  then 1
case (and move-east robot-at(x2, y1))  then 0
case (and move-west robot-at(x3, y1))  then 1
case (and move-west robot-at(x2, y1))  then 0
case 1 then robot-at(x2, y1)


  Domain: false true 
  HashKeyBase: 0: 0, 1: 1024
  KleeneHashKeyBase: 59049

--------------
robot-at(x2, y2)
  HashIndex: 11, deterministic, caching in vectors, Kleene caching in maps.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x2, y1))  then 1
case (and move-north robot-at(x2, y2))  then 0
case (and move-south robot-at(x2, y3) (not obstacle-at(x2, y3)) )  then 1
case (and move-south robot-at(x2, y2))  then 0
case (and move-east robot-at(x1, y2) (not obstacle-at(x1, y2)) )  then 1
case (and move-east robot-at(x2, y2))  then 0
case (and move-west robot-at(x3, y2) (not obstacle-at(x3, y2)) )  then 1
case (and move-west robot-at(x2, y2))  then 0
case 1 then (and robot-at(x2, y2) (not obstacle-at(x2, y2)) ) 


  Domain: false true 
  HashKeyBase: 0: 0, 1: 2048
  KleeneHashKeyBase: 177147

--------------
robot-at(x2, y3)
  HashIndex: 12, deterministic, caching in vectors, Kleene caching in maps.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x2, y2) (not obstacle-at(x2, y2)) )  then 1
case (and move-north robot-at(x2, y3))  then 0
case (and move-south robot-at(x2, y4))  then 1
case (and move-south robot-at(x2, y3))  then 0
case (and move-east robot-at(x1, y3) (not obstacle-at(x1, y3)) )  then 1
case (and move-east robot-at(x2, y3))  then 0
case (and move-west robot-at(x3, y3) (not obstacle-at(x3, y3)) )  then 1
case (and move-west robot-at(x2, y3))  then 0
case 1 then (and robot-at(x2, y3) (not obstacle-at(x2, y3)) ) 


  Domain: false true 
  HashKeyBase: 0: 0, 1: 4096
  KleeneHashKeyBase: 531441

--------------
robot-at(x2, y4)
  HashIndex: 13, deterministic, caching in vectors, Kleene caching in vectors of size 3645.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x2, y3) (not obstacle-at(x2, y3)) )  then 1
case (and move-south robot-at(x2, y4))  then 0
case (and move-east robot-at(x1, y4))  then 1
case (and move-east robot-at(x2, y4))  then 0
case (and move-west robot-at(x3, y4))  then 1
case (and move-west robot-at(x2, y4))  then 0
case 1 then robot-at(x2, y4)


  Domain: false true 
  HashKeyBase: 0: 0, 1: 8192
  KleeneHashKeyBase: 1594323

--------------
robot-at(x3, y1)
  HashIndex: 14, deterministic, caching in vectors, Kleene caching in vectors of size 3645.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x3, y1))  then 0
case (and move-south robot-at(x3, y2) (not obstacle-at(x3, y2)) )  then 1
case (and move-east robot-at(x2, y1))  then 1
case (and move-east robot-at(x3, y1))  then 0
case (and move-west robot-at(x4, y1))  then 1
case (and move-west robot-at(x3, y1))  then 0
case 1 then robot-at(x3, y1)


  Domain: false true 
  HashKeyBase: 0: 0, 1: 16384
  KleeneHashKeyBase: 4782969

--------------
robot-at(x3, y2)
  HashIndex: 15, deterministic, caching in vectors, Kleene caching in maps.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x3, y1))  then 1
case (and move-north robot-at(x3, y2))  then 0
case (and move-south robot-at(x3, y3) (not obstacle-at(x3, y3)) )  then 1
case (and move-south robot-at(x3, y2))  then 0
case (and move-east robot-at(x2, y2) (not obstacle-at(x2, y2)) )  then 1
case (and move-east robot-at(x3, y2))  then 0
case (and move-west robot-at(x4, y2) (not obstacle-at(x4, y2)) )  then 1
case (and move-west robot-at(x3, y2))  then 0
case 1 then (and robot-at(x3, y2) (not obstacle-at(x3, y2)) ) 


  Domain: false true 
  HashKeyBase: 0: 0, 1: 32768
  KleeneHashKeyBase: 14348907

--------------
robot-at(x3, y3)
  HashIndex: 16, deterministic, caching in vectors, Kleene caching in maps.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x3, y2) (not obstacle-at(x3, y2)) )  then 1
case (and move-north robot-at(x3, y3))  then 0
case (and move-south robot-at(x3, y4))  then 1
case (and move-south robot-at(x3, y3))  then 0
case (and move-east robot-at(x2, y3) (not obstacle-at(x2, y3)) )  then 1
case (and move-east robot-at(x3, y3))  then 0
case (and move-west robot-at(x4, y3) (not obstacle-at(x4, y3)) )  then 1
case (and move-west robot-at(x3, y3))  then 0
case 1 then (and robot-at(x3, y3) (not obstacle-at(x3, y3)) ) 


  Domain: false true 
  HashKeyBase: 0: 0, 1: 65536
  KleeneHashKeyBase: 43046721

--------------
robot-at(x3, y4)
  HashIndex: 17, deterministic, caching in vectors, Kleene caching in vectors of size 1215.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x3, y3) (not obstacle-at(x3, y3)) )  then 1
case (and move-south robot-at(x3, y4))  then 0
case (and move-east robot-at(x2, y4))  then 1
case (and move-east robot-at(x3, y4))  then 0
case (and move-west robot-at(x4, y4))  then 1
case (and move-west robot-at(x3, y4))  then 0
case 1 then robot-at(x3, y4)


  Domain: false true 
  HashKeyBase: 0: 0, 1: 131072
  KleeneHashKeyBase: 129140163

--------------
robot-at(x4, y1)
  HashIndex: 18, deterministic, caching in vectors, Kleene caching in vectors of size 1215.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x4, y1))  then 0
case (and move-south robot-at(x4, y2) (not obstacle-at(x4, y2)) )  then 1
case (and move-east robot-at(x3, y1))  then 1
case (and move-west robot-at(x4, y1))  then 0
case 1 then robot-at(x4, y1)


  Domain: false true 
  HashKeyBase: 0: 0, 1: 262144
  KleeneHashKeyBase: 387420489

--------------
robot-at(x4, y2)
  HashIndex: 19, deterministic, caching in vectors, Kleene caching in vectors of size 32805.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x4, y1))  then 1
case (and move-north robot-at(x4, y2))  then 0
case (and move-south robot-at(x4, y3) (not obstacle-at(x4, y3)) )  then 1
case (and move-south robot-at(x4, y2))  then 0
case (and move-east robot-at(x3, y2) (not obstacle-at(x3, y2)) )  then 1
case (and move-west robot-at(x4, y2))  then 0
case 1 then (and robot-at(x4, y2) (not obstacle-at(x4, y2)) ) 


  Domain: false true 
  HashKeyBase: 0: 0, 1: 524288
  KleeneHashKeyBase: 1162261467

--------------
robot-at(x4, y3)
  HashIndex: 20, deterministic, caching in vectors, Kleene caching in vectors of size 10935.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 0
case (and move-north robot-at(x4, y2) (not obstacle-at(x4, y2)) )  then 1
case (and move-north robot-at(x4, y3))  then 0
case (and move-south robot-at(x4, y4))  then 1
case (and move-south robot-at(x4, y3))  then 0
case (and move-east robot-at(x3, y3) (not obstacle-at(x3, y3)) )  then 1
case (and move-west robot-at(x4, y3))  then 0
case 1 then (and robot-at(x4, y3) (not obstacle-at(x4, y3)) ) 


  Domain: false true 
  HashKeyBase: 0: 0, 1: 1048576
  KleeneHashKeyBase: 3486784401

--------------
robot-at(x4, y4)
  HashIndex: 21, deterministic, caching in vectors, Kleene caching in vectors of size 405.

  Action Hash Key Map: 
    move-west  : 1
    move-south  : 2
    move-north  : 3
    move-east  : 4
  Formula: 
case robot-at(x4, y4) then 1
case robot-at(x4, y4) then 0
case (and move-north robot-at(x4, y3) (not obstacle-at(x4, y3)) )  then 1
case (and move-south robot-at(x4, y4))  then 0
case (and move-east robot-at(x3, y4))  then 1
case (and move-west robot-at(x4, y4))  then 0
case 1 then robot-at(x4, y4)


  Domain: false true 
  HashKeyBase: 0: 0, 1: 2097152
  KleeneHashKeyBase: 10460353203

--------------
obstacle-at(x4, y2)
  HashIndex: 22, probabilistic, caching in vectors, Kleene caching in vectors of size 1.

  Action Hash Key Map: 
  Formula: 
Bernoulli(0.3) 
  Determinized formula: 
0
  Domain: false true 
  HashKeyBase: 0: 0, 1: 4194304
  KleeneHashKeyBase: 31381059609

--------------
obstacle-at(x4, y3)
  HashIndex: 23, probabilistic, caching in vectors, Kleene caching in vectors of size 1.

  Action Hash Key Map: 
  Formula: 
Bernoulli(0.3) 
  Determinized formula: 
0
  Domain: false true 
  HashKeyBase: 0: 0, 1: 8388608
  KleeneHashKeyBase: 94143178827

--------------

Reward CPF:
Reward
  HashIndex: 24, deterministic, caching in vectors, Kleene caching in vectors of size 3.

  Action Hash Key Map: 
  Formula: 
(- 0 (not robot-at(x4, y4)) ) 
Minimal reward: -1
Maximal reward: 0
Is action independent: 1



------State Fluent Hash Key Map-------

a change of deterministic state fluent 0 influences variables 6 (5) 7 (5) 8 (5) 11 (5) 
a change of deterministic state fluent 1 influences variables 7 (10) 8 (10) 9 (5) 12 (5) 
a change of deterministic state fluent 2 influences variables 0 (1) 7 (20) 10 (5) 11 (10) 12 (10) 15 (5) 
a change of deterministic state fluent 3 influences variables 1 (1) 8 (20) 11 (20) 12 (20) 13 (5) 16 (5) 
a change of deterministic state fluent 4 influences variables 2 (1) 11 (40) 14 (5) 15 (10) 16 (10) 19 (5) 
a change of deterministic state fluent 5 influences variables 3 (1) 12 (40) 15 (20) 16 (20) 17 (5) 20 (5) 
a change of deterministic state fluent 6 influences variables 6 (10) 7 (40) 10 (10) 
a change of deterministic state fluent 7 influences variables 6 (20) 7 (80) 8 (40) 11 (80) 
a change of deterministic state fluent 8 influences variables 7 (160) 8 (80) 9 (10) 12 (80) 
a change of deterministic state fluent 9 influences variables 8 (160) 9 (20) 13 (10) 
a change of deterministic state fluent 10 influences variables 6 (40) 10 (20) 11 (160) 14 (10) 
a change of deterministic state fluent 11 influences variables 7 (320) 10 (40) 11 (320) 12 (160) 15 (40) 
a change of deterministic state fluent 12 influences variables 8 (320) 11 (640) 12 (320) 13 (20) 16 (40) 
a change of deterministic state fluent 13 influences variables 9 (40) 12 (640) 13 (40) 17 (10) 
a change of deterministic state fluent 14 influences variables 10 (80) 14 (20) 15 (80) 18 (5) 
a change of deterministic state fluent 15 influences variables 11 (1280) 14 (40) 15 (160) 16 (80) 19 (10) 
a change of deterministic state fluent 16 influences variables 12 (1280) 15 (320) 16 (160) 17 (20) 20 (10) 
a change of deterministic state fluent 17 influences variables 13 (80) 16 (320) 17 (40) 21 (5) 
a change of deterministic state fluent 18 influences variables 14 (80) 18 (10) 19 (20) 
a change of deterministic state fluent 19 influences variables 15 (640) 18 (20) 19 (40) 20 (20) 
a change of deterministic state fluent 20 influences variables 16 (640) 19 (80) 20 (40) 21 (10) 
a change of deterministic state fluent 21 influences variables 6 (80) 7 (640) 8 (640) 9 (80) 10 (160) 11 (2560) 12 (2560) 13 (160) 14 (160) 15 (1280) 16 (1280) 17 (80) 18 (40) 19 (160) 20 (80) 21 (20) 24 (1) 

a change of probabilistic state fluent 0 influences variables 4 (1) 15 (2560) 18 (80) 19 (320) 20 (160) 
a change of probabilistic state fluent 1 influences variables 5 (1) 16 (2560) 19 (640) 20 (320) 21 (40) 


a change of variable 0 influences variables in Kleene states 6 (5) 7 (5) 8 (5) 11 (5) 
a change of variable 1 influences variables in Kleene states 7 (15) 8 (15) 9 (5) 12 (5) 
a change of variable 2 influences variables in Kleene states 0 (1) 7 (45) 10 (5) 11 (15) 12 (15) 15 (5) 
a change of variable 3 influences variables in Kleene states 1 (1) 8 (45) 11 (45) 12 (45) 13 (5) 16 (5) 
a change of variable 4 influences variables in Kleene states 2 (1) 11 (135) 14 (5) 15 (15) 16 (15) 19 (5) 
a change of variable 5 influences variables in Kleene states 3 (1) 12 (135) 15 (45) 16 (45) 17 (5) 20 (5) 
a change of variable 6 influences variables in Kleene states 6 (15) 7 (135) 10 (15) 
a change of variable 7 influences variables in Kleene states 6 (45) 7 (405) 8 (135) 11 (405) 
a change of variable 8 influences variables in Kleene states 7 (1215) 8 (405) 9 (15) 12 (405) 
a change of variable 9 influences variables in Kleene states 8 (1215) 9 (45) 13 (15) 
a change of variable 10 influences variables in Kleene states 6 (135) 10 (45) 11 (1215) 14 (15) 
a change of variable 11 influences variables in Kleene states 7 (3645) 10 (135) 11 (3645) 12 (1215) 15 (135) 
a change of variable 12 influences variables in Kleene states 8 (3645) 11 (10935) 12 (3645) 13 (45) 16 (135) 
a change of variable 13 influences variables in Kleene states 9 (135) 12 (10935) 13 (135) 17 (15) 
a change of variable 14 influences variables in Kleene states 10 (405) 14 (45) 15 (405) 18 (5) 
a change of variable 15 influences variables in Kleene states 11 (32805) 14 (135) 15 (1215) 16 (405) 19 (15) 
a change of variable 16 influences variables in Kleene states 12 (32805) 15 (3645) 16 (1215) 17 (45) 20 (15) 
a change of variable 17 influences variables in Kleene states 13 (405) 16 (3645) 17 (135) 21 (5) 
a change of variable 18 influences variables in Kleene states 14 (405) 18 (15) 19 (45) 
a change of variable 19 influences variables in Kleene states 15 (10935) 18 (45) 19 (135) 20 (45) 
a change of variable 20 influences variables in Kleene states 16 (10935) 19 (405) 20 (135) 21 (15) 
a change of variable 21 influences variables in Kleene states 6 (405) 7 (10935) 8 (10935) 9 (405) 10 (1215) 11 (98415) 12 (98415) 13 (1215) 14 (1215) 15 (32805) 16 (32805) 17 (405) 18 (135) 19 (1215) 20 (405) 21 (45) 24 (1) 
a change of variable 22 influences variables in Kleene states 4 (1) 15 (98415) 18 (405) 19 (3645) 20 (1215) 
a change of variable 23 influences variables in Kleene states 5 (1) 16 (98415) 19 (10935) 20 (3645) 21 (135) 

---------Action Preconditions---------

----------Initial State---------------

obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 1
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 0

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 40
StateHashKey: 262186

Hashing of States is possible.
Hashing of KleeneStates is possible.
Reward lock detection is enabled for goals and dead ends.
This task contains unreasonable actions.
The final reward is determined by applying NOOP.

***********************************************
>>> STARTING ROUND 1 -- REMAINING TIME 1080s
***********************************************
***********************************************
Planning step 1/40 in round 1/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 0.8975s.
DP-UCT: Maximal search depth set to 40

Search time: 0.074652s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2483
Cache Hits: 0
Skipped backups: 1539
Initialization: 
  Statistics of IDS:
  Average search depth: 4.12635 (in 277 runs)
  Maximal search depth: 40
  Cache hits: 120

Root Node: 
-12.5049 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.4269 (in 98 real visits)
move-west : -12.5049 (in 392 real visits)
move-north : -23.214 (in 13 real visits)

Used RAM: 332756

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 1/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 0.898146788990826s.
DP-UCT: Maximal search depth set to 39

Search time: 0.07128s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2662
Cache Hits: 0
Skipped backups: 3147
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51392 (in 467 runs)
  Maximal search depth: 40
  Cache hits: 381

Root Node: 
-15.7288 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.7288 (in 199 real visits)
move-west : -16.2387 (in 142 real visits)
move-north : -39 (in 4 real visits)
move-east : -16.0507 (in 159 real visits)

Used RAM: 333448

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 1/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 0.898829716193656s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0483902s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2229
Cache Hits: 0
Skipped backups: 4545
Initialization: 
  Statistics of IDS:
  Average search depth: 4.50399 (in 627 runs)
  Maximal search depth: 40
  Cache hits: 546

Root Node: 
-7.53812 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.0917 (in 36 real visits)
move-west : -15.517 (in 31 real visits)
move-north : -7.53812 (in 404 real visits)
move-east : -16.8635 (in 33 real visits)

Used RAM: 333728

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 1/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 0.899529657477026s.
DP-UCT: Maximal search depth set to 37

Search time: 0.027169s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1903
Cache Hits: 0
Skipped backups: 6270
Initialization: 
  Statistics of IDS:
  Average search depth: 4.21791 (in 748 runs)
  Maximal search depth: 40
  Cache hits: 679

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -37 (in 5 real visits)
move-west : -15.125 (in 10 real visits)
move-south : -15.1827 (in 10 real visits)
move-north : -3 (in 470 real visits)
move-east : -20.0542 (in 10 real visits)

Used RAM: 334252

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 1/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 1 

Setting time for this decision to 0.900249163879599s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0197151s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1723
Cache Hits: 0
Skipped backups: 7773
Initialization: 
  Statistics of IDS:
  Average search depth: 4.0918 (in 817 runs)
  Maximal search depth: 40
  Cache hits: 829

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -36 (in 5 real visits)
move-west : -13.4996 (in 10 real visits)
move-south : -15.0496 (in 10 real visits)
move-north : -2 (in 470 real visits)
move-east : -12.2 (in 10 real visits)

Used RAM: 334304

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 1/30
Current state: 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 1 0 

Setting time for this decision to 0.900979079497908s.
DP-UCT: Maximal search depth set to 35

Search time: 0.015934s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1759
Cache Hits: 0
Skipped backups: 9306
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -4.25 (in 10 real visits)
move-west : -9.18425 (in 10 real visits)
move-south : -3 (in 479 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 334444

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 1/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.90171189279732s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 34
StateHashKey: 6291481
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 1/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.90246102263202s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 33
StateHashKey: 2097174
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 1/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.903213087248322s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 32
StateHashKey: 6291461
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 1/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.903965575146935s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 31
StateHashKey: 2097169
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 1/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.904719327731092s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 6291460
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 1/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.905475189234651s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 10485777
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 1/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.906229797979798s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 28
StateHashKey: 10485796
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 1/30
Current state: 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.906987363100253s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 27
StateHashKey: 2097193
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 1/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.907747048903879s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 2097162
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 1/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.908508016877637s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 2097154
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 1/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.909271114864865s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 1/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.910034657650042s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 1/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.910800338409475s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 1/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.911567315834039s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 2097156
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 1/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.912335593220339s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 20
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 1/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.913104325699746s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 1/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.913874363327674s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 1/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.914645709430756s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 10485764
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 1/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.915417517006803s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 2097185
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 1/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.916193191489362s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 6291464
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 1/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.916970187393526s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 6291474
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 1/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.917747655583973s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 2097172
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 1/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.918527303754266s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 10485765
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 1/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.91930828351836s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 10485793
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 1/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.920089743589744s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 2097192
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 1/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.920870829769033s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 6291466
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 1/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.921653253424658s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 8
StateHashKey: 10485778
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 1/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.922437017994859s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 7
StateHashKey: 10485796
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 1/30
Current state: 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.923224699828473s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 2097193
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 1/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.924012017167382s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 2097162
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 1/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.924801546391753s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 6291458
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 1/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.925594153052451s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 3
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 1/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.926386402753873s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 6291460
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 1/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.927179155900086s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.02468 (in 851 runs)
  Maximal search depth: 40
  Cache hits: 1023

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 500
Accumulated number of search nodes in root state: 2483

Used RAM: 334496

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 1 -- REWARD RECEIVED: -6
***********************************************

***********************************************
>>> STARTING ROUND 2 -- REMAINING TIME 1079s
***********************************************
***********************************************
Planning step 1/40 in round 2/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 0.927972413793104s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0558541s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2508
Cache Hits: 0
Skipped backups: 10887
Initialization: 
  Statistics of IDS:
  Average search depth: 4.16393 (in 915 runs)
  Maximal search depth: 40
  Cache hits: 1360

Root Node: 
-12.6114 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.8585 (in 89 real visits)
move-west : -12.6114 (in 398 real visits)
move-north : -23.1195 (in 16 real visits)

Used RAM: 334496

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 2/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 0.928690250215703s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0658569s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2595
Cache Hits: 0
Skipped backups: 12426
Initialization: 
  Statistics of IDS:
  Average search depth: 4.25542 (in 1108 runs)
  Maximal search depth: 40
  Cache hits: 1600

Root Node: 
-14.1304 (in 504 real visits)

Q-Value Estimates: 
noop() : -14.1304 (in 194 real visits)
move-west : -16.4375 (in 125 real visits)
move-north : -39 (in 4 real visits)
move-east : -16.0455 (in 181 real visits)

Used RAM: 334948

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 2/30
Current state: 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 0.929431778929188s.
DP-UCT: Maximal search depth set to 38

Search time: 0.039813s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2250
Cache Hits: 0
Skipped backups: 14013
Initialization: 
  Statistics of IDS:
  Average search depth: 4.40625 (in 1152 runs)
  Maximal search depth: 40
  Cache hits: 1880

Root Node: 
-7.20007 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.3775 (in 23 real visits)
move-west : -15.6518 (in 21 real visits)
move-north : -7.20007 (in 437 real visits)
move-east : -15.6117 (in 23 real visits)

Used RAM: 335040

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 2/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 0.930195332757131s.
DP-UCT: Maximal search depth set to 37

Search time: 0.039017s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2230
Cache Hits: 0
Skipped backups: 15615
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54163 (in 1213 runs)
  Maximal search depth: 40
  Cache hits: 2138

Root Node: 
-6.91714 (in 505 real visits)

Q-Value Estimates: 
noop() : -6.91714 (in 435 real visits)
move-west : -13.6865 (in 41 real visits)
move-south : -14.7948 (in 15 real visits)
move-north : SOLVED with: -37 (in 5 real visits)
move-east : -20.6594 (in 9 real visits)

Used RAM: 335236

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 2/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 0.930961937716263s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0196528s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1863
Cache Hits: 0
Skipped backups: 17202
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52696 (in 1224 runs)
  Maximal search depth: 40
  Cache hits: 2374

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -14.1972 (in 10 real visits)
move-west : -14.8775 (in 10 real visits)
move-south : -14.7725 (in 10 real visits)
move-north : -3 (in 465 real visits)
move-east : -20.2325 (in 10 real visits)

Used RAM: 335332

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 2/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 1 

Setting time for this decision to 0.93174632034632s.
DP-UCT: Maximal search depth set to 35

Search time: 0.016341s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1710
Cache Hits: 0
Skipped backups: 18570
Initialization: 
  Statistics of IDS:
  Average search depth: 4.50201 (in 1241 runs)
  Maximal search depth: 40
  Cache hits: 2574

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -35 (in 5 real visits)
move-west : -12.706 (in 10 real visits)
move-south : -13.225 (in 10 real visits)
move-north : -2 (in 470 real visits)
move-east : -11.9 (in 10 real visits)

Used RAM: 335344

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 2/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 0 

Setting time for this decision to 0.932534662045061s.
DP-UCT: Maximal search depth set to 34

Search time: 0.019372s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1790
Cache Hits: 0
Skipped backups: 20112
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -5.6975 (in 10 real visits)
move-west : -3 (in 479 real visits)
move-south : -6.57 (in 10 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 335364

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 2/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.933321769297485s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 33
StateHashKey: 10485768
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335420

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 2/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.934127604166667s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 32
StateHashKey: 10485794
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 2/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.934933970460469s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 31
StateHashKey: 10485800
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 2/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.935741739130435s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 6291498
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 2/30
Current state: 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.936550043516101s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 14680090
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 2/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.9373606271777s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 6291510
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 2/30
Current state: 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.938171752397559s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 27
StateHashKey: 6291485
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 2/30
Current state: 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.938985165794066s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 26
StateHashKey: 10485783
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 2/30
Current state: 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.9398s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 6291493
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 2/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.940616258741259s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 2097177
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 2/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.941433070866142s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 23
StateHashKey: 14680070
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 2/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.942252189141856s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 22
StateHashKey: 14680113
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 2/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.943072743207713s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 21
StateHashKey: 10485820
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 2/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.943893859649123s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 10485807
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 2/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.944717295873573s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 14680107
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 2/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.945544815465729s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 2097210
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 2/30
Current state: 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.946372911169745s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 17
StateHashKey: 6291470
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 2/30
Current state: 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.947203345070422s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 16
StateHashKey: 14680083
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 2/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.94803436123348s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 2097204
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 2/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.948867724867725s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 2097165
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 2/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.949702559576346s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 6291459
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 2/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.950537985865724s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 2/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.951375773651636s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 14680068
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 2/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.952215044247788s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 6291505
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 2/30
Current state: 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.953054915854739s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 9
StateHashKey: 10485788
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 2/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.953897163120567s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 2097191
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 2/30
Current state: 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.954740905057675s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 7
StateHashKey: 10485769
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 2/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.955585257548845s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 6291490
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 2/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.956432s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 5
StateHashKey: 10485784
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 2/30
Current state: 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.957279359430605s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 6291494
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 2/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.958129118432769s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 3
StateHashKey: 2097177
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 2/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.958979500891265s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 6291462
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 2/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.959832292595897s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.46767 (in 1268 runs)
  Maximal search depth: 40
  Cache hits: 2779

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 1000
Accumulated number of search nodes in root state: 4991

Used RAM: 335424

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 2 -- REWARD RECEIVED: -7
***********************************************

***********************************************
>>> STARTING ROUND 3 -- REMAINING TIME 1078s
***********************************************
***********************************************
Planning step 1/40 in round 3/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 0.960685714285714s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0494921s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2520
Cache Hits: 0
Skipped backups: 21636
Initialization: 
  Statistics of IDS:
  Average search depth: 4.4699 (in 1279 runs)
  Maximal search depth: 40
  Cache hits: 3178

Root Node: 
-13.6987 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.264 (in 89 real visits)
move-west : -13.6987 (in 394 real visits)
move-north : -22.7888 (in 20 real visits)

Used RAM: 335424

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 3/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 0.961460232350313s.
DP-UCT: Maximal search depth set to 39

Search time: 0.057956s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2603
Cache Hits: 0
Skipped backups: 23178
Initialization: 
  Statistics of IDS:
  Average search depth: 4.49475 (in 1334 runs)
  Maximal search depth: 40
  Cache hits: 3550

Root Node: 
-13.4149 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.4149 (in 285 real visits)
move-west : -16.553 (in 93 real visits)
move-north : SOLVED with: -39 (in 5 real visits)
move-east : -16.3822 (in 121 real visits)

Used RAM: 335476

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 3/30
Current state: 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 0.962263864042934s.
DP-UCT: Maximal search depth set to 38

Search time: 0.036242s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2212
Cache Hits: 0
Skipped backups: 24684
Initialization: 
  Statistics of IDS:
  Average search depth: 4.49963 (in 1341 runs)
  Maximal search depth: 40
  Cache hits: 3866

Root Node: 
-7.01 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.5665 (in 25 real visits)
move-west : -15.6597 (in 23 real visits)
move-north : -7.01 (in 439 real visits)
move-east : -16.805 (in 17 real visits)

Used RAM: 335568

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 3/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 0.963088630259624s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0210631s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1861
Cache Hits: 0
Skipped backups: 26181
Initialization: 
  Statistics of IDS:
  Average search depth: 4.4878 (in 1353 runs)
  Maximal search depth: 40
  Cache hits: 4101

Root Node: 
-3.06277 (in 505 real visits)

Q-Value Estimates: 
noop() : -14.0917 (in 10 real visits)
move-west : -15.2075 (in 10 real visits)
move-south : -14.7948 (in 10 real visits)
move-north : -3.06277 (in 465 real visits)
move-east : -22.5012 (in 10 real visits)

Used RAM: 335572

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 3/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 0 

Setting time for this decision to 0.963928315412186s.
DP-UCT: Maximal search depth set to 36

Search time: 0.018702s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1795
Cache Hits: 0
Skipped backups: 27717
Initialization: 
  Statistics of IDS:
  Average search depth: 4.47976 (in 1359 runs)
  Maximal search depth: 40
  Cache hits: 4325

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -7.475 (in 10 real visits)
move-west : -13.4996 (in 10 real visits)
move-south : -13.3333 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -12.2 (in 10 real visits)

Used RAM: 335580

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 3/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 1 0 

Setting time for this decision to 0.964772197309417s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0186551s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1750
Cache Hits: 0
Skipped backups: 29214
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 479 real visits)
move-west : -9.80925 (in 10 real visits)
move-south : -10.875 (in 10 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 335592

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 3/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.965616696588869s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 34
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 3/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.966480682839173s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 33
StateHashKey: 14680068
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 3/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.967344424460432s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 32
StateHashKey: 14680113
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 3/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.968210621062106s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 31
StateHashKey: 2097212
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 3/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.969079279279279s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 2097167
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 3/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 0.969950405770965s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 10485763
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 3/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.970823104693141s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 2097184
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 3/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.971697380307136s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 27
StateHashKey: 2097160
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 3/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.972573236889693s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 2097154
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 3/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.973449773755656s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 3/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.974328804347826s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 6291472
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 3/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.975207615593835s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 2097172
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 3/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.976087114337568s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 2097157
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 3/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.976969118982743s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 3/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.977851818181818s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 14680064
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 3/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.97873703366697s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 2097200
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 3/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.979625683060109s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 6291468
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 3/30
Current state: 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.980515041020966s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 17
StateHashKey: 2097171
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 3/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.981406934306569s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 6291460
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 3/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.982300456621005s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 2097169
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 3/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.983194698354662s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 14680068
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 3/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.984091491308326s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 2097201
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 3/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.984989926739927s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 6291468
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 3/30
Current state: 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.985889092575619s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 2097171
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 3/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.986790825688074s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 2097156
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 3/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.987693296602387s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 3/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.988598345588235s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 8
StateHashKey: 14680064
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 3/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 0.989504139834407s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 6291504
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 3/30
Current state: 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.990412523020258s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 14680092
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 3/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.991321658986175s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 5
StateHashKey: 14680119
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 3/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.992233394833948s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 2097213
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 3/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 0.993145891043398s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 14680079
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 3/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.994060998151571s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 2097203
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 3/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 0.994977798334875s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45389 (in 1377 runs)
  Maximal search depth: 40
  Cache hits: 4529

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 1500
Accumulated number of search nodes in root state: 7511

Used RAM: 335612

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 3 -- REWARD RECEIVED: -6
***********************************************

***********************************************
>>> STARTING ROUND 4 -- REMAINING TIME 1078s
***********************************************
***********************************************
Planning step 1/40 in round 4/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 0.99589537037037s.
DP-UCT: Maximal search depth set to 40

Search time: 0.049597s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2498
Cache Hits: 0
Skipped backups: 30690
Initialization: 
  Statistics of IDS:
  Average search depth: 4.45948 (in 1382 runs)
  Maximal search depth: 40
  Cache hits: 4938

Root Node: 
-15.5385 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.0737 (in 266 real visits)
move-west : -15.5385 (in 214 real visits)
move-north : -22.0631 (in 23 real visits)

Used RAM: 335612

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 4/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 0.996735866543096s.
DP-UCT: Maximal search depth set to 39

Search time: 0.055253s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2603
Cache Hits: 0
Skipped backups: 32286
Initialization: 
  Statistics of IDS:
  Average search depth: 4.50212 (in 1414 runs)
  Maximal search depth: 40
  Cache hits: 5339

Root Node: 
-13.2768 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.2768 (in 277 real visits)
move-west : -16.3063 (in 95 real visits)
move-north : SOLVED with: -39 (in 5 real visits)
move-east : -15.7759 (in 127 real visits)

Used RAM: 335644

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 4/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 0.997605751391466s.
DP-UCT: Maximal search depth set to 38

Search time: 0.037843s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2248
Cache Hits: 0
Skipped backups: 33792
Initialization: 
  Statistics of IDS:
  Average search depth: 4.55239 (in 1441 runs)
  Maximal search depth: 40
  Cache hits: 5641

Root Node: 
-7.24622 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.2142 (in 28 real visits)
move-west : -16.2667 (in 20 real visits)
move-north : -7.24622 (in 435 real visits)
move-east : -16.2392 (in 21 real visits)

Used RAM: 335696

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 4/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 0.998492107706592s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0215788s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1993
Cache Hits: 0
Skipped backups: 35526
Initialization: 
  Statistics of IDS:
  Average search depth: 4.53018 (in 1458 runs)
  Maximal search depth: 40
  Cache hits: 5899

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -13.9167 (in 10 real visits)
move-west : -15.125 (in 10 real visits)
move-south : -15.2845 (in 10 real visits)
move-north : -3 (in 465 real visits)
move-east : -14.8275 (in 10 real visits)

Used RAM: 335748

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 4/30
Current state: 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 0 

Setting time for this decision to 0.999395910780669s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0185411s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1830
Cache Hits: 0
Skipped backups: 37203
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51978 (in 1466 runs)
  Maximal search depth: 40
  Cache hits: 6134

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -10.5 (in 10 real visits)
move-west : -13.7212 (in 10 real visits)
move-south : SOLVED with: -36 (in 5 real visits)
move-north : -2 (in 470 real visits)
move-east : -13.8275 (in 10 real visits)

Used RAM: 335780

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 4/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 0 

Setting time for this decision to 1.00030418604651s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0163798s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1727
Cache Hits: 0
Skipped backups: 38736
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 479 real visits)
move-west : -8.20075 (in 10 real visits)
move-south : -7.135 (in 10 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 335792

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 4/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.00121601489758s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 34
StateHashKey: 2097156
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 4/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.00214538676608s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 33
StateHashKey: 6291457
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 4/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.00307649253731s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 32
StateHashKey: 6291472
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 4/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.00400840336134s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 31
StateHashKey: 2097172
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 4/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.00494112149533s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 2097157
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 4/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.00587652011225s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 10485761
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 4/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.0068127340824s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 6291488
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 4/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.00775164011246s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 27
StateHashKey: 6291480
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 4/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.008691369606s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 2097174
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 4/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.00963474178404s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 25
StateHashKey: 14680069
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 4/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.01057988721805s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 2097201
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 4/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.01152587017874s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 2097164
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 4/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.01247457627119s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 22
StateHashKey: 14680067
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 4/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.01342412818096s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 2097200
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 4/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.01437452830189s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 10485772
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 4/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.01532766761095s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 2097187
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 4/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.01628260869565s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 2097160
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 4/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.01724124881741s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 17
StateHashKey: 2097154
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 4/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.01820170454545s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 4/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.01916398104265s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 15
StateHashKey: 10485760
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 4/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.02012808349146s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 6291488
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 4/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.02109401709402s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 2097176
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 4/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.02206178707224s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 2097158
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 4/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.02303139866794s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 14680065
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 4/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.02400285714286s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 10
StateHashKey: 14680112
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 4/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.02497616777884s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 6291516
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 4/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.02595133587786s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 8
StateHashKey: 14680095
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 4/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.0269264565425s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 2097207
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 4/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.0279034416826s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 2097165
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 4/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.02888325358852s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 2097155
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 4/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.02986398467433s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 4/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.03084659635666s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 10485760
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 4/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.0318310940499s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 2097184
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 4/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.03281748318924s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.51703 (in 1468 runs)
  Maximal search depth: 40
  Cache hits: 6355

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 2000
Accumulated number of search nodes in root state: 10009

Used RAM: 335792

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 4 -- REWARD RECEIVED: -6
***********************************************

***********************************************
>>> STARTING ROUND 5 -- REMAINING TIME 1078s
***********************************************
***********************************************
Planning step 1/40 in round 5/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 1.03380576923077s.
DP-UCT: Maximal search depth set to 40

Search time: 0.047435s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2542
Cache Hits: 0
Skipped backups: 40284
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52003 (in 1473 runs)
  Maximal search depth: 40
  Cache hits: 6763

Root Node: 
-13.0447 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.3802 (in 133 real visits)
move-west : -13.0447 (in 357 real visits)
move-north : -23.8183 (in 13 real visits)

Used RAM: 335792

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 5/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.03471511068335s.
DP-UCT: Maximal search depth set to 39

Search time: 0.038456s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2228
Cache Hits: 0
Skipped backups: 41751
Initialization: 
  Statistics of IDS:
  Average search depth: 4.56786 (in 1481 runs)
  Maximal search depth: 40
  Cache hits: 7077

Root Node: 
-7.33754 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.3911 (in 29 real visits)
move-west : -16.8 (in 19 real visits)
move-north : -7.33754 (in 421 real visits)
move-east : -14.9535 (in 35 real visits)

Used RAM: 335824

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 5/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.03567052023121s.
DP-UCT: Maximal search depth set to 38

Search time: 0.020987s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1856
Cache Hits: 0
Skipped backups: 43374
Initialization: 
  Statistics of IDS:
  Average search depth: 4.56032 (in 1492 runs)
  Maximal search depth: 40
  Cache hits: 7313

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -38 (in 5 real visits)
move-west : -15.5 (in 10 real visits)
move-south : -15.653 (in 10 real visits)
move-north : -3 (in 470 real visits)
move-east : -21.795 (in 10 real visits)

Used RAM: 335832

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 5/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.03664513018322s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0179701s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1780
Cache Hits: 0
Skipped backups: 44958
Initialization: 
  Statistics of IDS:
  Average search depth: 4.55467 (in 1500 runs)
  Maximal search depth: 40
  Cache hits: 7538

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -11.2225 (in 10 real visits)
move-west : -13.8417 (in 10 real visits)
move-south : SOLVED with: -37 (in 5 real visits)
move-north : -2 (in 470 real visits)
move-east : -11.75 (in 10 real visits)

Used RAM: 335840

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 5/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 0 

Setting time for this decision to 1.03762355212355s.
DP-UCT: Maximal search depth set to 36

Search time: 0.017509s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1817
Cache Hits: 0
Skipped backups: 46557
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -5.9525 (in 10 real visits)
move-west : -3 (in 479 real visits)
move-south : -7.28 (in 10 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 335856

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 5/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.03860579710145s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 35
StateHashKey: 6291461
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 5/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.03960541586074s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 34
StateHashKey: 2097169
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 5/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.04060793804453s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 33
StateHashKey: 14680068
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 5/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.04161143410853s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 32
StateHashKey: 14680113
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 5/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.04261687681862s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 31
StateHashKey: 10485820
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 5/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.04362330097087s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 30
StateHashKey: 10485807
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 5/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.04463265306122s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 29
StateHashKey: 2097195
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 5/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.04564494163424s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 2097162
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 5/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.04665725413827s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 10485762
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 5/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.04767153996101s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 2097184
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 5/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.0486887804878s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 2097160
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 5/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.049708984375s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 2097154
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.05073020527859s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.05175342465753s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.05277864838394s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.05380588235294s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 20
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.05483415112856s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 5/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.05586640471513s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 5/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.05690167158309s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 10485776
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 5/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.05793897637795s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 16
StateHashKey: 14680100
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 5/30
Current state: 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.05897832512315s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 2097209
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 5/30
Current state: 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.06001873767258s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 10485774
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 5/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.0610602171767s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 6291491
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 5/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.062104743083s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 6291480
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 5/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.06314935707221s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 2097174
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 5/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.06419702970297s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 10
StateHashKey: 14680069
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 5/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.0652467789891s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 2097201
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 5/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.06629861111111s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 8
StateHashKey: 10485772
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 5/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.06735253227408s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 2097187
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 5/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.06840854870775s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 6291464
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 5/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.06946766169154s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 6291474
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 5/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.07052689243028s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 2097172
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 5/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.07158823529412s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 3
StateHashKey: 6291461
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 5/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.07265269461078s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 10485777
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 5/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.07372027972028s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54329 (in 1513 runs)
  Maximal search depth: 40
  Cache hits: 7766

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 2500
Accumulated number of search nodes in root state: 12551

Used RAM: 335876

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 5 -- REWARD RECEIVED: -5
***********************************************

***********************************************
>>> STARTING ROUND 6 -- REMAINING TIME 1077s
***********************************************
***********************************************
Planning step 1/40 in round 6/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 1.07479s.
DP-UCT: Maximal search depth set to 40

Search time: 0.048604s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2530
Cache Hits: 0
Skipped backups: 48159
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54551 (in 1516 runs)
  Maximal search depth: 40
  Cache hits: 8169

Root Node: 
-12.2493 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.0928 (in 113 real visits)
move-west : -12.2493 (in 360 real visits)
move-north : -22.129 (in 30 real visits)

Used RAM: 335876

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 6/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.07577477477477s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0372739s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2232
Cache Hits: 0
Skipped backups: 49749
Initialization: 
  Statistics of IDS:
  Average search depth: 4.55069 (in 1529 runs)
  Maximal search depth: 40
  Cache hits: 8481

Root Node: 
-7.60675 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.1596 (in 28 real visits)
move-west : -16.663 (in 16 real visits)
move-north : -7.60675 (in 446 real visits)
move-east : -17.1125 (in 14 real visits)

Used RAM: 335900

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 6/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.07681062124248s.
DP-UCT: Maximal search depth set to 38

Search time: 0.020612s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1886
Cache Hits: 0
Skipped backups: 51393
Initialization: 
  Statistics of IDS:
  Average search depth: 4.55062 (in 1531 runs)
  Maximal search depth: 40
  Cache hits: 8730

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -14.2625 (in 10 real visits)
move-west : -15.527 (in 10 real visits)
move-south : -15.71 (in 10 real visits)
move-north : -3 (in 465 real visits)
move-east : -20.2907 (in 10 real visits)

Used RAM: 335912

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 6/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.07786559679037s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0182559s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1834
Cache Hits: 0
Skipped backups: 53139
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 8968

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -37 (in 5 real visits)
move-west : -13.5232 (in 10 real visits)
move-south : -13.6667 (in 10 real visits)
move-north : -2 (in 467 real visits)
move-east : -9.35 (in 13 real visits)

Used RAM: 335912

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 6/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 0 

Setting time for this decision to 1.07892570281124s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0168719s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1839
Cache Hits: 0
Skipped backups: 54561
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 390 real visits)
move-west : -5.25 (in 8 real visits)
move-south : -3.89775 (in 101 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 335920

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 6/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.07998894472362s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 35
StateHashKey: 14680072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 6/30
Current state: 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.08107142857143s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 34
StateHashKey: 2097202
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 6/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.08215508559919s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 33
StateHashKey: 2097164
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 6/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.08324193548387s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 32
StateHashKey: 2097155
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 6/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.08433097880928s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 31
StateHashKey: 10485760
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 6/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.08542121212121s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 30
StateHashKey: 10485792
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 6/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.08651263902932s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 14680104
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 6/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.08760728744939s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 6291514
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 6/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.0887031408308s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 14680094
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 6/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.08980324543611s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 26
StateHashKey: 10485815
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 6/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.09090456852792s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 25
StateHashKey: 10485805
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 6/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.0920081300813s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 24
StateHashKey: 10485803
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 6/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.09311393692777s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 2097194
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 6/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.09422199592668s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 2097162
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 6/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.09533231396534s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 2097154
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 6/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.09644387755102s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 20
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 6/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.09755975485189s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 6291472
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 6/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.09867689161554s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 6291476
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 6/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.09979631525077s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 17
StateHashKey: 2097173
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 6/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.10091803278689s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 16
StateHashKey: 10485765
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 6/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.10204102564103s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 6291489
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 6/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.10316837782341s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 10485784
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 6/30
Current state: 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.10429701952724s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 2097190
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 6/30
Current state: 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.10542798353909s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 10485769
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 6/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.10656127703399s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 2097186
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 6/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.10769690721649s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 2097160
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 6/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.10883488132095s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 2097154
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 6/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.10997520661157s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 6/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.11111892450879s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 6/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.11226397515528s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 6/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.11341139896373s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 6/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.1145612033195s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 6/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.11570924195223s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 3
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 6/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.1168659043659s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 10485776
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 6/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.11802393340271s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.54026 (in 1540 runs)
  Maximal search depth: 40
  Cache hits: 9212

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 3000
Accumulated number of search nodes in root state: 15081

Used RAM: 335920

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 6 -- REWARD RECEIVED: -5
***********************************************

***********************************************
>>> STARTING ROUND 7 -- REMAINING TIME 1077s
***********************************************
***********************************************
Planning step 1/40 in round 7/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 1.11918541666667s.
DP-UCT: Maximal search depth set to 40

Search time: 0.050813s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2516
Cache Hits: 0
Skipped backups: 56253
Initialization: 
  Statistics of IDS:
  Average search depth: 4.53826 (in 1542 runs)
  Maximal search depth: 40
  Cache hits: 9617

Root Node: 
-12.3457 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.7403 (in 72 real visits)
move-west : -12.3457 (in 422 real visits)
move-north : -23.375 (in 9 real visits)

Used RAM: 335920

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 7/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.12025651720542s.
DP-UCT: Maximal search depth set to 39

Search time: 0.035289s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2231
Cache Hits: 0
Skipped backups: 57789
Initialization: 
  Statistics of IDS:
  Average search depth: 4.53786 (in 1545 runs)
  Maximal search depth: 40
  Cache hits: 9943

Root Node: 
-7.40878 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.4462 (in 32 real visits)
move-west : -16.7001 (in 21 real visits)
move-north : -7.40878 (in 422 real visits)
move-east : -15.7117 (in 29 real visits)

Used RAM: 335944

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 7/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.12138413361169s.
DP-UCT: Maximal search depth set to 38

Search time: 0.033376s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2266
Cache Hits: 0
Skipped backups: 59322
Initialization: 
  Statistics of IDS:
  Average search depth: 4.53826 (in 1555 runs)
  Maximal search depth: 40
  Cache hits: 10257

Root Node: 
-7.74154 (in 505 real visits)

Q-Value Estimates: 
noop() : -7.74154 (in 447 real visits)
move-west : -15.77 (in 21 real visits)
move-south : -15.1187 (in 23 real visits)
move-north : SOLVED with: -38 (in 5 real visits)
move-east : -23.09 (in 9 real visits)

Used RAM: 335944

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 7/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.12251724137931s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0190551s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1844
Cache Hits: 0
Skipped backups: 60774
Initialization: 
  Statistics of IDS:
  Average search depth: 4.535 (in 1557 runs)
  Maximal search depth: 40
  Cache hits: 10496

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -14.8617 (in 10 real visits)
move-west : -15.2405 (in 10 real visits)
move-south : -15.2652 (in 10 real visits)
move-north : -3 (in 465 real visits)
move-east : -15.3 (in 10 real visits)

Used RAM: 335956

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 7/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.12366736401674s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0177088s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1822
Cache Hits: 0
Skipped backups: 62280
Initialization: 
  Statistics of IDS:
  Average search depth: 4.53107 (in 1561 runs)
  Maximal search depth: 40
  Cache hits: 10729

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -11.15 (in 10 real visits)
move-west : -13.4046 (in 10 real visits)
move-south : -13.7371 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -12.2 (in 10 real visits)

Used RAM: 335956

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 7/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 0 

Setting time for this decision to 1.12482094240838s.
DP-UCT: Maximal search depth set to 35

Search time: 0.017529s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1800
Cache Hits: 0
Skipped backups: 63729
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 140 real visits)
move-west : -3 (in 351 real visits)
move-south : -5.175 (in 8 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 335956

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 7/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.12597693920335s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 34
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 7/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.12715424973767s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 33
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 7/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.12833508403361s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 32
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 7/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.12951629863302s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 31
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 7/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.13069894736842s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 7/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.13188514225501s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 10485764
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 7/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.13307489451477s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 2097185
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 7/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.13426610348469s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 27
StateHashKey: 2097160
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 7/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.13545983086681s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 6291458
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 7/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.13665502645503s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 7/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.13785487288136s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 2097156
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 7/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.1390572640509s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 7/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.14026220806794s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 7/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.14146865037194s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 7/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.14267765957447s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 20
StateHashKey: 6291472
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 7/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.14388924387646s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 14680084
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 7/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.14510341151386s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 2097205
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 7/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.1463212379936s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 14680077
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 7/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.14754166666667s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 6291507
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 7/30
Current state: 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.14876363636364s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 15
StateHashKey: 10485788
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 7/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.14998822269807s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 2097191
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 7/30
Current state: 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.1512154340836s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 13
StateHashKey: 10485769
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 7/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.15244527896996s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 2097186
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 7/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.15367776584318s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 2097160
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 7/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.15491397849462s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 2097154
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 7/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.15615177610334s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 9
StateHashKey: 10485760
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 7/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.15739224137931s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 2097184
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 7/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.15863538295577s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 2097160
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 7/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.15988120950324s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 14680066
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 7/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.16113081081081s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 5
StateHashKey: 10485808
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 7/30
Current state: 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.16238203463203s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 2097196
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 7/30
Current state: 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.16363596966414s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 10485771
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 7/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.16489262472885s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 6291490
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 7/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.16615200868621s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.52971 (in 1565 runs)
  Maximal search depth: 40
  Cache hits: 10965

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 3500
Accumulated number of search nodes in root state: 17597

Used RAM: 335964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 7 -- REWARD RECEIVED: -6
***********************************************

***********************************************
>>> STARTING ROUND 8 -- REMAINING TIME 1077s
***********************************************
***********************************************
Planning step 1/40 in round 8/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 1.1674152173913s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0491281s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2545
Cache Hits: 0
Skipped backups: 65331
Initialization: 
  Statistics of IDS:
  Average search depth: 4.53129 (in 1566 runs)
  Maximal search depth: 40
  Cache hits: 11380

Root Node: 
-13.4726 (in 503 real visits)

Q-Value Estimates: 
noop() : -15.9561 (in 152 real visits)
move-west : -13.4726 (in 335 real visits)
move-north : -22.5992 (in 16 real visits)

Used RAM: 335964

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 8/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.16858650707291s.
DP-UCT: Maximal search depth set to 39

Search time: 0.032017s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2187
Cache Hits: 0
Skipped backups: 66951
Initialization: 
  Statistics of IDS:
  Average search depth: 4.53316 (in 1568 runs)
  Maximal search depth: 40
  Cache hits: 11699

Root Node: 
-7.59803 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.875 (in 21 real visits)
move-west : -16.653 (in 17 real visits)
move-north : -7.59803 (in 440 real visits)
move-east : -15.5233 (in 26 real visits)

Used RAM: 335984

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 8/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.16982135076253s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0359321s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2292
Cache Hits: 0
Skipped backups: 68526
Initialization: 
  Statistics of IDS:
  Average search depth: 4.53558 (in 1574 runs)
  Maximal search depth: 40
  Cache hits: 12029

Root Node: 
-7.58863 (in 505 real visits)

Q-Value Estimates: 
noop() : -7.58863 (in 414 real visits)
move-west : -15.5838 (in 41 real visits)
move-south : -15.6717 (in 36 real visits)
move-north : SOLVED with: -38 (in 5 real visits)
move-east : -23.09 (in 9 real visits)

Used RAM: 335984

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 8/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.17105452562704s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0360701s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2223
Cache Hits: 0
Skipped backups: 69948
Initialization: 
  Statistics of IDS:
  Average search depth: 4.53807 (in 1589 runs)
  Maximal search depth: 40
  Cache hits: 12335

Root Node: 
-7.08061 (in 505 real visits)

Q-Value Estimates: 
noop() : -7.08061 (in 425 real visits)
move-west : -12.9791 (in 46 real visits)
move-south : -15.1497 (in 20 real visits)
move-north : SOLVED with: -37 (in 5 real visits)
move-east : -21.2413 (in 9 real visits)

Used RAM: 335988

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 8/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.17228930131004s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0579522s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2534
Cache Hits: 0
Skipped backups: 71460
Initialization: 
  Statistics of IDS:
  Average search depth: 4.56124 (in 1641 runs)
  Maximal search depth: 40
  Cache hits: 12681

Root Node: 
-13.0459 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -36 (in 5 real visits)
move-west : -15.5139 (in 131 real visits)
move-south : -13.0459 (in 343 real visits)
move-north : SOLVED with: -36 (in 5 real visits)
move-east : -20.2185 (in 21 real visits)

Used RAM: 336020

Submitted action: move-south 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 8/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.17350273224044s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0573359s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2604
Cache Hits: 0
Skipped backups: 73002
Initialization: 
  Statistics of IDS:
  Average search depth: 4.57236 (in 1693 runs)
  Maximal search depth: 40
  Cache hits: 13057

Root Node: 
-13.0771 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.0771 (in 316 real visits)
move-west : -14.892 (in 80 real visits)
move-north : SOLVED with: -35 (in 5 real visits)
move-east : -14.534 (in 103 real visits)

Used RAM: 336116

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 8/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.17471881838074s.
DP-UCT: Maximal search depth set to 34

Search time: 0.0335262s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2157
Cache Hits: 0
Skipped backups: 74460
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6076 (in 1710 runs)
  Maximal search depth: 40
  Cache hits: 13349

Root Node: 
-6.54174 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.6733 (in 23 real visits)
move-west : -14.1098 (in 20 real visits)
move-north : -6.54174 (in 439 real visits)
move-east : -14.5187 (in 22 real visits)

Used RAM: 336184

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 8/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.17596495071194s.
DP-UCT: Maximal search depth set to 33

Search time: 0.020237s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1894
Cache Hits: 0
Skipped backups: 76026
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60842 (in 1711 runs)
  Maximal search depth: 40
  Cache hits: 13599

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -13.5133 (in 10 real visits)
move-west : -13.6617 (in 10 real visits)
move-south : -13.7142 (in 10 real visits)
move-north : -3 (in 465 real visits)
move-east : -17.5388 (in 10 real visits)

Used RAM: 336200

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 9/40 in round 8/30
Current state: 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.17722697368421s.
DP-UCT: Maximal search depth set to 32

Search time: 0.018631s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1848
Cache Hits: 0
Skipped backups: 77700
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60548 (in 1716 runs)
  Maximal search depth: 40
  Cache hits: 13840

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -4.95 (in 10 real visits)
move-west : -12.1312 (in 10 real visits)
move-south : -12 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -8.3 (in 10 real visits)

Used RAM: 336200

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 10/40 in round 8/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 0 

Setting time for this decision to 1.17849396267838s.
DP-UCT: Maximal search depth set to 31

Search time: 0.0172141s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1814
Cache Hits: 0
Skipped backups: 79365
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 479 real visits)
move-west : -9.62187 (in 10 real visits)
move-south : -7.375 (in 10 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 336212

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 11/40 in round 8/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.17976593406593s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 30
StateHashKey: 14680064
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 8/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.18105940594059s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 29
StateHashKey: 2097200
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 8/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.18235682819383s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 6291468
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 8/30
Current state: 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.18365600882029s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 14680083
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 8/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.18495695364238s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 26
StateHashKey: 14680116
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 8/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.18626077348066s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 6291517
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 8/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.18756747787611s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 2097183
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 8/30
Current state: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.18887818383167s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 2097159
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 8/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.19019068736142s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 6291457
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 8/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.19150721420644s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 6291472
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 8/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.19282555555556s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 20
StateHashKey: 2097172
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 8/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.19414571746385s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 2097157
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 8/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.19546993318486s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 6291457
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 8/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.19679710144928s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 17
StateHashKey: 6291472
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 8/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.19812834821429s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 2097172
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 8/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.1994625698324s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 2097157
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 8/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.20079865771812s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 8/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.20213773796193s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 8/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.20348094170404s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 8/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.20482603815937s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 2097156
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 8/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.20617415730337s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 6291457
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 8/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.20752530933633s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 6291472
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 8/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.2088795045045s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 8
StateHashKey: 10485780
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 8/30
Current state: 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.21023675310034s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 2097189
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 8/30
Current state: 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.21159819413093s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 10485769
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 8/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.2129615819209s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 2097186
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 8/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.21432805429864s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 2097160
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 8/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.21569762174405s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 10485762
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 8/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.21707029478458s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 2097184
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 8/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.21844721906924s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60303 (in 1718 runs)
  Maximal search depth: 40
  Cache hits: 14079

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 4000
Accumulated number of search nodes in root state: 20142

Used RAM: 336216

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 8 -- REWARD RECEIVED: -10
***********************************************

***********************************************
>>> STARTING ROUND 9 -- REMAINING TIME 1076s
***********************************************
***********************************************
Planning step 1/40 in round 9/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 1.21982613636364s.
DP-UCT: Maximal search depth set to 40

Search time: 0.052953s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2556
Cache Hits: 0
Skipped backups: 81003
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60442 (in 1719 runs)
  Maximal search depth: 40
  Cache hits: 14497

Root Node: 
-13.6554 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.7482 (in 102 real visits)
move-west : -13.6554 (in 382 real visits)
move-north : -21.8528 (in 19 real visits)

Used RAM: 336216

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 9/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.22110466439135s.
DP-UCT: Maximal search depth set to 39

Search time: 0.058588s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2633
Cache Hits: 0
Skipped backups: 82575
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61102 (in 1743 runs)
  Maximal search depth: 40
  Cache hits: 14912

Root Node: 
-14.8456 (in 504 real visits)

Q-Value Estimates: 
noop() : -14.8456 (in 245 real visits)
move-west : -16.3333 (in 112 real visits)
move-north : SOLVED with: -39 (in 5 real visits)
move-east : -15.9603 (in 142 real visits)

Used RAM: 336232

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 9/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.22242482915718s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0569959s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2632
Cache Hits: 0
Skipped backups: 84213
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62197 (in 1775 runs)
  Maximal search depth: 40
  Cache hits: 15319

Root Node: 
-13.2744 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.2744 (in 261 real visits)
move-west : -16.1101 (in 114 real visits)
move-north : SOLVED with: -38 (in 5 real visits)
move-east : -16.0715 (in 124 real visits)

Used RAM: 336264

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 9/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.22375028506271s.
DP-UCT: Maximal search depth set to 37

Search time: 0.052022s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2542
Cache Hits: 0
Skipped backups: 85728
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6294 (in 1789 runs)
  Maximal search depth: 40
  Cache hits: 15725

Root Node: 
-13.1124 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.1124 (in 310 real visits)
move-west : -15.8287 (in 78 real visits)
move-north : SOLVED with: -37 (in 5 real visits)
move-east : -15.2426 (in 111 real visits)

Used RAM: 336304

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 9/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.22508333333333s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0568299s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2626
Cache Hits: 0
Skipped backups: 87351
Initialization: 
  Statistics of IDS:
  Average search depth: 4.63099 (in 1794 runs)
  Maximal search depth: 40
  Cache hits: 16161

Root Node: 
-14.2653 (in 504 real visits)

Q-Value Estimates: 
noop() : -14.2653 (in 220 real visits)
move-west : -15.3106 (in 107 real visits)
move-north : SOLVED with: -36 (in 5 real visits)
move-east : -14.9912 (in 172 real visits)

Used RAM: 336320

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 9/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.22641485714286s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0590658s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2623
Cache Hits: 0
Skipped backups: 88953
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64921 (in 1833 runs)
  Maximal search depth: 40
  Cache hits: 16562

Root Node: 
-14.2138 (in 504 real visits)

Q-Value Estimates: 
noop() : -14.2138 (in 228 real visits)
move-west : -14.9612 (in 126 real visits)
move-north : SOLVED with: -35 (in 5 real visits)
move-east : -14.7356 (in 145 real visits)

Used RAM: 336328

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 9/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.22774599542334s.
DP-UCT: Maximal search depth set to 34

Search time: 0.0340631s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2235
Cache Hits: 0
Skipped backups: 90501
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65378 (in 1837 runs)
  Maximal search depth: 40
  Cache hits: 16883

Root Node: 
-6.77983 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.1605 (in 26 real visits)
move-west : -14.0825 (in 22 real visits)
move-north : -6.77983 (in 439 real visits)
move-east : -14.429 (in 17 real visits)

Used RAM: 336376

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 9/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.22910767468499s.
DP-UCT: Maximal search depth set to 33

Search time: 0.0533991s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2565
Cache Hits: 0
Skipped backups: 92067
Initialization: 
  Statistics of IDS:
  Average search depth: 4.66739 (in 1852 runs)
  Maximal search depth: 40
  Cache hits: 17268

Root Node: 
-11.1706 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -33 (in 5 real visits)
move-west : -13.4724 (in 132 real visits)
move-south : -11.1706 (in 345 real visits)
move-north : SOLVED with: -33 (in 5 real visits)
move-east : -18.79 (in 18 real visits)

Used RAM: 336376

Submitted action: move-south 
Immediate reward: -1
***********************************************

***********************************************
Planning step 9/40 in round 9/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.23045183486239s.
DP-UCT: Maximal search depth set to 32

Search time: 0.0550661s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2580
Cache Hits: 0
Skipped backups: 93630
Initialization: 
  Statistics of IDS:
  Average search depth: 4.67487 (in 1870 runs)
  Maximal search depth: 40
  Cache hits: 17678

Root Node: 
-12.4042 (in 504 real visits)

Q-Value Estimates: 
noop() : -12.4042 (in 301 real visits)
move-west : -13.9012 (in 88 real visits)
move-north : SOLVED with: -32 (in 5 real visits)
move-east : -13.5613 (in 110 real visits)

Used RAM: 336412

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 10/40 in round 9/30
Current state: 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.23179678530425s.
DP-UCT: Maximal search depth set to 31

Search time: 0.0344s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2274
Cache Hits: 0
Skipped backups: 95229
Initialization: 
  Statistics of IDS:
  Average search depth: 4.67575 (in 1872 runs)
  Maximal search depth: 40
  Cache hits: 18008

Root Node: 
-6.67557 (in 504 real visits)

Q-Value Estimates: 
noop() : -12.7005 (in 21 real visits)
move-west : -13.591 (in 16 real visits)
move-north : -6.67557 (in 447 real visits)
move-east : -12.9582 (in 20 real visits)

Used RAM: 336436

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 11/40 in round 9/30
Current state: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.23316896551724s.
DP-UCT: Maximal search depth set to 30

Search time: 0.037472s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2295
Cache Hits: 0
Skipped backups: 96816
Initialization: 
  Statistics of IDS:
  Average search depth: 4.67857 (in 1876 runs)
  Maximal search depth: 40
  Cache hits: 18338

Root Node: 
-6.49467 (in 505 real visits)

Q-Value Estimates: 
noop() : -6.49467 (in 430 real visits)
move-west : -11.3375 (in 36 real visits)
move-south : -12.15 (in 25 real visits)
move-north : SOLVED with: -30 (in 5 real visits)
move-east : -12.36 (in 9 real visits)

Used RAM: 336436

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 12/40 in round 9/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.23453970080552s.
DP-UCT: Maximal search depth set to 29

Search time: 0.020046s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1888
Cache Hits: 0
Skipped backups: 98460
Initialization: 
  Statistics of IDS:
  Average search depth: 4.67304 (in 1884 runs)
  Maximal search depth: 40
  Cache hits: 18583

Root Node: 
-3.04657 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -29 (in 5 real visits)
move-west : -12.1475 (in 10 real visits)
move-south : -12.125 (in 10 real visits)
move-north : -3.04657 (in 470 real visits)
move-east : -10.8 (in 10 real visits)

Used RAM: 336440

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 13/40 in round 9/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.23593433179723s.
DP-UCT: Maximal search depth set to 28

Search time: 0.0159991s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1754
Cache Hits: 0
Skipped backups: 99930
Initialization: 
  Statistics of IDS:
  Average search depth: 4.66861 (in 1889 runs)
  Maximal search depth: 40
  Cache hits: 18801

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -28 (in 5 real visits)
move-west : -10.6667 (in 10 real visits)
move-south : -10.6667 (in 10 real visits)
move-north : -2 (in 470 real visits)
move-east : -9.8 (in 10 real visits)

Used RAM: 336444

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 14/40 in round 9/30
Current state: 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 1 0 

Setting time for this decision to 1.23733564013841s.
DP-UCT: Maximal search depth set to 27

Search time: 0.0185111s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1850
Cache Hits: 0
Skipped backups: 101553
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -3.65 (in 16 real visits)
move-west : -3 (in 473 real visits)
move-south : -5.6775 (in 10 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 336448

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 15/40 in round 9/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.23873903002309s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 6291481
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

Used RAM: 336476

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 9/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.24016647398844s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 2097174
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

Used RAM: 336476

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 9/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.24159722222222s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 2097157
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

Used RAM: 336476

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 9/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.24303128621089s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

Used RAM: 336476

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 9/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.24446751740139s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

Used RAM: 336476

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 9/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.24590824622532s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 21
StateHashKey: 10485760
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

Used RAM: 336476

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 9/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.2473511627907s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 10485792
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

Used RAM: 336476

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 9/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.24879860302678s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 2097192
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

Used RAM: 336476

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 9/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.25024708624709s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 2097162
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

Used RAM: 336476

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 9/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.25170011668611s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 10485762
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

Used RAM: 336476

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 9/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.25315654205607s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 2097184
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

Used RAM: 336476

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 9/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.25461637426901s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 15
StateHashKey: 10485768
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

Used RAM: 336476

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 9/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.25608196721311s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 14680098
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

Used RAM: 336476

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 9/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.25754865181712s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 13
StateHashKey: 10485816
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

Used RAM: 336476

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 9/30
Current state: 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.25901877934272s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 2097198
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

Used RAM: 336476

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 9/30
Current state: 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.26049236192714s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 2097163
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

Used RAM: 336476

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 9/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.26196941176471s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 10
StateHashKey: 10485762
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

Used RAM: 336476

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 9/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.26345111896349s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 6291488
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

Used RAM: 336476

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 9/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.26493632075472s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 6291480
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

Used RAM: 336476

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 9/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.26642384887839s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 7
StateHashKey: 14680086
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

Used RAM: 336476

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 9/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.26791489361702s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 6291509
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

Used RAM: 336476

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 9/30
Current state: 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.26940828402367s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 2097181
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

Used RAM: 336476

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 9/30
Current state: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.27090758293839s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 6291463
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

Used RAM: 336476

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 9/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.27240925266904s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 3
StateHashKey: 6291473
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

Used RAM: 336476

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 9/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.27391567695962s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 10485780
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

Used RAM: 336476

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 9/30
Current state: 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.27542449464923s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65949 (in 1903 runs)
  Maximal search depth: 40
  Cache hits: 19035

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 4500
Accumulated number of search nodes in root state: 22698

Used RAM: 336476

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 9 -- REWARD RECEIVED: -14
***********************************************

***********************************************
>>> STARTING ROUND 10 -- REMAINING TIME 1075s
***********************************************
***********************************************
Planning step 1/40 in round 10/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 1.27693571428571s.
DP-UCT: Maximal search depth set to 40

Search time: 0.048038s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2517
Cache Hits: 0
Skipped backups: 103113
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6602 (in 1907 runs)
  Maximal search depth: 40
  Cache hits: 19443

Root Node: 
-14.651 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.5087 (in 137 real visits)
move-west : -14.651 (in 338 real visits)
move-north : -21.5823 (in 28 real visits)

Used RAM: 336476

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 10/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.27834803337306s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0347641s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2264
Cache Hits: 0
Skipped backups: 104793
Initialization: 
  Statistics of IDS:
  Average search depth: 4.66492 (in 1913 runs)
  Maximal search depth: 40
  Cache hits: 19771

Root Node: 
-7.75685 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.875 (in 13 real visits)
move-west : -16.81 (in 10 real visits)
move-north : -7.75685 (in 468 real visits)
move-east : -15.7983 (in 13 real visits)

Used RAM: 336500

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 10/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.27982696897375s.
DP-UCT: Maximal search depth set to 38

Search time: 0.020426s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1940
Cache Hits: 0
Skipped backups: 106551
Initialization: 
  Statistics of IDS:
  Average search depth: 4.66492 (in 1913 runs)
  Maximal search depth: 40
  Cache hits: 20039

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -14.6787 (in 10 real visits)
move-west : -15.527 (in 10 real visits)
move-south : -15.563 (in 10 real visits)
move-north : -3 (in 465 real visits)
move-east : -19.2575 (in 10 real visits)

Used RAM: 336508

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 10/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.28132616487455s.
DP-UCT: Maximal search depth set to 37

Search time: 0.020299s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1891
Cache Hits: 0
Skipped backups: 108363
Initialization: 
  Statistics of IDS:
  Average search depth: 4.66215 (in 1918 runs)
  Maximal search depth: 40
  Cache hits: 20288

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -37 (in 5 real visits)
move-west : -13.6667 (in 10 real visits)
move-south : -14.8617 (in 10 real visits)
move-north : -2 (in 470 real visits)
move-east : -12.5 (in 10 real visits)

Used RAM: 336508

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 10/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 0 

Setting time for this decision to 1.28282894736842s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0163929s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1873
Cache Hits: 0
Skipped backups: 109932
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 140 real visits)
move-west : -3.06075 (in 351 real visits)
move-south : -11.15 (in 8 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 336508

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 10/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.28434131736527s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 35
StateHashKey: 14680072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 10/30
Current state: 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.28587649880096s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 34
StateHashKey: 2097202
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 10/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.28741536614646s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 33
StateHashKey: 2097164
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 10/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.28895793269231s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 32
StateHashKey: 2097155
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 10/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.29050421179302s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 31
StateHashKey: 14680064
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 10/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.29205301204819s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 2097200
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 10/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.29360554885404s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 29
StateHashKey: 6291468
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 10/30
Current state: 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.29516183574879s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 28
StateHashKey: 10485779
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 10/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.296723095526s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 27
StateHashKey: 2097188
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 10/30
Current state: 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.29828692493947s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 6291465
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 10/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.29985454545455s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 25
StateHashKey: 10485778
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 10/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.30142718446602s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 2097188
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 10/30
Current state: 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.30300243013366s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 2097161
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 10/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.30458150851582s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 2097154
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 10/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.30616443361754s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 10/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.30775243902439s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 20
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 10/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.30934432234432s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 10/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.31093887530562s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 10/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.31253733170135s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 17
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 10/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.31413970588235s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 16
StateHashKey: 10485760
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 10/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.3157472392638s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 2097184
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 10/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.31735749385749s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 6291464
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 10/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.3189717097171s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 6291474
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 10/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.32058990147783s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 6291476
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 10/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.32221331689273s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 6291477
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 10/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.32383950617284s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 2097173
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 10/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.32546971569839s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 6291461
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 10/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.3271051980198s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 6291473
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 10/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.32874349442379s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 2097172
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 10/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.3303858560794s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 2097157
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 10/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.33203229813665s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 6291457
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 10/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.3336828358209s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 4
StateHashKey: 14680080
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 10/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.33533872976339s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 3
StateHashKey: 2097204
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 10/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.33699750623441s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 14680077
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 10/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.33866042446941s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20539

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 5000
Accumulated number of search nodes in root state: 25215

Used RAM: 336508

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 10 -- REWARD RECEIVED: -5
***********************************************

***********************************************
>>> STARTING ROUND 11 -- REMAINING TIME 1075s
***********************************************
***********************************************
Planning step 1/40 in round 11/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 1.34032875s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0519161s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2492
Cache Hits: 0
Skipped backups: 111504
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 20946

Root Node: 
-12.8031 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.3062 (in 127 real visits)
move-west : -12.8031 (in 357 real visits)
move-north : -22.3215 (in 19 real visits)

Used RAM: 336508

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 11/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.34188986232791s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0344269s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2208
Cache Hits: 0
Skipped backups: 112851
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6618 (in 1919 runs)
  Maximal search depth: 40
  Cache hits: 21266

Root Node: 
-7.29947 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.7464 (in 24 real visits)
move-west : -16.803 (in 18 real visits)
move-north : -7.29947 (in 413 real visits)
move-east : -14.2853 (in 49 real visits)

Used RAM: 336524

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 11/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.34352380952381s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0202892s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1889
Cache Hits: 0
Skipped backups: 114420
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65783 (in 1923 runs)
  Maximal search depth: 40
  Cache hits: 21518

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -12.425 (in 10 real visits)
move-west : -15.59 (in 10 real visits)
move-south : -15.626 (in 10 real visits)
move-north : -3 (in 465 real visits)
move-east : -23.265 (in 10 real visits)

Used RAM: 336524

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 11/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.34517816813049s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0180781s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1824
Cache Hits: 0
Skipped backups: 116028
Initialization: 
  Statistics of IDS:
  Average search depth: 4.65456 (in 1928 runs)
  Maximal search depth: 40
  Cache hits: 21751

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -37 (in 5 real visits)
move-west : -13.6667 (in 10 real visits)
move-south : -14.0917 (in 10 real visits)
move-north : -2 (in 470 real visits)
move-east : -12.5 (in 10 real visits)

Used RAM: 336528

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 11/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 1 

Setting time for this decision to 1.34684045226131s.
DP-UCT: Maximal search depth set to 36

Search time: 0.017884s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1730
Cache Hits: 0
Skipped backups: 117654
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -4.325 (in 10 real visits)
move-west : -3 (in 484 real visits)
move-south : SOLVED with: -36 (in 5 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 336544

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 11/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.34850691823899s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 35
StateHashKey: 6291496
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 11/30
Current state: 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.35020151133501s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 34
StateHashKey: 10485786
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 11/30
Current state: 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.35189785624212s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 33
StateHashKey: 10485798
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 11/30
Current state: 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.35359722222222s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 32
StateHashKey: 2097193
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 11/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.35530214917826s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 31
StateHashKey: 2097162
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 11/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.35701012658228s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 2097154
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 11/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.3587237008872s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 29
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 11/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.36044162436548s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 11/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.36216518424396s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 27
StateHashKey: 2097156
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 11/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.36389185750636s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 11/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.36562420382166s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 11/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.36735969387755s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 11/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.36909961685824s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 11/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.3708452685422s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 11/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.37259411011524s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 6291460
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 11/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.37434743589744s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 20
StateHashKey: 2097169
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 11/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.37610526315789s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 14680068
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 11/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.3778676092545s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 14680113
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 11/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.37963577863578s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 14680124
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 11/30
Current state: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.38140721649485s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 2097215
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 11/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.38318451612903s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 2097167
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 11/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.38496511627907s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 6291459
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 11/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.38675032341527s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 11/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.38854015544041s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 2097156
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 11/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.39033463035019s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 11/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.39213506493506s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 11/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.3939388816645s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 11/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.39574739583333s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 2097156
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 11/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.39756192959583s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 11/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.39937989556136s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 11/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.40120261437908s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 11/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.40303141361257s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 11/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.40486369593709s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 3
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 11/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.40670078740157s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 2097156
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 11/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.40854270696452s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64809 (in 1938 runs)
  Maximal search depth: 40
  Cache hits: 21967

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 5500
Accumulated number of search nodes in root state: 27707

Used RAM: 336564

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 11 -- REWARD RECEIVED: -5
***********************************************

***********************************************
>>> STARTING ROUND 12 -- REMAINING TIME 1074s
***********************************************
***********************************************
Planning step 1/40 in round 12/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 1.41038947368421s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0487778s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2532
Cache Hits: 0
Skipped backups: 119250
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6493 (in 1939 runs)
  Maximal search depth: 40
  Cache hits: 22375

Root Node: 
-13.4823 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.2833 (in 125 real visits)
move-west : -13.4823 (in 351 real visits)
move-north : -20.2383 (in 27 real visits)

Used RAM: 336564

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 12/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.4121277997365s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0348229s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2226
Cache Hits: 0
Skipped backups: 120915
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64985 (in 1942 runs)
  Maximal search depth: 40
  Cache hits: 22698

Root Node: 
-7.36633 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.875 (in 19 real visits)
move-west : -16.656 (in 15 real visits)
move-north : -7.36633 (in 449 real visits)
move-east : -15.5111 (in 21 real visits)

Used RAM: 336584

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 12/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.41393931398417s.
DP-UCT: Maximal search depth set to 38

Search time: 0.020225s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1856
Cache Hits: 0
Skipped backups: 122475
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64836 (in 1948 runs)
  Maximal search depth: 40
  Cache hits: 22940

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -38 (in 5 real visits)
move-west : -15.59 (in 10 real visits)
move-south : -15.2447 (in 10 real visits)
move-north : -3 (in 470 real visits)
move-east : -20.57 (in 10 real visits)

Used RAM: 336584

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 12/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.41577410832232s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0157769s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1737
Cache Hits: 0
Skipped backups: 123960
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64414 (in 1953 runs)
  Maximal search depth: 40
  Cache hits: 23158

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -37 (in 5 real visits)
move-west : -14.15 (in 10 real visits)
move-south : -13.8417 (in 10 real visits)
move-north : -2 (in 470 real visits)
move-east : -9.35 (in 10 real visits)

Used RAM: 336592

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 12/30
Current state: 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 1 0 

Setting time for this decision to 1.41762037037037s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0163479s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1768
Cache Hits: 0
Skipped backups: 125469
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -3.6275 (in 12 real visits)
move-west : -3 (in 477 real visits)
move-south : -9.12 (in 10 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 336600

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 12/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.41947152317881s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 35
StateHashKey: 6291481
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 12/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.42134880636605s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 34
StateHashKey: 2097174
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 12/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.42323240371846s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 33
StateHashKey: 2097157
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 12/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.42511968085106s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 32
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.42701065246338s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 31
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 12/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.428908s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 12/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.4308090787717s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 10485764
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 12/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.43271524064171s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 28
StateHashKey: 10485793
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 12/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.43462516733601s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 14680104
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 12/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.43654289544236s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 26
StateHashKey: 10485818
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 12/30
Current state: 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.43846577181208s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 2097198
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 12/30
Current state: 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.44039247311828s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 24
StateHashKey: 10485771
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 12/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.44232436069987s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 2097186
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 12/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.44426145552561s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 6291464
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 12/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.44620377867746s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 6291474
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 12/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.44815135135135s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 10485780
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 12/30
Current state: 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.45010554803789s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 10485797
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 12/30
Current state: 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.45206368563686s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 10485801
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 12/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.45402713704206s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 17
StateHashKey: 2097194
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 12/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.45599592391304s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 2097162
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 12/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.45797006802721s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 2097154
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.45994959128065s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.46193451568895s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 13
StateHashKey: 10485760
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 12/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.4639262295082s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 6291488
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 12/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.4659220246238s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 2097176
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 12/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.46792328767123s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 10
StateHashKey: 10485766
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 12/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.46993141289438s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 6291489
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 12/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.47194368131868s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 6291480
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 12/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.47396148555708s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 6291478
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 12/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.47598622589532s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 2097173
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 12/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.47801517241379s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 2097157
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 12/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.48004972375691s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.48209128630705s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 3
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.48413711911357s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 12/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.48618862690707s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.64012 (in 1959 runs)
  Maximal search depth: 40
  Cache hits: 23381

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 6000
Accumulated number of search nodes in root state: 30239

Used RAM: 336608

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 12 -- REWARD RECEIVED: -5
***********************************************

***********************************************
>>> STARTING ROUND 13 -- REMAINING TIME 1074s
***********************************************
***********************************************
Planning step 1/40 in round 13/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 1.48824583333333s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0474329s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2517
Cache Hits: 0
Skipped backups: 127110
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6398 (in 1960 runs)
  Maximal search depth: 40
  Cache hits: 23786

Root Node: 
-12.8121 (in 503 real visits)

Q-Value Estimates: 
noop() : -15.9169 (in 114 real visits)
move-west : -12.8121 (in 377 real visits)
move-north : -23.375 (in 12 real visits)

Used RAM: 336608

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 13/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.49019054242003s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0375319s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2254
Cache Hits: 0
Skipped backups: 128517
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6398 (in 1960 runs)
  Maximal search depth: 40
  Cache hits: 24118

Root Node: 
-6.86457 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.2974 (in 36 real visits)
move-west : -16.6971 (in 23 real visits)
move-north : -6.86457 (in 417 real visits)
move-east : -16.1099 (in 28 real visits)

Used RAM: 336624

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 13/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.49220891364903s.
DP-UCT: Maximal search depth set to 38

Search time: 0.019896s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1918
Cache Hits: 0
Skipped backups: 130185
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6398 (in 1960 runs)
  Maximal search depth: 40
  Cache hits: 24378

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -14.3675 (in 10 real visits)
move-west : -15.59 (in 10 real visits)
move-south : -15.653 (in 10 real visits)
move-north : -3 (in 465 real visits)
move-east : -18.89 (in 10 real visits)

Used RAM: 336624

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.49425662482566s.
DP-UCT: Maximal search depth set to 37

Search time: 0.016537s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1838
Cache Hits: 0
Skipped backups: 131796
Initialization: 
  Statistics of IDS:
  Average search depth: 4.63845 (in 1961 runs)
  Maximal search depth: 40
  Cache hits: 24625

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -10.75 (in 10 real visits)
move-west : -12.855 (in 10 real visits)
move-south : -15.0367 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -9.35 (in 10 real visits)

Used RAM: 336624

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 1 1 

Setting time for this decision to 1.49631424581006s.
DP-UCT: Maximal search depth set to 36

Search time: 0.017823s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1813
Cache Hits: 0
Skipped backups: 133488
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 43 real visits)
move-west : -3 (in 451 real visits)
move-south : SOLVED with: -36 (in 5 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 336624

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 13/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.49837622377622s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 35
StateHashKey: 10485808
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 13/30
Current state: 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.50046918767507s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 34
StateHashKey: 2097196
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 13/30
Current state: 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.50256802244039s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 33
StateHashKey: 10485771
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 13/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.50467275280899s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 32
StateHashKey: 6291490
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 13/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.50678340365682s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 31
StateHashKey: 14680088
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 13/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.5089s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 6291510
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 13/30
Current state: 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.51102256699577s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 29
StateHashKey: 2097181
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 13/30
Current state: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.5131511299435s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 2097159
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 13/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.51528571428571s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 27
StateHashKey: 6291457
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 13/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.51742634560907s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 6291472
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 13/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.51957304964539s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 2097172
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 13/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.52172585227273s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 2097157
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 13/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.52388335704125s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 6291457
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 13/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.52604700854701s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 6291472
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 13/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.52821683309558s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 2097172
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 13/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.53039428571429s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 10485765
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 13/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.5325765379113s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 2097185
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 13/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.53476504297994s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 6291464
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 13/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.5369612625538s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 10485778
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 13/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.53916235632184s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 16
StateHashKey: 14680100
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 13/30
Current state: 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.54137122302158s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 6291513
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 13/30
Current state: 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.54358501440922s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 6291486
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 13/30
Current state: 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.54580519480519s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 6291479
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 13/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.54803179190751s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 10485781
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 13/30
Current state: 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.55026628075253s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 2097189
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 13/30
Current state: 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.55250724637681s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 2097161
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 13/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.55475326560232s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 2097154
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.55700581395349s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 13/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.55926637554585s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 6291472
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 13/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.56153206997085s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 2097172
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 13/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.56380437956204s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 2097157
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 13/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.56608479532164s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 13/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.56837042459736s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 14680064
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 13/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.5706642228739s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 6291504
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 13/30
Current state: 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.57296328928047s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60541 (in 1997 runs)
  Maximal search depth: 40
  Cache hits: 24829

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 6500
Accumulated number of search nodes in root state: 32756

Used RAM: 336664

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 13 -- REWARD RECEIVED: -5
***********************************************

***********************************************
>>> STARTING ROUND 14 -- REMAINING TIME 1074s
***********************************************
***********************************************
Planning step 1/40 in round 14/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 1.57526911764706s.
DP-UCT: Maximal search depth set to 40

Search time: 0.048322s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2485
Cache Hits: 0
Skipped backups: 134991
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60611 (in 1998 runs)
  Maximal search depth: 40
  Cache hits: 25231

Root Node: 
-13.2565 (in 503 real visits)

Q-Value Estimates: 
noop() : -15.9886 (in 143 real visits)
move-west : -13.2565 (in 343 real visits)
move-north : -22.8318 (in 17 real visits)

Used RAM: 336664

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 14/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.57745655375552s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0346711s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2193
Cache Hits: 0
Skipped backups: 136530
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60611 (in 1998 runs)
  Maximal search depth: 40
  Cache hits: 25551

Root Node: 
-7.51112 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.875 (in 25 real visits)
move-west : -15.9222 (in 24 real visits)
move-north : -7.51112 (in 424 real visits)
move-east : -15.2018 (in 31 real visits)

Used RAM: 336680

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 14/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.57972713864307s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0562019s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2587
Cache Hits: 0
Skipped backups: 138240
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61385 (in 2007 runs)
  Maximal search depth: 40
  Cache hits: 25954

Root Node: 
-12.9015 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -38 (in 5 real visits)
move-west : -14.863 (in 170 real visits)
move-south : -12.9015 (in 308 real visits)
move-north : SOLVED with: -38 (in 5 real visits)
move-east : -21.0093 (in 17 real visits)

Used RAM: 336680

Submitted action: move-south 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 14/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.58197045790251s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0555439s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2603
Cache Hits: 0
Skipped backups: 139773
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61573 (in 2009 runs)
  Maximal search depth: 40
  Cache hits: 26383

Root Node: 
-13.1151 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.1151 (in 296 real visits)
move-west : -15.6779 (in 82 real visits)
move-north : SOLVED with: -37 (in 5 real visits)
move-east : -15.0231 (in 121 real visits)

Used RAM: 336696

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 14/30
Current state: 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.58422337278107s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0357208s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2267
Cache Hits: 0
Skipped backups: 141351
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61848 (in 2013 runs)
  Maximal search depth: 40
  Cache hits: 26715

Root Node: 
-7.08955 (in 504 real visits)

Q-Value Estimates: 
noop() : -14.6397 (in 25 real visits)
move-west : -15.4847 (in 19 real visits)
move-north : -7.08955 (in 424 real visits)
move-east : -13.6684 (in 36 real visits)

Used RAM: 336700

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 14/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.58651111111111s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0189688s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1865
Cache Hits: 0
Skipped backups: 142995
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61954 (in 2016 runs)
  Maximal search depth: 40
  Cache hits: 26958

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -35 (in 5 real visits)
move-west : -14.375 (in 10 real visits)
move-south : -14.375 (in 10 real visits)
move-north : -3 (in 470 real visits)
move-east : -19.8887 (in 10 real visits)

Used RAM: 336700

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 14/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.58883086053412s.
DP-UCT: Maximal search depth set to 34

Search time: 0.0183749s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1936
Cache Hits: 0
Skipped backups: 144813
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61744 (in 2018 runs)
  Maximal search depth: 40
  Cache hits: 27221

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -34 (in 5 real visits)
move-west : -12.2642 (in 10 real visits)
move-south : -11.94 (in 10 real visits)
move-north : -2 (in 470 real visits)
move-east : -13.1225 (in 10 real visits)

Used RAM: 336700

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 14/30
Current state: 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 1 0 

Setting time for this decision to 1.59115750371471s.
DP-UCT: Maximal search depth set to 33

Search time: 0.016479s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1813
Cache Hits: 0
Skipped backups: 146526
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 479 real visits)
move-west : -8.93025 (in 10 real visits)
move-south : -8.1275 (in 10 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 336700

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 9/40 in round 14/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.59349553571429s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 32
StateHashKey: 2097177
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 14/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.59586438152012s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 31
StateHashKey: 2097158
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 14/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.59824179104478s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 6291457
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 14/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.60062331838565s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 29
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 14/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.60301347305389s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 6291460
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 14/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.60540929535232s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 27
StateHashKey: 6291473
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 14/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.60781231231231s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 2097172
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 14/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.61022255639098s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 25
StateHashKey: 10485765
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 14/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.61264156626506s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 6291489
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 14/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.61506636500754s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 6291480
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 14/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.61749848942598s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 22
StateHashKey: 10485782
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 14/30
Current state: 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.61993948562784s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 21
StateHashKey: 10485797
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 14/30
Current state: 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.62238636363636s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 20
StateHashKey: 2097193
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 14/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.6248406676783s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 2097162
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 14/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.6273009118541s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 2097154
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 14/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.6297701674277s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 17
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 14/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.63224695121951s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 14/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.63473282442748s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 15
StateHashKey: 10485764
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 14/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.6372247706422s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 10485793
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 14/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.6397258805513s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 13
StateHashKey: 14680104
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 14/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.64223312883436s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 2097210
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 14/30
Current state: 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.64474807987711s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 10485774
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 14/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.64727076923077s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 6291491
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 14/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.64980277349769s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 2097176
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 14/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.65234104938272s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 2097158
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 14/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.65488871715611s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 14/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.6574427244582s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 14/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.66000465116279s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 14/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.66257453416149s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 4
StateHashKey: 10485764
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 14/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.66515241057543s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 3
StateHashKey: 2097185
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 14/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.66773987538941s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 14680072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 14/30
Current state: 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.67033385335413s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61584 (in 2020 runs)
  Maximal search depth: 40
  Cache hits: 27459

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 7000
Accumulated number of search nodes in root state: 35241

Used RAM: 336700

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 14 -- REWARD RECEIVED: -8
***********************************************

***********************************************
>>> STARTING ROUND 15 -- REMAINING TIME 1073s
***********************************************
***********************************************
Planning step 1/40 in round 15/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 1.6729359375s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0487008s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2565
Cache Hits: 0
Skipped backups: 148122
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61672 (in 2022 runs)
  Maximal search depth: 40
  Cache hits: 27875

Root Node: 
-13.1854 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.3174 (in 129 real visits)
move-west : -13.1854 (in 343 real visits)
move-north : -22.3215 (in 31 real visits)

Used RAM: 336700

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 15/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.67541001564945s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0330989s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2196
Cache Hits: 0
Skipped backups: 149622
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61808 (in 2024 runs)
  Maximal search depth: 40
  Cache hits: 28190

Root Node: 
-7.69303 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.875 (in 20 real visits)
move-west : -16.653 (in 16 real visits)
move-north : -7.69303 (in 445 real visits)
move-east : -15.3349 (in 23 real visits)

Used RAM: 336716

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 15/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.67797962382445s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0188279s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1891
Cache Hits: 0
Skipped backups: 151215
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61698 (in 2026 runs)
  Maximal search depth: 40
  Cache hits: 28439

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -14.6787 (in 10 real visits)
move-west : -15.59 (in 10 real visits)
move-south : -15.527 (in 10 real visits)
move-north : -3 (in 465 real visits)
move-east : -20.57 (in 10 real visits)

Used RAM: 336716

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 15/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.6805808477237s.
DP-UCT: Maximal search depth set to 37

Search time: 0.016356s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1817
Cache Hits: 0
Skipped backups: 152913
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61667 (in 2027 runs)
  Maximal search depth: 40
  Cache hits: 28679

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -6 (in 10 real visits)
move-west : -13.6667 (in 10 real visits)
move-south : SOLVED with: -37 (in 5 real visits)
move-north : -2 (in 470 real visits)
move-east : -11.75 (in 10 real visits)

Used RAM: 336716

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 15/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 0 

Setting time for this decision to 1.68319182389937s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0154781s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1855
Cache Hits: 0
Skipped backups: 154683
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 479 real visits)
move-west : -5.6775 (in 10 real visits)
move-south : -10.955 (in 10 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 336716

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 15/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.6858125984252s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 35
StateHashKey: 2097156
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 15/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.68846687697161s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 34
StateHashKey: 6291457
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 15/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.69112796208531s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 33
StateHashKey: 14680080
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 15/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.69379746835443s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 32
StateHashKey: 14680116
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 15/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.69647543581616s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 31
StateHashKey: 2097213
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 15/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.69916031746032s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 2097167
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 15/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.70185214626391s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 14680067
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 15/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.70455573248408s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 28
StateHashKey: 14680112
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 15/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.7072663476874s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 27
StateHashKey: 2097212
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 15/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.70998562300319s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 2097167
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 15/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.7127152s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 2097155
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 15/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.71545192307692s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 15/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.7181974317817s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 23
StateHashKey: 14680064
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 15/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.72095337620579s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 22
StateHashKey: 10485808
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 15/30
Current state: 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.72371658615137s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 6291500
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 15/30
Current state: 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.72649032258065s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 20
StateHashKey: 2097179
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 15/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.72927140549273s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 14680070
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 15/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.73206310679612s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 10485809
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 15/30
Current state: 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.73486223662885s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 17
StateHashKey: 6291500
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 15/30
Current state: 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.73767045454545s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 16
StateHashKey: 10485787
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 15/30
Current state: 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.74048780487805s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 2097190
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 15/30
Current state: 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.74331596091205s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 14680073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 15/30
Current state: 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.74615171288744s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 6291506
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 15/30
Current state: 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.74899836601307s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 6291484
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 15/30
Current state: 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.751852700491s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 6291479
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 15/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.75471803278689s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 6291477
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 15/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.75759113300493s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 2097173
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 15/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.76047368421053s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 2097157
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 15/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.76336738056013s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 6291457
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 15/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.76626897689769s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 15/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.76918181818182s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 6291460
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 15/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.77210264900662s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 2097169
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 15/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.77503316749585s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 3
StateHashKey: 6291460
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 15/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.77797508305648s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 6291473
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 15/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.78092678868552s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 28927

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 7500
Accumulated number of search nodes in root state: 37806

Used RAM: 336716

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 15 -- REWARD RECEIVED: -5
***********************************************

***********************************************
>>> STARTING ROUND 16 -- REMAINING TIME 1073s
***********************************************
***********************************************
Planning step 1/40 in round 16/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 1.78388666666667s.
DP-UCT: Maximal search depth set to 40

Search time: 0.048331s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2542
Cache Hits: 0
Skipped backups: 156219
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61588 (in 2028 runs)
  Maximal search depth: 40
  Cache hits: 29347

Root Node: 
-13.6653 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.4318 (in 201 real visits)
move-west : -13.6653 (in 279 real visits)
move-north : -21.7468 (in 23 real visits)

Used RAM: 336716

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 16/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.78671285475793s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0584528s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2587
Cache Hits: 0
Skipped backups: 157749
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61459 (in 2029 runs)
  Maximal search depth: 40
  Cache hits: 29772

Root Node: 
-13.8551 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.8551 (in 280 real visits)
move-west : -16.5459 (in 110 real visits)
move-north : SOLVED with: -39 (in 5 real visits)
move-east : -16.3945 (in 109 real visits)

Used RAM: 336732

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 16/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.78959698996656s.
DP-UCT: Maximal search depth set to 38

Search time: 0.055393s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2629
Cache Hits: 0
Skipped backups: 159417
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61947 (in 2034 runs)
  Maximal search depth: 40
  Cache hits: 30211

Root Node: 
-15.3123 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.3123 (in 202 real visits)
move-west : -15.9689 (in 119 real visits)
move-north : SOLVED with: -38 (in 5 real visits)
move-east : -15.3283 (in 178 real visits)

Used RAM: 336736

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 16/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.79249581239531s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0555792s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2600
Cache Hits: 0
Skipped backups: 161037
Initialization: 
  Statistics of IDS:
  Average search depth: 4.625 (in 2040 runs)
  Maximal search depth: 40
  Cache hits: 30641

Root Node: 
-13.8262 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.8262 (in 238 real visits)
move-west : -15.6507 (in 106 real visits)
move-north : SOLVED with: -37 (in 5 real visits)
move-east : -15.0484 (in 155 real visits)

Used RAM: 336744

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 16/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.79540268456376s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0349939s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2283
Cache Hits: 0
Skipped backups: 162675
Initialization: 
  Statistics of IDS:
  Average search depth: 4.625 (in 2040 runs)
  Maximal search depth: 40
  Cache hits: 30974

Root Node: 
-7.22726 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.8479 (in 27 real visits)
move-west : -15.5584 (in 16 real visits)
move-north : -7.22726 (in 436 real visits)
move-east : -14.5327 (in 25 real visits)

Used RAM: 336752

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 16/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.79835462184874s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0191441s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1862
Cache Hits: 0
Skipped backups: 164340
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31222

Root Node: 
-3.05872 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -35 (in 5 real visits)
move-west : -14.4222 (in 10 real visits)
move-south : -14.375 (in 10 real visits)
move-north : -3.05872 (in 470 real visits)
move-east : -18.2525 (in 10 real visits)

Used RAM: 336752

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 16/30
Current state: 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.80134343434343s.
DP-UCT: Maximal search depth set to 34

Search time: 0.016289s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1808
Cache Hits: 0
Skipped backups: 165879
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31457

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -10 (in 10 real visits)
move-west : -11.7912 (in 10 real visits)
move-south : -12.8792 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -10.895 (in 10 real visits)

Used RAM: 336752

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 16/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 0 

Setting time for this decision to 1.80434569983137s.
DP-UCT: Maximal search depth set to 33

Search time: 0.017108s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1882
Cache Hits: 0
Skipped backups: 167754
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 479 real visits)
move-west : -7.60725 (in 10 real visits)
move-south : -8.00975 (in 10 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 336752

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 9/40 in round 16/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.80735810810811s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 32
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 16/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.81041116751269s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 31
StateHashKey: 10485760
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 16/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.81347288135593s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 6291488
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 16/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.81654329371817s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 29
StateHashKey: 6291480
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 16/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.81962414965986s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 28
StateHashKey: 10485782
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 16/30
Current state: 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.82271720613288s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 10485797
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 16/30
Current state: 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.82581911262799s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 2097193
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 16/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.82893162393162s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 2097162
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 16/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.83205650684932s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 2097154
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 16/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.83519210977702s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 16/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.83833676975945s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 16/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.84149225473322s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 21
StateHashKey: 10485760
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 16/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.84465862068966s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 20
StateHashKey: 6291488
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 16/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.84783765112263s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 10485784
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 16/30
Current state: 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.8510276816609s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 6291494
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 16/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.85422703639515s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 10485785
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 16/30
Current state: 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.85743923611111s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 16
StateHashKey: 10485798
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 16/30
Current state: 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.86066086956522s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 6291497
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 16/30
Current state: 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.863893728223s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 2097178
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 16/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.86713961605585s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 2097158
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 16/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.8703951048951s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 16/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.87366199649737s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 16/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.87694210526316s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 16/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.88023374340949s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 16/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.88353521126761s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 2097156
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 16/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 1.88684832451499s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 7
StateHashKey: 14680065
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 16/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.89017314487633s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 10485808
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 16/30
Current state: 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.89351150442478s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 2097196
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 16/30
Current state: 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.89685992907801s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 2097163
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 16/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.90022202486679s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 10485762
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 16/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.90359430604982s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 10485792
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 16/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.90698039215686s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62567 (in 2041 runs)
  Maximal search depth: 40
  Cache hits: 31718

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 8000
Accumulated number of search nodes in root state: 40348

Used RAM: 336752

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 16 -- REWARD RECEIVED: -8
***********************************************

***********************************************
>>> STARTING ROUND 17 -- REMAINING TIME 1072s
***********************************************
***********************************************
Planning step 1/40 in round 17/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 1.91037678571429s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0470562s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2532
Cache Hits: 0
Skipped backups: 169389
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62751 (in 2043 runs)
  Maximal search depth: 40
  Cache hits: 32126

Root Node: 
-12.4958 (in 503 real visits)

Q-Value Estimates: 
noop() : -17.1713 (in 62 real visits)
move-west : -12.4958 (in 428 real visits)
move-north : -22.7597 (in 13 real visits)

Used RAM: 336752

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 17/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 1.91363864042934s.
DP-UCT: Maximal search depth set to 39

Search time: 0.033751s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2206
Cache Hits: 0
Skipped backups: 170868
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62818 (in 2044 runs)
  Maximal search depth: 40
  Cache hits: 32446

Root Node: 
-6.98449 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.4204 (in 26 real visits)
move-west : -16.8 (in 17 real visits)
move-north : -6.98449 (in 437 real visits)
move-east : -16.1883 (in 24 real visits)

Used RAM: 336756

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 17/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.917s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0366788s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2268
Cache Hits: 0
Skipped backups: 172380
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62854 (in 2046 runs)
  Maximal search depth: 40
  Cache hits: 32774

Root Node: 
-7.30667 (in 505 real visits)

Q-Value Estimates: 
noop() : -7.30667 (in 421 real visits)
move-west : -14.3581 (in 41 real visits)
move-south : -15.2142 (in 29 real visits)
move-north : SOLVED with: -38 (in 5 real visits)
move-east : -20.57 (in 9 real visits)

Used RAM: 336756

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 17/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 1.92036983842011s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0331261s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2256
Cache Hits: 0
Skipped backups: 174036
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6297 (in 2047 runs)
  Maximal search depth: 40
  Cache hits: 33099

Root Node: 
-6.94968 (in 505 real visits)

Q-Value Estimates: 
noop() : -6.94968 (in 428 real visits)
move-west : -12.9112 (in 44 real visits)
move-south : -14.9587 (in 19 real visits)
move-north : SOLVED with: -37 (in 5 real visits)
move-east : -16.4392 (in 9 real visits)

Used RAM: 336756

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 17/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 1.9237571942446s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0185959s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1777
Cache Hits: 0
Skipped backups: 175482
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62622 (in 2052 runs)
  Maximal search depth: 40
  Cache hits: 33324

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -36 (in 5 real visits)
move-west : -14.75 (in 10 real visits)
move-south : -14.825 (in 10 real visits)
move-north : -3 (in 470 real visits)
move-east : -21.125 (in 10 real visits)

Used RAM: 336756

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 17/30
Current state: 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 1 

Setting time for this decision to 1.92718378378378s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0184381s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1754
Cache Hits: 0
Skipped backups: 177042
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59894 (in 2077 runs)
  Maximal search depth: 40
  Cache hits: 33528

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -35 (in 5 real visits)
move-west : -12.706 (in 10 real visits)
move-south : SOLVED with: -35 (in 5 real visits)
move-north : -2 (in 475 real visits)
move-east : -8.93 (in 10 real visits)

Used RAM: 336756

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 17/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 0 

Setting time for this decision to 1.93062093862816s.
DP-UCT: Maximal search depth set to 34

Search time: 0.0153699s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1777
Cache Hits: 0
Skipped backups: 178320
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 140 real visits)
move-west : -10.84 (in 8 real visits)
move-south : -3 (in 351 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 336796

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 17/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.93407775768535s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 33
StateHashKey: 2097165
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 17/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.93757427536232s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 32
StateHashKey: 6291459
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 17/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.9410834845735s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 31
StateHashKey: 6291472
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 17/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.94460545454545s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 2097172
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 17/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.94814025500911s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 29
StateHashKey: 2097157
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 17/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.95168795620438s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 17/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.95524680073126s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 27
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 17/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.95882051282051s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 26
StateHashKey: 10485776
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 17/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.96240917431193s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 2097188
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 17/30
Current state: 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 1.96600735294118s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 6291465
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 17/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.96961878453039s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 2097170
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 17/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.97324538745387s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 22
StateHashKey: 10485764
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 17/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.97688354898336s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 21
StateHashKey: 10485793
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 17/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.98053518518519s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 10485800
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 17/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.98420222634508s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 2097194
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 17/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.98788104089219s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 2097162
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 17/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.99157541899441s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 10485762
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 17/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 1.99528358208955s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 16
StateHashKey: 10485792
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 17/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1.99900373831776s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 2097192
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 17/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.00273782771536s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 2097162
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 17/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.00648592870544s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 6291458
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 17/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.01025s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 10485776
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 17/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.01402824858757s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 2097188
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 17/30
Current state: 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.01781886792453s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 6291465
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 17/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.02162381852552s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 2097170
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 17/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.02544507575758s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 8
StateHashKey: 10485764
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 17/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.0292789373814s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 2097185
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 17/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.03312737642586s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 10485768
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 17/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.03699238095238s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 6291490
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 17/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.04087022900763s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 2097176
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 17/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.04476481835564s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 10485766
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 17/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.04867432950192s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 2097185
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 17/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.05259692898273s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 33751

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 8500
Accumulated number of search nodes in root state: 42880

Used RAM: 336804

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 17 -- REWARD RECEIVED: -7
***********************************************

***********************************************
>>> STARTING ROUND 18 -- REMAINING TIME 1072s
***********************************************
***********************************************
Planning step 1/40 in round 18/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 2.05653461538462s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0534708s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2583
Cache Hits: 0
Skipped backups: 179952
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59578 (in 2083 runs)
  Maximal search depth: 40
  Cache hits: 34179

Root Node: 
-15.211 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.3446 (in 161 real visits)
move-west : -15.211 (in 322 real visits)
move-north : -21.6068 (in 20 real visits)

Used RAM: 336804

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 18/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 2.06031213872832s.
DP-UCT: Maximal search depth set to 39

Search time: 0.034574s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2211
Cache Hits: 0
Skipped backups: 181410
Initialization: 
  Statistics of IDS:
  Average search depth: 4.59645 (in 2084 runs)
  Maximal search depth: 40
  Cache hits: 34499

Root Node: 
-7.29542 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.6041 (in 28 real visits)
move-west : -16.7589 (in 20 real visits)
move-north : -7.29542 (in 432 real visits)
move-east : -16.2 (in 24 real visits)

Used RAM: 336820

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 18/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.06421621621622s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0530701s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2475
Cache Hits: 0
Skipped backups: 182955
Initialization: 
  Statistics of IDS:
  Average search depth: 4.5999 (in 2087 runs)
  Maximal search depth: 40
  Cache hits: 34876

Root Node: 
-12.8451 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -38 (in 5 real visits)
move-west : -12.8451 (in 321 real visits)
move-south : -15.1996 (in 159 real visits)
move-north : SOLVED with: -38 (in 5 real visits)
move-east : -21.7425 (in 15 real visits)

Used RAM: 336820

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 18/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 2.06809864603482s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0363081s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2221
Cache Hits: 0
Skipped backups: 184638
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60057 (in 2088 runs)
  Maximal search depth: 40
  Cache hits: 35194

Root Node: 
-7.3885 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -37 (in 5 real visits)
move-west : -15.8775 (in 18 real visits)
move-south : -16 (in 18 real visits)
move-north : SOLVED with: -37 (in 5 real visits)
move-east : -7.3885 (in 459 real visits)

Used RAM: 336824

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 18/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 2.07202713178295s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0536611s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2578
Cache Hits: 0
Skipped backups: 186105
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60239 (in 2090 runs)
  Maximal search depth: 40
  Cache hits: 35600

Root Node: 
-12.8396 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -36 (in 5 real visits)
move-west : -14.8922 (in 146 real visits)
move-south : -12.8396 (in 331 real visits)
move-north : SOLVED with: -36 (in 5 real visits)
move-east : -21.6552 (in 18 real visits)

Used RAM: 336824

Submitted action: move-south 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 18/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 2.07593786407767s.
DP-UCT: Maximal search depth set to 35

Search time: 0.055506s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2611
Cache Hits: 0
Skipped backups: 187689
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60239 (in 2090 runs)
  Maximal search depth: 40
  Cache hits: 36033

Root Node: 
-13.4522 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.4522 (in 290 real visits)
move-west : -14.9184 (in 102 real visits)
move-north : SOLVED with: -35 (in 5 real visits)
move-east : -14.8868 (in 107 real visits)

Used RAM: 336828

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 18/30
Current state: 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 2.07986186770428s.
DP-UCT: Maximal search depth set to 34

Search time: 0.036767s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2260
Cache Hits: 0
Skipped backups: 189198
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2091 runs)
  Maximal search depth: 40
  Cache hits: 36357

Root Node: 
-6.82324 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.7027 (in 29 real visits)
move-west : -14.74 (in 21 real visits)
move-north : -6.82324 (in 430 real visits)
move-east : -14.2401 (in 24 real visits)

Used RAM: 336828

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 18/30
Current state: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 2.08383625730994s.
DP-UCT: Maximal search depth set to 33

Search time: 0.03561s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2289
Cache Hits: 0
Skipped backups: 190761
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60315 (in 2094 runs)
  Maximal search depth: 40
  Cache hits: 36685

Root Node: 
-6.77777 (in 505 real visits)

Q-Value Estimates: 
noop() : -6.77777 (in 426 real visits)
move-west : -12.7125 (in 42 real visits)
move-south : -13.2269 (in 23 real visits)
move-north : SOLVED with: -33 (in 5 real visits)
move-east : -18.3933 (in 9 real visits)

Used RAM: 336828

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 9/40 in round 18/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 2.087830078125s.
DP-UCT: Maximal search depth set to 32

Search time: 0.0194759s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1858
Cache Hits: 0
Skipped backups: 192291
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60315 (in 2094 runs)
  Maximal search depth: 40
  Cache hits: 36933

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -12.1312 (in 10 real visits)
move-west : -13.25 (in 10 real visits)
move-south : -13.25 (in 10 real visits)
move-north : -3 (in 465 real visits)
move-east : -18.875 (in 10 real visits)

Used RAM: 336828

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 10/40 in round 18/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 1 

Setting time for this decision to 2.09186888454012s.
DP-UCT: Maximal search depth set to 31

Search time: 0.0170982s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1774
Cache Hits: 0
Skipped backups: 193806
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37157

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -31 (in 5 real visits)
move-west : -11.6667 (in 10 real visits)
move-south : -12.6292 (in 10 real visits)
move-north : -2 (in 470 real visits)
move-east : -8.09 (in 10 real visits)

Used RAM: 336828

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 11/40 in round 18/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 0 

Setting time for this decision to 2.09592941176471s.
DP-UCT: Maximal search depth set to 30

Search time: 0.0148401s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1734
Cache Hits: 0
Skipped backups: 195039
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 242 real visits)
move-west : -8.24 (in 6 real visits)
move-south : -3 (in 251 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 336828

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 12/40 in round 18/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.10000982318271s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 14680072
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 18/30
Current state: 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.10413582677165s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 2097202
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 18/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.10827810650888s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 27
StateHashKey: 2097164
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 18/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.11243675889328s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 6291459
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 18/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.11661188118812s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 18/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.12080158730159s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 24
StateHashKey: 14680068
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 18/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.12500994035785s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 2097201
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 18/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.12923505976096s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 2097164
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 18/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.13347704590818s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 2097155
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 18/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.137734s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 20
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 18/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.14201002004008s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 18/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.14630120481928s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 18/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.15060965794769s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 10485760
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 18/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.15493548387097s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 2097184
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 18/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.15928080808081s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 6291464
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 18/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.16364170040486s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 10485778
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 18/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.16802231237323s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 13
StateHashKey: 14680100
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 18/30
Current state: 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.17241869918699s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 2097209
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 18/30
Current state: 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.1768350305499s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 6291470
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 18/30
Current state: 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.18126734693878s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 6291475
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 18/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.18571779141104s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 9
StateHashKey: 10485780
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 18/30
Current state: 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.19018852459016s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 2097189
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 18/30
Current state: 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.19467761806982s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 2097161
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 18/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.19918312757202s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 2097154
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 18/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.20370721649485s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 5
StateHashKey: 14680064
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 18/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.20825s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 2097200
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 18/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.21281366459627s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 3
StateHashKey: 2097164
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 18/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.21739419087137s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 2097155
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 18/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.22199376299376s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37378

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 9000
Accumulated number of search nodes in root state: 45463

Used RAM: 336828

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 18 -- REWARD RECEIVED: -11
***********************************************

***********************************************
>>> STARTING ROUND 19 -- REMAINING TIME 1071s
***********************************************
***********************************************
Planning step 1/40 in round 19/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 2.22661458333333s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0492499s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2568
Cache Hits: 0
Skipped backups: 196554
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6021 (in 2096 runs)
  Maximal search depth: 40
  Cache hits: 37799

Root Node: 
-12.8129 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.7551 (in 150 real visits)
move-west : -12.8129 (in 335 real visits)
move-north : -21.667 (in 18 real visits)

Used RAM: 336828

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 19/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 2.23107306889353s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0330889s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2107
Cache Hits: 0
Skipped backups: 197946
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61839 (in 2099 runs)
  Maximal search depth: 40
  Cache hits: 38092

Root Node: 
-7.44039 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.875 (in 17 real visits)
move-west : -16.8 (in 14 real visits)
move-north : -7.44039 (in 460 real visits)
move-east : -17.1125 (in 13 real visits)

Used RAM: 336836

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 19/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 2.23566317991632s.
DP-UCT: Maximal search depth set to 38

Search time: 0.01948s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1846
Cache Hits: 0
Skipped backups: 199563
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61875 (in 2101 runs)
  Maximal search depth: 40
  Cache hits: 38333

Root Node: 
-3.0648 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -38 (in 5 real visits)
move-west : -15.653 (in 10 real visits)
move-south : -15.59 (in 10 real visits)
move-north : -3.0648 (in 470 real visits)
move-east : -19.9575 (in 10 real visits)

Used RAM: 336836

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 19/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 0 

Setting time for this decision to 2.24029979035639s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0157931s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1784
Cache Hits: 0
Skipped backups: 201039
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38564

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -7.425 (in 10 real visits)
move-west : -13.8417 (in 10 real visits)
move-south : SOLVED with: -37 (in 5 real visits)
move-north : -2 (in 470 real visits)
move-east : -12.5 (in 10 real visits)

Used RAM: 336836

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 19/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 0 

Setting time for this decision to 2.24496428571429s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0151789s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1792
Cache Hits: 0
Skipped backups: 202707
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 479 real visits)
move-west : -11.15 (in 10 real visits)
move-south : -10.4417 (in 10 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 336836

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 19/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.24965052631579s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 35
StateHashKey: 2097157
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 19/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.25438818565401s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 34
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 19/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.25914587737844s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 33
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 19/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.26392584745763s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 32
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 19/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.26872611464968s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 31
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 19/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.27354680851064s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 2097156
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 19/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.27838379530917s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 29
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 19/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.28324145299145s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 19/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.28812205567452s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 14680064
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 19/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.29302145922747s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 2097200
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 19/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.29794408602151s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 2097164
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 19/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.30288577586207s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 24
StateHashKey: 10485763
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 19/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.30784881209503s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 23
StateHashKey: 10485792
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 19/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.3128354978355s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 6291496
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 19/30
Current state: 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.31784381778742s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 2097178
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 19/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.32287173913043s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 20
StateHashKey: 2097158
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 19/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.32792374727669s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 6291457
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 19/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.33299563318777s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 6291472
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 19/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.33808971553611s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 17
StateHashKey: 2097172
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 19/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.34320833333333s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 16
StateHashKey: 10485765
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 19/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.34834725274725s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 6291489
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 19/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.35351321585903s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 2097176
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 19/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.35869977924945s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 2097158
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 19/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.36391150442478s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 6291457
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 19/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.36914412416851s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 10485776
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 19/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.37439777777778s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 2097188
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 19/30
Current state: 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.37967260579065s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 6291465
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 19/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.38497544642857s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 6291474
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 19/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.39030201342282s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 7
StateHashKey: 14680084
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 19/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.39565022421525s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 10485813
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 19/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.40102247191011s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 2097197
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 19/30
Current state: 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.40642117117117s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 6291467
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 19/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.41184198645598s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 10485778
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 19/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.41728733031674s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 2097188
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 19/30
Current state: 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.42275963718821s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 38801

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 9500
Accumulated number of search nodes in root state: 48031

Used RAM: 336836

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 19 -- REWARD RECEIVED: -5
***********************************************

***********************************************
>>> STARTING ROUND 20 -- REMAINING TIME 1071s
***********************************************
***********************************************
Planning step 1/40 in round 20/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 2.42825454545455s.
DP-UCT: Maximal search depth set to 40

Search time: 0.046813s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2487
Cache Hits: 0
Skipped backups: 204270
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 39205

Root Node: 
-13.1866 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.5185 (in 111 real visits)
move-west : -13.1866 (in 381 real visits)
move-north : -24.7855 (in 11 real visits)

Used RAM: 336836

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 20/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 2.43357858769932s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0379479s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2313
Cache Hits: 0
Skipped backups: 205782
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 39545

Root Node: 
-7.49498 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.875 (in 25 real visits)
move-west : -15.8781 (in 24 real visits)
move-north : -7.49498 (in 423 real visits)
move-east : -15.0876 (in 32 real visits)

Used RAM: 336844

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 20/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 2.43903881278539s.
DP-UCT: Maximal search depth set to 38

Search time: 0.019263s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1866
Cache Hits: 0
Skipped backups: 207330
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61846 (in 2102 runs)
  Maximal search depth: 40
  Cache hits: 39790

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -14 (in 10 real visits)
move-west : -15.527 (in 10 real visits)
move-south : -15.59 (in 10 real visits)
move-north : -3 (in 465 real visits)
move-east : -25.05 (in 10 real visits)

Used RAM: 336844

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 20/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 0 

Setting time for this decision to 2.44456750572082s.
DP-UCT: Maximal search depth set to 37

Search time: 0.015456s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1780
Cache Hits: 0
Skipped backups: 208827
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61721 (in 2103 runs)
  Maximal search depth: 40
  Cache hits: 40019

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -7.6275 (in 10 real visits)
move-west : -13.2867 (in 10 real visits)
move-south : SOLVED with: -37 (in 5 real visits)
move-north : -2 (in 470 real visits)
move-east : -9.35 (in 10 real visits)

Used RAM: 336844

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 20/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 1 0 

Setting time for this decision to 2.45012844036697s.
DP-UCT: Maximal search depth set to 36

Search time: 0.016891s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1798
Cache Hits: 0
Skipped backups: 210348
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 89 real visits)
move-west : -3 (in 401 real visits)
move-south : -11.41 (in 9 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 336844

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 20/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.45571264367816s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 35
StateHashKey: 6291476
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 20/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.46136405529954s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 34
StateHashKey: 2097173
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 20/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.46703926096998s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 33
StateHashKey: 6291461
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 20/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.47274074074074s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 32
StateHashKey: 2097169
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 20/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.4784686774942s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 31
StateHashKey: 6291460
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 20/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.48422325581395s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 2097169
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 20/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.49000233100233s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 29
StateHashKey: 2097156
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 20/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.49581074766355s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 28
StateHashKey: 10485761
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 20/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.50164402810304s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 10485792
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 20/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.50750704225352s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 26
StateHashKey: 10485800
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 20/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.51339529411765s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 2097194
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 20/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.51931132075472s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 2097162
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 20/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.52525768321513s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 2097154
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 20/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.53123222748815s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 22
StateHashKey: 10485760
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 20/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.53723277909739s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 2097184
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 20/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.54326428571429s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 20
StateHashKey: 2097160
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 20/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.54932219570406s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 2097154
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 20/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.55540909090909s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 14680064
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 20/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.56152757793765s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 10485808
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 20/30
Current state: 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.56767307692308s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 16
StateHashKey: 14680108
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 20/30
Current state: 1 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.57385060240964s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 2097211
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 20/30
Current state: 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.58005555555556s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 2097166
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 20/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.58629297820823s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 6291459
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 20/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.59255825242718s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 6291472
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 20/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.59885644768856s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 14680084
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 20/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.60518292682927s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 2097205
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 20/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.61154034229829s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 9
StateHashKey: 10485773
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 20/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.61793137254902s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 8
StateHashKey: 10485795
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 20/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.62435380835381s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 7
StateHashKey: 10485800
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 20/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.63080541871921s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 6291498
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 20/30
Current state: 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.63729135802469s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 6291482
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 20/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.64380445544554s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 2097174
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 20/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.6503523573201s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 3
StateHashKey: 2097157
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 20/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.6569328358209s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 20/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.66354862842893s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40250

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 10000
Accumulated number of search nodes in root state: 50518

Used RAM: 336848

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 20 -- REWARD RECEIVED: -5
***********************************************

***********************************************
>>> STARTING ROUND 21 -- REMAINING TIME 1071s
***********************************************
***********************************************
Planning step 1/40 in round 21/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 2.670195s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0473349s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2492
Cache Hits: 0
Skipped backups: 211947
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61458 (in 2112 runs)
  Maximal search depth: 40
  Cache hits: 40649

Root Node: 
-12.8156 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.226 (in 94 real visits)
move-west : -12.8156 (in 392 real visits)
move-north : -21.4297 (in 17 real visits)

Used RAM: 336848

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 21/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 2.67666165413534s.
DP-UCT: Maximal search depth set to 39

Search time: 0.036232s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2194
Cache Hits: 0
Skipped backups: 213399
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61524 (in 2113 runs)
  Maximal search depth: 40
  Cache hits: 40968

Root Node: 
-7.42206 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.9042 (in 21 real visits)
move-west : -16.656 (in 17 real visits)
move-north : -7.42206 (in 440 real visits)
move-east : -15.7745 (in 26 real visits)

Used RAM: 336864

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 21/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 2.6832864321608s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0188131s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1828
Cache Hits: 0
Skipped backups: 214953
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61524 (in 2113 runs)
  Maximal search depth: 40
  Cache hits: 41208

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -15.2337 (in 10 real visits)
move-west : -15.5 (in 10 real visits)
move-south : -14.9167 (in 10 real visits)
move-north : -3 (in 465 real visits)
move-east : -18.057 (in 10 real visits)

Used RAM: 336864

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 21/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 0 

Setting time for this decision to 2.68998740554156s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0170679s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1833
Cache Hits: 0
Skipped backups: 216666
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61524 (in 2113 runs)
  Maximal search depth: 40
  Cache hits: 41450

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -7.6275 (in 10 real visits)
move-west : -12.605 (in 10 real visits)
move-south : SOLVED with: -37 (in 5 real visits)
move-north : -2 (in 470 real visits)
move-east : -9.35 (in 10 real visits)

Used RAM: 336864

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 21/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 0 

Setting time for this decision to 2.69672727272727s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0171421s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1826
Cache Hits: 0
Skipped backups: 218328
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -3.6275 (in 12 real visits)
move-west : -3 (in 477 real visits)
move-south : -7.9275 (in 10 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 336864

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 21/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.70350126582278s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 35
StateHashKey: 2097156
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 21/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.71035279187817s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 34
StateHashKey: 10485761
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 21/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.71723918575064s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 33
StateHashKey: 6291488
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 21/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.72416071428571s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 32
StateHashKey: 6291480
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 21/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.73111764705882s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 31
StateHashKey: 6291478
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 21/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.73811025641026s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 2097173
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 21/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.74513881748072s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 29
StateHashKey: 6291461
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 21/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.75220360824742s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 2097169
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 21/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.75930490956072s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 10485764
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 21/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.76644041450777s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 6291489
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 21/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.77361558441558s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 25
StateHashKey: 10485784
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 21/30
Current state: 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.780828125s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 6291494
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 21/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.78807832898172s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 23
StateHashKey: 10485785
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 21/30
Current state: 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.7953664921466s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 6291494
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 21/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.80269028871391s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 2097177
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 21/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.81005526315789s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 20
StateHashKey: 6291462
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 21/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.81745646437995s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 10485777
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 21/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.82489682539683s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 2097188
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 21/30
Current state: 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.83237931034483s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 17
StateHashKey: 2097161
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 21/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.83989893617021s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 2097154
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 21/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.84745866666667s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 21/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.8550614973262s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 21/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.86270509383378s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 2097156
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 21/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.87038978494624s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 10485761
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 21/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.87811320754717s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 10485792
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 21/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.88587837837838s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 2097192
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 21/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.89368834688347s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 2097162
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 21/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.90153804347826s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 6291458
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 21/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 2.90943324250681s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 7
StateHashKey: 14680080
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 21/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.91736885245902s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 10485812
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 21/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 2.92535068493151s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 5
StateHashKey: 10485805
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 21/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.93337637362637s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 2097195
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 21/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.9414435261708s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 3
StateHashKey: 2097162
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 21/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 2.94955524861878s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 6291458
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 21/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 2.95771468144044s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6136 (in 2117 runs)
  Maximal search depth: 40
  Cache hits: 41690

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 10500
Accumulated number of search nodes in root state: 53010

Used RAM: 336864

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 21 -- REWARD RECEIVED: -5
***********************************************

***********************************************
>>> STARTING ROUND 22 -- REMAINING TIME 1070s
***********************************************
***********************************************
Planning step 1/40 in round 22/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 2.96591666666667s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0511391s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2563
Cache Hits: 0
Skipped backups: 219933
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61473 (in 2118 runs)
  Maximal search depth: 40
  Cache hits: 42105

Root Node: 
-13.2924 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.3288 (in 119 real visits)
move-west : -13.2924 (in 369 real visits)
move-north : -23.0606 (in 15 real visits)

Used RAM: 336864

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 22/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 2.97391643454039s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0344989s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2239
Cache Hits: 0
Skipped backups: 221514
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61444 (in 2119 runs)
  Maximal search depth: 40
  Cache hits: 42430

Root Node: 
-7.44441 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.5749 (in 23 real visits)
move-west : -16.663 (in 17 real visits)
move-north : -7.44441 (in 441 real visits)
move-east : -15.5166 (in 23 real visits)

Used RAM: 336872

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 22/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 2.98211452513966s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0189111s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1885
Cache Hits: 0
Skipped backups: 223143
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61444 (in 2119 runs)
  Maximal search depth: 40
  Cache hits: 42681

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -13.664 (in 10 real visits)
move-west : -15.59 (in 10 real visits)
move-south : -15.527 (in 10 real visits)
move-north : -3 (in 465 real visits)
move-east : -21.305 (in 10 real visits)

Used RAM: 336872

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 22/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 0 

Setting time for this decision to 2.99040336134454s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0169642s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1801
Cache Hits: 0
Skipped backups: 224700
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61444 (in 2119 runs)
  Maximal search depth: 40
  Cache hits: 42917

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -10.2857 (in 10 real visits)
move-west : -12.855 (in 10 real visits)
move-south : -13.8417 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -11.75 (in 10 real visits)

Used RAM: 336872

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 22/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 0 

Setting time for this decision to 2.99874438202247s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0169361s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1806
Cache Hits: 0
Skipped backups: 226107
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 89 real visits)
move-west : -3 (in 401 real visits)
move-south : -11.15 (in 9 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 336872

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.00713521126761s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 35
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.0156186440678s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 34
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 3.02415297450425s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 33
StateHashKey: 10485760
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 22/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.03273295454545s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 32
StateHashKey: 14680096
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 22/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 3.04135897435897s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 31
StateHashKey: 10485816
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 22/30
Current state: 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.05003428571429s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 6291502
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 22/30
Current state: 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 3.05876217765043s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 10485787
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 22/30
Current state: 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.06753735632184s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 2097190
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 22/30
Current state: 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 3.07636599423631s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 10485769
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 22/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.08524566473988s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 6291490
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 22/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.09417391304348s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 2097176
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 22/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.10315697674419s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 2097158
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 22/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.11218950437318s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.12127777777778s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.13041642228739s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 22/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.13960882352941s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 14680080
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 22/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.14885840707965s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 2097204
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 22/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.15815976331361s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 2097165
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 22/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.16751928783383s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 17
StateHashKey: 6291459
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 22/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 3.17693452380952s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 16
StateHashKey: 10485776
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 22/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 3.18640298507463s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 15
StateHashKey: 10485796
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 22/30
Current state: 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.19592814371258s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 2097193
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 22/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.20551651651652s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 2097162
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 22/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.21516265060241s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 2097154
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 3.22486404833837s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 10485760
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 22/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.23462424242424s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 2097184
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 22/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.24444376899696s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 2097160
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 22/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.25432317073171s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 2097154
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.26425993883792s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 22/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 3.27426073619632s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 10485760
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 22/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 3.28432s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 5
StateHashKey: 10485792
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 22/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.29444444444444s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 2097192
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 22/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.30462848297214s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 3
StateHashKey: 6291466
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 22/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 3.31487888198758s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 10485778
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 22/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.32519314641745s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43151

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 11000
Accumulated number of search nodes in root state: 55573

Used RAM: 336872

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 22 -- REWARD RECEIVED: -5
***********************************************

***********************************************
>>> STARTING ROUND 23 -- REMAINING TIME 1070s
***********************************************
***********************************************
Planning step 1/40 in round 23/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 3.335571875s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0506392s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2565
Cache Hits: 0
Skipped backups: 227754
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43571

Root Node: 
-13.2865 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.5686 (in 146 real visits)
move-west : -13.2865 (in 337 real visits)
move-north : -22.0858 (in 20 real visits)

Used RAM: 336872

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 23/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 3.34573040752351s.
DP-UCT: Maximal search depth set to 39

Search time: 0.031142s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2189
Cache Hits: 0
Skipped backups: 229332
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61386 (in 2121 runs)
  Maximal search depth: 40
  Cache hits: 43889

Root Node: 
-7.52297 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.875 (in 20 real visits)
move-west : -16.807 (in 16 real visits)
move-north : -7.52297 (in 445 real visits)
move-east : -16.8124 (in 23 real visits)

Used RAM: 336880

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 23/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 3.35614465408805s.
DP-UCT: Maximal search depth set to 38

Search time: 0.018955s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1916
Cache Hits: 0
Skipped backups: 230946
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61357 (in 2122 runs)
  Maximal search depth: 40
  Cache hits: 44144

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -38 (in 5 real visits)
move-west : -15.563 (in 10 real visits)
move-south : -15.653 (in 10 real visits)
move-north : -3 (in 470 real visits)
move-east : -21.515 (in 10 real visits)

Used RAM: 336880

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 23/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 0 

Setting time for this decision to 3.36666246056782s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0156789s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1841
Cache Hits: 0
Skipped backups: 232566
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61281 (in 2123 runs)
  Maximal search depth: 40
  Cache hits: 44387

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -9.36172 (in 10 real visits)
move-west : -12.605 (in 10 real visits)
move-south : -12.68 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -12.5 (in 10 real visits)

Used RAM: 336880

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 23/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 0 

Setting time for this decision to 3.37725949367089s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0168352s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1881
Cache Hits: 0
Skipped backups: 234165
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 89 real visits)
move-west : -3 (in 401 real visits)
move-south : -11.15 (in 9 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 336880

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 23/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.38791746031746s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 35
StateHashKey: 6291457
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 23/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.39870063694268s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 34
StateHashKey: 14680080
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 23/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.40954632587859s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 33
StateHashKey: 2097204
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 23/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.42046474358974s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 32
StateHashKey: 2097165
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 23/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.4314501607717s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 31
StateHashKey: 2097155
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 23/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.44250322580645s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 30
StateHashKey: 14680064
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 23/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.45363106796117s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 29
StateHashKey: 2097200
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 23/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.46483116883117s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 2097164
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 23/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.47610423452769s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 27
StateHashKey: 2097155
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 23/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 3.4874477124183s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 26
StateHashKey: 10485760
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 23/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.49886885245902s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 2097184
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 23/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.51036513157895s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 2097160
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 23/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 3.52193399339934s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 23
StateHashKey: 10485762
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 23/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.53358278145695s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 22
StateHashKey: 14680096
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 23/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.54530564784053s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 2097208
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 23/30
Current state: 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 3.55710666666667s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 10485774
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 23/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.56898996655518s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 14680099
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 23/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.58094966442953s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 2097208
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 23/30
Current state: 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.59299326599327s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 17
StateHashKey: 2097166
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 23/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.60511824324324s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 2097155
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 23/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.6173220338983s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 23/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.62961224489796s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 14680080
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 23/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.64198634812287s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 13
StateHashKey: 14680116
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 23/30
Current state: 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.65444178082192s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 2097213
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 23/30
Current state: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.66698281786942s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 6291471
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 23/30
Current state: 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.67961379310345s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 2097171
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 23/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.69232871972318s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 2097156
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 23/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.70513194444444s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 23/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 3.71802787456446s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 7
StateHashKey: 14680064
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 23/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.73101398601399s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 2097200
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 23/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.74409122807018s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 2097164
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 23/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.75725704225352s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 6291459
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 23/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 3.77051590106007s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 10485776
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 23/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 3.78386879432624s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 10485796
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 23/30
Current state: 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.79731672597865s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 44639

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 11500
Accumulated number of search nodes in root state: 58138

Used RAM: 336880

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 23 -- REWARD RECEIVED: -5
***********************************************

***********************************************
>>> STARTING ROUND 24 -- REMAINING TIME 1070s
***********************************************
***********************************************
Planning step 1/40 in round 24/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 3.81086071428571s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0499198s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2581
Cache Hits: 0
Skipped backups: 235857
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61176 (in 2125 runs)
  Maximal search depth: 40
  Cache hits: 45069

Root Node: 
-15.5881 (in 503 real visits)

Q-Value Estimates: 
noop() : -15.5881 (in 201 real visits)
move-west : -16.1248 (in 276 real visits)
move-north : -21.6068 (in 26 real visits)

Used RAM: 336880

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 24/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 1 

Setting time for this decision to 3.82418637992832s.
DP-UCT: Maximal search depth set to 39

Search time: 0.051471s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2588
Cache Hits: 0
Skipped backups: 237534
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62069 (in 2146 runs)
  Maximal search depth: 40
  Cache hits: 45470

Root Node: 
-14.0659 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.4879 (in 107 real visits)
move-west : -14.0659 (in 376 real visits)
move-north : -22.2871 (in 20 real visits)

Used RAM: 336888

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 24/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 3.83774460431655s.
DP-UCT: Maximal search depth set to 38

Search time: 0.036459s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2278
Cache Hits: 0
Skipped backups: 239160
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 45803

Root Node: 
-7.36841 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.2142 (in 23 real visits)
move-west : -16.4035 (in 15 real visits)
move-north : -7.36841 (in 444 real visits)
move-east : -15.491 (in 22 real visits)

Used RAM: 336912

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 24/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 3.85145487364621s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0187819s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1834
Cache Hits: 0
Skipped backups: 240723
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46042

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -37 (in 5 real visits)
move-west : -15.125 (in 10 real visits)
move-south : -15.1827 (in 10 real visits)
move-north : -3 (in 470 real visits)
move-east : -20.7687 (in 10 real visits)

Used RAM: 336912

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 24/30
Current state: 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 0 

Setting time for this decision to 3.86532608695652s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0169961s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1802
Cache Hits: 0
Skipped backups: 242280
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46278

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -7.0025 (in 10 real visits)
move-west : -13.1333 (in 10 real visits)
move-south : -14.8833 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -9.14 (in 10 real visits)

Used RAM: 336912

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 24/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 0 

Setting time for this decision to 3.87930909090909s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0165081s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1817
Cache Hits: 0
Skipped backups: 243618
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 191 real visits)
move-west : -7.3225 (in 7 real visits)
move-south : -3 (in 301 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 336912

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 24/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.89339051094891s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 34
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 24/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.90764102564103s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 33
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 24/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 3.92199632352941s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 32
StateHashKey: 10485776
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 24/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.93645387453875s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 31
StateHashKey: 6291492
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 24/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.95102222222222s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 2097177
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 24/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 3.96569516728625s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 29
StateHashKey: 2097158
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 24/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.98047388059702s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 6291457
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 24/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 3.99536329588015s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 27
StateHashKey: 6291472
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 24/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 4.01036842105263s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 6291476
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 24/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 4.02548679245283s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 25
StateHashKey: 10485781
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 24/30
Current state: 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 4.0407196969697s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 24
StateHashKey: 10485797
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 24/30
Current state: 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 4.05606844106464s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 23
StateHashKey: 10485801
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 24/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.07153435114504s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 2097194
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 24/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.08711877394636s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 2097162
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 24/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 4.10281923076923s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 10485762
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 24/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.11864478764479s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 2097184
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 24/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 4.13459302325581s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 10485768
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 24/30
Current state: 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 4.15066536964981s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 17
StateHashKey: 6291490
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 24/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 4.166859375s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 6291480
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 24/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.18318039215686s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 2097174
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 24/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.19963385826772s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 2097157
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 24/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 4.21621343873518s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 6291457
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 24/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.2329246031746s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 24/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.24976892430279s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 2097156
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 24/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.266748s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 24/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 4.28386746987952s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 9
StateHashKey: 14680064
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 24/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.30112096774194s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 2097200
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 24/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.31851821862348s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 2097164
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 24/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.33605691056911s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 2097155
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 24/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.35373469387755s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 24/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.37156147540984s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 24/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 4.38953086419753s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 14680064
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 24/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.40765289256198s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 2097200
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 24/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 4.42592116182573s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46518

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 12000
Accumulated number of search nodes in root state: 60719

Used RAM: 336912

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 24 -- REWARD RECEIVED: -6
***********************************************

***********************************************
>>> STARTING ROUND 25 -- REMAINING TIME 1069s
***********************************************
***********************************************
Planning step 1/40 in round 25/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 4.44434583333333s.
DP-UCT: Maximal search depth set to 40

Search time: 0.048522s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2547
Cache Hits: 0
Skipped backups: 245190
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 46928

Root Node: 
-14.1519 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.8986 (in 120 real visits)
move-west : -14.1519 (in 359 real visits)
move-north : -21.7062 (in 24 real visits)

Used RAM: 336912

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 25/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 4.46256066945607s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0336299s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2173
Cache Hits: 0
Skipped backups: 246705
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 47244

Root Node: 
-7.51877 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.875 (in 19 real visits)
move-west : -16.807 (in 15 real visits)
move-north : -7.51877 (in 448 real visits)
move-east : -15.4775 (in 22 real visits)

Used RAM: 336916

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 25/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 4.48115546218487s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0193539s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1914
Cache Hits: 0
Skipped backups: 248421
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 47503

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -38 (in 5 real visits)
move-west : -15.653 (in 10 real visits)
move-south : -15.5 (in 10 real visits)
move-north : -3 (in 470 real visits)
move-east : -16.965 (in 10 real visits)

Used RAM: 336916

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 25/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 0 

Setting time for this decision to 4.49996202531646s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0175669s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1872
Cache Hits: 0
Skipped backups: 250089
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6218 (in 2147 runs)
  Maximal search depth: 40
  Cache hits: 47753

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -10.2857 (in 10 real visits)
move-west : -13.9167 (in 10 real visits)
move-south : -12.68 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -12.5 (in 10 real visits)

Used RAM: 336916

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 25/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 1 0 

Setting time for this decision to 4.5189406779661s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0176978s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1834
Cache Hits: 0
Skipped backups: 251724
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -3.6275 (in 16 real visits)
move-west : -3 (in 473 real visits)
move-south : -10.695 (in 10 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 336916

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 25/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 4.53807659574468s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 35
StateHashKey: 14680081
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 25/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.55745726495726s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 34
StateHashKey: 2097204
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 25/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.577s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 33
StateHashKey: 2097165
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 25/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 4.59671120689655s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 32
StateHashKey: 6291459
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 25/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.61659307359307s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 31
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 25/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 4.63664347826087s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 30
StateHashKey: 14680068
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 25/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.65687336244542s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 29
StateHashKey: 2097201
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 25/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.67727631578947s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 2097164
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 25/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 4.69786343612335s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 14680067
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 25/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.71862831858407s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 2097200
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 25/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.73957777777778s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 2097164
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 25/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.76072321428571s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 2097155
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 25/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 4.78204932735426s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 25/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 4.80356756756757s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 22
StateHashKey: 14680080
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 25/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 4.82528054298642s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 21
StateHashKey: 10485812
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 25/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.84719090909091s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 20
StateHashKey: 2097197
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 25/30
Current state: 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.86929680365297s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 2097163
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 25/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.89161467889908s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 2097154
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 25/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 4.91413824884793s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 17
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 25/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 4.93687037037037s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 25/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 4.95980930232558s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 6291460
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 25/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 4.98296728971963s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 6291473
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 25/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 5.00633802816901s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 2097172
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 25/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 5.02993396226415s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 2097157
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 25/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 5.05375355450237s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 25/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 5.07779523809524s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 25/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 5.10207177033493s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 25/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 5.12658173076923s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 25/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 5.15132850241546s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 7
StateHashKey: 10485776
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 25/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 5.17631553398058s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 6291492
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 25/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 5.2015512195122s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 2097177
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 25/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 5.22702450980392s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 2097158
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 25/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 5.25275369458128s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 3
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 25/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 5.27874257425743s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 10485760
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 25/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 5.30499502487562s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 47990

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 12500
Accumulated number of search nodes in root state: 63266

Used RAM: 336916

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 25 -- REWARD RECEIVED: -5
***********************************************

***********************************************
>>> STARTING ROUND 26 -- REMAINING TIME 1069s
***********************************************
***********************************************
Planning step 1/40 in round 26/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 5.3315s.
DP-UCT: Maximal search depth set to 40

Search time: 0.048342s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2610
Cache Hits: 0
Skipped backups: 253362
Initialization: 
  Statistics of IDS:
  Average search depth: 4.61931 (in 2154 runs)
  Maximal search depth: 40
  Cache hits: 48417

Root Node: 
-14.2214 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.4742 (in 124 real visits)
move-west : -14.2214 (in 363 real visits)
move-north : -22.5992 (in 16 real visits)

Used RAM: 336916

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 26/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 5.35784422110553s.
DP-UCT: Maximal search depth set to 39

Search time: 0.05547s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2597
Cache Hits: 0
Skipped backups: 254928
Initialization: 
  Statistics of IDS:
  Average search depth: 4.6192 (in 2156 runs)
  Maximal search depth: 40
  Cache hits: 48849

Root Node: 
-13.9372 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.9372 (in 234 real visits)
move-west : -16.4166 (in 118 real visits)
move-north : SOLVED with: -39 (in 5 real visits)
move-east : -16.0436 (in 147 real visits)

Used RAM: 336924

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 26/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 5.38460606060606s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0572069s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2626
Cache Hits: 0
Skipped backups: 256536
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62002 (in 2158 runs)
  Maximal search depth: 40
  Cache hits: 49289

Root Node: 
-15.4266 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.4266 (in 192 real visits)
move-west : -15.8457 (in 145 real visits)
move-north : -38 (in 4 real visits)
move-east : -15.6727 (in 163 real visits)

Used RAM: 336928

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 26/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 5.41162944162437s.
DP-UCT: Maximal search depth set to 37

Search time: 0.056638s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2634
Cache Hits: 0
Skipped backups: 258090
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62083 (in 2160 runs)
  Maximal search depth: 40
  Cache hits: 49724

Root Node: 
-14.8305 (in 504 real visits)

Q-Value Estimates: 
noop() : -14.8305 (in 251 real visits)
move-west : -15.7882 (in 121 real visits)
move-north : SOLVED with: -37 (in 5 real visits)
move-east : -15.7276 (in 127 real visits)

Used RAM: 336932

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 26/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 5.43893367346939s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0551488s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2639
Cache Hits: 0
Skipped backups: 259656
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62193 (in 2161 runs)
  Maximal search depth: 40
  Cache hits: 50160

Root Node: 
-12.6132 (in 504 real visits)

Q-Value Estimates: 
noop() : -12.6132 (in 282 real visits)
move-west : -15.3811 (in 104 real visits)
move-north : SOLVED with: -36 (in 5 real visits)
move-east : -15.2323 (in 113 real visits)

Used RAM: 336936

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 26/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 5.46652307692308s.
DP-UCT: Maximal search depth set to 35

Search time: 0.032702s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2193
Cache Hits: 0
Skipped backups: 261168
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62257 (in 2162 runs)
  Maximal search depth: 40
  Cache hits: 50475

Root Node: 
-7.08634 (in 504 real visits)

Q-Value Estimates: 
noop() : -14.132 (in 25 real visits)
move-west : -15.099 (in 18 real visits)
move-north : -7.08634 (in 430 real visits)
move-east : -13.5603 (in 31 real visits)

Used RAM: 336940

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 26/30
Current state: 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 5.49451546391753s.
DP-UCT: Maximal search depth set to 34

Search time: 0.019881s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1907
Cache Hits: 0
Skipped backups: 262764
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62257 (in 2162 runs)
  Maximal search depth: 40
  Cache hits: 50733

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -13.0279 (in 10 real visits)
move-west : -14.06 (in 10 real visits)
move-south : -14 (in 10 real visits)
move-north : -3 (in 465 real visits)
move-east : -16.9599 (in 10 real visits)

Used RAM: 336940

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 26/30
Current state: 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 0 

Setting time for this decision to 5.52286528497409s.
DP-UCT: Maximal search depth set to 33

Search time: 0.019031s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1821
Cache Hits: 0
Skipped backups: 264345
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62228 (in 2163 runs)
  Maximal search depth: 40
  Cache hits: 50967

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -8.9075 (in 10 real visits)
move-west : -12.3333 (in 10 real visits)
move-south : -12.8 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -11.3 (in 10 real visits)

Used RAM: 336940

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 9/40 in round 26/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 1 

Setting time for this decision to 5.55151041666667s.
DP-UCT: Maximal search depth set to 32

Search time: 0.014694s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1690
Cache Hits: 0
Skipped backups: 265881
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 484 real visits)
move-west : -5.9055 (in 10 real visits)
move-south : SOLVED with: -32 (in 5 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 336940

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 10/40 in round 26/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 5.58048167539267s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 31
StateHashKey: 2097184
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 26/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 5.60983157894737s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 6291464
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 26/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 5.63949735449735s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 29
StateHashKey: 6291474
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 26/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 5.66946808510638s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 2097172
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 26/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 5.69976470588235s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 27
StateHashKey: 2097157
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 26/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 5.73038709677419s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 6291457
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 26/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 5.76133513513513s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 26/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 5.792625s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 2097156
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 26/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 5.82425136612022s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 26/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 5.85623076923077s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 26/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 5.8885635359116s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 21
StateHashKey: 10485760
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 26/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 5.92125555555556s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 10485792
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 26/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 5.95431284916201s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 10485800
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 26/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 5.98774157303371s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 2097194
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 26/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 6.02154802259887s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 17
StateHashKey: 6291466
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 26/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 6.05573863636364s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 2097170
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 26/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 6.09032s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 6291460
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 26/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 6.12529310344828s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 6291473
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 26/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 6.16067630057803s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 2097172
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 26/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 6.19646511627907s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 10485765
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 26/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 6.2326783625731s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 6291489
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 26/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 6.26931176470588s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 2097176
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 26/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 6.30638461538462s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 2097158
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 26/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 6.34389285714286s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 6291457
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 26/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 6.38185628742515s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 26/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 6.42027710843374s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 6291460
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 26/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 6.45916363636364s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 2097169
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 26/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 6.4985243902439s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 4
StateHashKey: 10485764
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 26/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 6.53836196319018s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 3
StateHashKey: 2097185
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 26/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 6.5786975308642s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 2097160
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 26/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 6.61953416149068s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62153 (in 2164 runs)
  Maximal search depth: 40
  Cache hits: 51182

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 13000
Accumulated number of search nodes in root state: 65876

Used RAM: 336940

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 26 -- REWARD RECEIVED: -9
***********************************************

***********************************************
>>> STARTING ROUND 27 -- REMAINING TIME 1068s
***********************************************
***********************************************
Planning step 1/40 in round 27/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 6.660875s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0529909s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2552
Cache Hits: 0
Skipped backups: 267558
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62079 (in 2165 runs)
  Maximal search depth: 40
  Cache hits: 51600

Root Node: 
-13.1681 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.3294 (in 113 real visits)
move-west : -13.1681 (in 374 real visits)
move-north : -22.1477 (in 16 real visits)

Used RAM: 336940

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 27/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 6.7021572327044s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0520751s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2517
Cache Hits: 0
Skipped backups: 269037
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 52005

Root Node: 
-13.2893 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.2893 (in 328 real visits)
move-west : -16.5699 (in 79 real visits)
move-north : SOLVED with: -39 (in 5 real visits)
move-east : -16.3358 (in 92 real visits)

Used RAM: 336944

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 27/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 6.74422151898734s.
DP-UCT: Maximal search depth set to 38

Search time: 0.034678s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2216
Cache Hits: 0
Skipped backups: 270459
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 52329

Root Node: 
-7.51222 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.2142 (in 27 real visits)
move-west : -16.2771 (in 20 real visits)
move-north : -7.51222 (in 427 real visits)
move-east : -14.9434 (in 30 real visits)

Used RAM: 336944

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 27/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 6.78693630573248s.
DP-UCT: Maximal search depth set to 37

Search time: 0.01932s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1874
Cache Hits: 0
Skipped backups: 272043
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 52579

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -37 (in 5 real visits)
move-west : -14.8773 (in 10 real visits)
move-south : -15.1827 (in 10 real visits)
move-north : -3 (in 470 real visits)
move-east : -21.7867 (in 10 real visits)

Used RAM: 336944

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 27/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 0 

Setting time for this decision to 6.83029487179487s.
DP-UCT: Maximal search depth set to 36

Search time: 0.017447s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1837
Cache Hits: 0
Skipped backups: 273609
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 52819

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -10.695 (in 10 real visits)
move-west : -11.4375 (in 10 real visits)
move-south : -13.9413 (in 10 real visits)
move-north : -2 (in 463 real visits)
move-east : -12.2 (in 12 real visits)

Used RAM: 336944

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 27/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 1 

Setting time for this decision to 6.87421935483871s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0161459s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1800
Cache Hits: 0
Skipped backups: 275343
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 484 real visits)
move-west : -5.175 (in 10 real visits)
move-south : SOLVED with: -35 (in 5 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 336944

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 27/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 6.91872727272727s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 34
StateHashKey: 6291489
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 27/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 6.96392810457516s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 33
StateHashKey: 2097176
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 27/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 7.00971710526316s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 32
StateHashKey: 2097158
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 27/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 7.05611258278146s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 31
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 27/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 7.10312666666667s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 30
StateHashKey: 10485760
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 27/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 7.15077181208054s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 10485792
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 27/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 7.19906081081081s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 2097192
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 27/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 7.248s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 27
StateHashKey: 2097162
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 27/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 7.29761643835616s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 2097154
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 27/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 7.34791724137931s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 27/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 7.39890972222222s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 27/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 7.45061538461539s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 23
StateHashKey: 14680064
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 27/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 7.50304929577465s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 2097200
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 27/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 7.55624113475177s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 2097164
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 27/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 7.61019285714286s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 20
StateHashKey: 2097155
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 27/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 7.66492805755396s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 27/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 7.72044927536232s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 14680080
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 27/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 7.77677372262774s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 17
StateHashKey: 2097204
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 27/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 7.83391911764706s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 16
StateHashKey: 14680077
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 27/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 7.89191851851852s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 2097203
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 27/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 7.95078358208955s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 2097164
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 27/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 8.01053383458647s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 2097155
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 27/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 8.07118181818182s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 12
StateHashKey: 14680064
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 27/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 8.13276335877863s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 6291504
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 27/30
Current state: 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 8.19529230769231s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 6291484
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 27/30
Current state: 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 8.25879069767442s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 9
StateHashKey: 10485783
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 27/30
Current state: 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 8.32328125s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 8
StateHashKey: 10485797
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 27/30
Current state: 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 8.3887874015748s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 7
StateHashKey: 10485801
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 27/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 8.4553253968254s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 6
StateHashKey: 10485802
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 27/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 8.522936s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 5
StateHashKey: 10485802
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 27/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 8.59162903225807s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 2097194
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 27/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 8.66144715447154s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 3
StateHashKey: 2097162
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 27/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 8.73240163934426s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 2097154
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 27/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 8.80452892561983s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62067 (in 2167 runs)
  Maximal search depth: 40
  Cache hits: 53056

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 13500
Accumulated number of search nodes in root state: 68428

Used RAM: 336944

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 27 -- REWARD RECEIVED: -6
***********************************************

***********************************************
>>> STARTING ROUND 28 -- REMAINING TIME 1068s
***********************************************
***********************************************
Planning step 1/40 in round 28/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 8.87786666666667s.
DP-UCT: Maximal search depth set to 40

Search time: 0.049284s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2567
Cache Hits: 0
Skipped backups: 276966
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62102 (in 2169 runs)
  Maximal search depth: 40
  Cache hits: 53473

Root Node: 
-12.7679 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.4813 (in 94 real visits)
move-west : -12.7679 (in 395 real visits)
move-north : -22.3215 (in 14 real visits)

Used RAM: 336944

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 28/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 8.95170588235294s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0522709s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2583
Cache Hits: 0
Skipped backups: 278487
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62275 (in 2171 runs)
  Maximal search depth: 40
  Cache hits: 53900

Root Node: 
-13.7842 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.7842 (in 284 real visits)
move-west : -16.5819 (in 76 real visits)
move-north : SOLVED with: -39 (in 5 real visits)
move-east : -15.4842 (in 139 real visits)

Used RAM: 336948

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 28/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 9.02709322033898s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0348711s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2255
Cache Hits: 0
Skipped backups: 280014
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62275 (in 2171 runs)
  Maximal search depth: 40
  Cache hits: 54229

Root Node: 
-7.84101 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.59 (in 17 real visits)
move-west : -15.6503 (in 17 real visits)
move-north : -7.84101 (in 448 real visits)
move-east : -14.798 (in 22 real visits)

Used RAM: 336952

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 28/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 9.10391452991453s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0191569s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1863
Cache Hits: 0
Skipped backups: 281469
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62275 (in 2171 runs)
  Maximal search depth: 40
  Cache hits: 54477

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : -13.6667 (in 10 real visits)
move-west : -15.2405 (in 10 real visits)
move-south : -15.2597 (in 10 real visits)
move-north : -3 (in 465 real visits)
move-east : -22.2449 (in 10 real visits)

Used RAM: 336952

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 28/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 0 0 

Setting time for this decision to 9.18219827586207s.
DP-UCT: Maximal search depth set to 36

Search time: 0.016221s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1719
Cache Hits: 0
Skipped backups: 282834
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62293 (in 2172 runs)
  Maximal search depth: 40
  Cache hits: 54693

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -10.5025 (in 10 real visits)
move-west : -13.7371 (in 10 real visits)
move-south : -13.3333 (in 10 real visits)
move-north : -2 (in 465 real visits)
move-east : -13.8275 (in 10 real visits)

Used RAM: 336952

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 28/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 1 0 

Setting time for this decision to 9.26187826086957s.
DP-UCT: Maximal search depth set to 35

Search time: 0.0167642s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1799
Cache Hits: 0
Skipped backups: 284436
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -4.25 (in 14 real visits)
move-west : -3 (in 475 real visits)
move-south : -7.3225 (in 10 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 336952

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 28/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 9.34293859649123s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 34
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 28/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 9.42558407079646s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 33
StateHashKey: 6291460
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 28/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 9.50971428571428s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 32
StateHashKey: 2097169
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 28/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 9.59535135135135s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 31
StateHashKey: 10485764
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 28/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 9.68253636363636s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 30
StateHashKey: 10485793
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 28/30
Current state: 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 9.77133027522936s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 14680104
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 28/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 9.86176851851852s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 28
StateHashKey: 10485818
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 28/30
Current state: 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 9.95389719626168s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 10485806
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 28/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 10.0477641509434s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 2097195
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 28/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 10.143419047619s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 2097162
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 28/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 10.2409134615385s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 6291458
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 28/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 10.3403009708738s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 23
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 28/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 10.441637254902s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 22
StateHashKey: 10485764
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 28/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 10.5449801980198s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 6291489
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 28/30
Current state: 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 10.65039s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 20
StateHashKey: 6291480
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 28/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 10.7579292929293s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 19
StateHashKey: 10485782
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 28/30
Current state: 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 10.8676632653061s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 18
StateHashKey: 2097189
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 28/30
Current state: 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 10.9796494845361s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 17
StateHashKey: 14680073
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 28/30
Current state: 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 11.0939791666667s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 2097202
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 28/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 11.2107157894737s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 15
StateHashKey: 14680076
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 28/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 11.3299361702128s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 14680115
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 28/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 11.4517204301075s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 13
StateHashKey: 10485820
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 28/30
Current state: 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 11.576152173913s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 6291503
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 28/30
Current state: 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 11.7033186813187s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 2097179
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 28/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 11.8333s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 2097158
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 28/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 11.966202247191s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 9
StateHashKey: 6291457
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 28/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 12.1021136363636s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 28/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 12.2411609195402s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 2097156
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 28/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 12.3834534883721s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 28/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 12.5290941176471s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 28/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 12.6782023809524s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 4
StateHashKey: 2097168
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 28/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 12.8309036144578s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 3
StateHashKey: 6291460
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 28/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 12.9873170731707s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 2097169
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 28/30
Current state: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 13.1476049382716s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 54928

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 14000
Accumulated number of search nodes in root state: 70995

Used RAM: 336952

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 28 -- REWARD RECEIVED: -6
***********************************************

***********************************************
>>> STARTING ROUND 29 -- REMAINING TIME 1067s
***********************************************
***********************************************
Planning step 1/40 in round 29/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 13.3119s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0543051s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2640
Cache Hits: 0
Skipped backups: 286110
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62236 (in 2174 runs)
  Maximal search depth: 40
  Cache hits: 55368

Root Node: 
-16.0837 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.6596 (in 191 real visits)
move-west : -16.0837 (in 292 real visits)
move-north : -22.9258 (in 20 real visits)

Used RAM: 336952

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 29/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 13.4791772151899s.
DP-UCT: Maximal search depth set to 39

Search time: 0.05354s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2568
Cache Hits: 0
Skipped backups: 287598
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62534 (in 2178 runs)
  Maximal search depth: 40
  Cache hits: 55786

Root Node: 
-13.3607 (in 504 real visits)

Q-Value Estimates: 
noop() : -13.3607 (in 300 real visits)
move-west : -16.5856 (in 87 real visits)
move-north : SOLVED with: -39 (in 5 real visits)
move-east : -16.1032 (in 112 real visits)

Used RAM: 336960

Submitted action: noop() 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 29/30
Current state: 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 13.6512435897436s.
DP-UCT: Maximal search depth set to 38

Search time: 0.035027s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2213
Cache Hits: 0
Skipped backups: 289167
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62534 (in 2178 runs)
  Maximal search depth: 40
  Cache hits: 56107

Root Node: 
-7.1571 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.5 (in 26 real visits)
move-west : -16.4035 (in 19 real visits)
move-north : -7.1571 (in 436 real visits)
move-east : -16.2837 (in 23 real visits)

Used RAM: 336964

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 29/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 1 

Setting time for this decision to 13.828025974026s.
DP-UCT: Maximal search depth set to 37

Search time: 0.050406s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2568
Cache Hits: 0
Skipped backups: 290682
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62661 (in 2180 runs)
  Maximal search depth: 40
  Cache hits: 56510

Root Node: 
-12.7362 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -37 (in 5 real visits)
move-west : -15.0777 (in 124 real visits)
move-south : -12.7362 (in 354 real visits)
move-north : SOLVED with: -37 (in 5 real visits)
move-east : -20.6516 (in 17 real visits)

Used RAM: 336964

Submitted action: move-south 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 29/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 1 

Setting time for this decision to 14.0092631578947s.
DP-UCT: Maximal search depth set to 36

Search time: 0.032896s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2141
Cache Hits: 0
Skipped backups: 292155
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62586 (in 2181 runs)
  Maximal search depth: 40
  Cache hits: 56815

Root Node: 
-6.84772 (in 504 real visits)

Q-Value Estimates: 
noop() : -14.405 (in 19 real visits)
move-west : -15.595 (in 13 real visits)
move-north : -6.84772 (in 459 real visits)
move-east : -15.5775 (in 13 real visits)

Used RAM: 336964

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 29/30
Current state: 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 14.19556s.
DP-UCT: Maximal search depth set to 35

Search time: 0.018949s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1827
Cache Hits: 0
Skipped backups: 293706
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57049

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -35 (in 5 real visits)
move-west : -14.4425 (in 10 real visits)
move-south : -14.4425 (in 10 real visits)
move-north : -3 (in 470 real visits)
move-east : -18.5412 (in 10 real visits)

Used RAM: 336964

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 7/40 in round 29/30
Current state: 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 0 

Setting time for this decision to 14.3870810810811s.
DP-UCT: Maximal search depth set to 34

Search time: 0.017154s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1787
Cache Hits: 0
Skipped backups: 295248
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57279

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -10.6 (in 10 real visits)
move-west : -12.6667 (in 10 real visits)
move-south : SOLVED with: -34 (in 5 real visits)
move-north : -2 (in 470 real visits)
move-east : -11.6 (in 10 real visits)

Used RAM: 336964

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 8/40 in round 29/30
Current state: 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 0 0 

Setting time for this decision to 14.5838904109589s.
DP-UCT: Maximal search depth set to 33

Search time: 0.0156229s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1789
Cache Hits: 0
Skipped backups: 296658
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 373 real visits)
move-west : -3.4374 (in 118 real visits)
move-south : -9.9225 (in 8 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 336964

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 9/40 in round 29/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 14.7861666666667s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 32
StateHashKey: 14680069
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 29/30
Current state: 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 14.9943661971831s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 31
StateHashKey: 14680113
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 29/30
Current state: 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 15.2085285714286s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 30
StateHashKey: 6291516
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 29/30
Current state: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 15.428884057971s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 14680095
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 29/30
Current state: 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 15.6557205882353s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 2097207
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 29/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 15.889328358209s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 27
StateHashKey: 14680077
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 29/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 16.13s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 6291507
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 29/30
Current state: 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 16.3780923076923s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 2097180
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 29/30
Current state: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 16.633921875s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 2097159
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 29/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 16.8978412698413s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 23
StateHashKey: 14680065
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 29/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 17.1703387096774s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 6291504
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 29/30
Current state: 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 17.4517704918033s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 2097180
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 29/30
Current state: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 17.7425833333333s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 20
StateHashKey: 2097159
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 29/30
Current state: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 18.0432203389831s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 2097153
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 29/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 18.354224137931s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 10485760
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 29/30
Current state: 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 18.6761403508772s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 17
StateHashKey: 2097184
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 29/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 19.0095535714286s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 2097160
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 29/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 19.3550909090909s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 2097154
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 29/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 19.7134259259259s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 14
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 29/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 20.0853018867925s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 13
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 29/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 20.4714807692308s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 2097152
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 29/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 20.8727843137255s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 11
StateHashKey: 14680064
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 29/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 21.29016s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 2097200
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 29/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 21.7245714285714s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 9
StateHashKey: 14680076
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 29/30
Current state: 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 22.1770625s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 2097203
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 29/30
Current state: 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 22.648829787234s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 7
StateHashKey: 2097164
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 29/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 23.1411086956522s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 2097155
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 29/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 23.6552444444444s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 5
StateHashKey: 6291456
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 29/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 24.1927727272727s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 4
StateHashKey: 10485776
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 29/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 24.7553023255814s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 3
StateHashKey: 14680100
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 29/30
Current state: 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 25.344619047619s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 2
StateHashKey: 14680121
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 29/30
Current state: 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 25.9626585365854s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57514

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 14500
Accumulated number of search nodes in root state: 73635

Used RAM: 336964

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 29 -- REWARD RECEIVED: -8
***********************************************

***********************************************
>>> STARTING ROUND 30 -- REMAINING TIME 1067s
***********************************************
***********************************************
Planning step 1/40 in round 30/30
Current state: 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 | 0 0 

Setting time for this decision to 26.611625s.
DP-UCT: Maximal search depth set to 40

Search time: 0.0486488s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2543
Cache Hits: 0
Skipped backups: 298179
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 57928

Root Node: 
-12.6767 (in 503 real visits)

Q-Value Estimates: 
noop() : -16.538 (in 127 real visits)
move-west : -12.6767 (in 352 real visits)
move-north : -22.129 (in 24 real visits)

Used RAM: 336964

Submitted action: move-west 
Immediate reward: -1
***********************************************

***********************************************
Planning step 2/40 in round 30/30
Current state: 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 | 0 0 

Setting time for this decision to 27.2916923076923s.
DP-UCT: Maximal search depth set to 39

Search time: 0.0319071s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 2236
Cache Hits: 0
Skipped backups: 299721
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62574 (in 2183 runs)
  Maximal search depth: 40
  Cache hits: 58250

Root Node: 
-7.14703 (in 504 real visits)

Q-Value Estimates: 
noop() : -15.4462 (in 19 real visits)
move-west : -16.81 (in 14 real visits)
move-north : -7.14703 (in 438 real visits)
move-east : -14.7103 (in 33 real visits)

Used RAM: 336972

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 3/40 in round 30/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 | 1 0 

Setting time for this decision to 28.0089736842105s.
DP-UCT: Maximal search depth set to 38

Search time: 0.0186222s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1904
Cache Hits: 0
Skipped backups: 301380
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62563 (in 2185 runs)
  Maximal search depth: 40
  Cache hits: 58507

Root Node: 
-3 (in 505 real visits)

Q-Value Estimates: 
noop() : SOLVED with: -38 (in 5 real visits)
move-west : -15.59 (in 10 real visits)
move-south : -15.527 (in 10 real visits)
move-north : -3 (in 470 real visits)
move-east : -16.125 (in 10 real visits)

Used RAM: 336972

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 4/40 in round 30/30
Current state: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 | 1 0 

Setting time for this decision to 28.7653513513514s.
DP-UCT: Maximal search depth set to 37

Search time: 0.0163012s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1748
Cache Hits: 0
Skipped backups: 302919
Initialization: 
  Statistics of IDS:
  Average search depth: 4.62534 (in 2186 runs)
  Maximal search depth: 40
  Cache hits: 58735

Root Node: 
-2 (in 505 real visits)

Q-Value Estimates: 
noop() : -8.1 (in 10 real visits)
move-west : -13.1735 (in 10 real visits)
move-south : SOLVED with: -37 (in 5 real visits)
move-north : -2 (in 470 real visits)
move-east : -12.5 (in 10 real visits)

Used RAM: 336972

Submitted action: move-north 
Immediate reward: -1
***********************************************

***********************************************
Planning step 5/40 in round 30/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 | 1 1 

Setting time for this decision to 29.5638333333333s.
DP-UCT: Maximal search depth set to 36

Search time: 0.0169649s
Statistics of DP-UCT:
Performed trials: 500
Created SearchNodes: 1778
Cache Hits: 0
Skipped backups: 304485
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Root Node: 
-1 (in 504 real visits)

Q-Value Estimates: 
noop() : -2 (in 93 real visits)
move-west : -3 (in 401 real visits)
move-south : SOLVED with: -36 (in 5 real visits)
move-east : SOLVED with: -1 (in 5 real visits)

Used RAM: 336972

Submitted action: move-east 
Immediate reward: -1
***********************************************

***********************************************
Planning step 6/40 in round 30/30
Current state: 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 30.4079428571429s.
DP-UCT: Maximal search depth set to 35

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 35
StateHashKey: 2097205
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 7/40 in round 30/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 31.3022058823529s.
DP-UCT: Maximal search depth set to 34

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 34
StateHashKey: 6291469
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 8/40 in round 30/30
Current state: 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 32.2506363636364s.
DP-UCT: Maximal search depth set to 33

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 33
StateHashKey: 14680083
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 9/40 in round 30/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 33.258375s.
DP-UCT: Maximal search depth set to 32

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 32
StateHashKey: 10485812
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 10/40 in round 30/30
Current state: 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 34.3310967741935s.
DP-UCT: Maximal search depth set to 31

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 31
StateHashKey: 10485805
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 11/40 in round 30/30
Current state: 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 35.4753666666667s.
DP-UCT: Maximal search depth set to 30

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 30
StateHashKey: 14680107
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 12/40 in round 30/30
Current state: 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 36.6984827586207s.
DP-UCT: Maximal search depth set to 29

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 29
StateHashKey: 10485818
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 13/40 in round 30/30
Current state: 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 38.0089642857143s.
DP-UCT: Maximal search depth set to 28

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 28
StateHashKey: 2097198
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 14/40 in round 30/30
Current state: 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 39.4165185185185s.
DP-UCT: Maximal search depth set to 27

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 27
StateHashKey: 6291467
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 15/40 in round 30/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 40.9323846153846s.
DP-UCT: Maximal search depth set to 26

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 26
StateHashKey: 6291474
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 16/40 in round 30/30
Current state: 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 42.56952s.
DP-UCT: Maximal search depth set to 25

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 25
StateHashKey: 6291476
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 17/40 in round 30/30
Current state: 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 44.3430833333333s.
DP-UCT: Maximal search depth set to 24

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 24
StateHashKey: 2097173
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 18/40 in round 30/30
Current state: 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 46.2708260869565s.
DP-UCT: Maximal search depth set to 23

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 23
StateHashKey: 10485765
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 19/40 in round 30/30
Current state: 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 48.3738636363636s.
DP-UCT: Maximal search depth set to 22

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 22
StateHashKey: 2097185
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 20/40 in round 30/30
Current state: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 50.6771428571429s.
DP-UCT: Maximal search depth set to 21

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 21
StateHashKey: 6291464
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 21/40 in round 30/30
Current state: 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 53.21085s.
DP-UCT: Maximal search depth set to 20

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 20
StateHashKey: 14680082
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 22/40 in round 30/30
Current state: 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 56.0111578947368s.
DP-UCT: Maximal search depth set to 19

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 19
StateHashKey: 6291508
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 23/40 in round 30/30
Current state: 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 59.1226666666667s.
DP-UCT: Maximal search depth set to 18

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 18
StateHashKey: 10485789
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 24/40 in round 30/30
Current state: 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 62.6002352941176s.
DP-UCT: Maximal search depth set to 17

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 17
StateHashKey: 2097191
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 25/40 in round 30/30
Current state: 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 66.5125s.
DP-UCT: Maximal search depth set to 16

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 16
StateHashKey: 2097161
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 26/40 in round 30/30
Current state: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 70.9463333333333s.
DP-UCT: Maximal search depth set to 15

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 15
StateHashKey: 2097154
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 27/40 in round 30/30
Current state: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 76.0136428571429s.
DP-UCT: Maximal search depth set to 14

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 14
StateHashKey: 14680064
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 28/40 in round 30/30
Current state: 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 81.8605384615385s.
DP-UCT: Maximal search depth set to 13

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 13
StateHashKey: 10485808
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 29/40 in round 30/30
Current state: 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 88.6819166666667s.
DP-UCT: Maximal search depth set to 12

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 12
StateHashKey: 6291500
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 30/40 in round 30/30
Current state: 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 96.7435454545455s.
DP-UCT: Maximal search depth set to 11

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 11
StateHashKey: 2097179
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 31/40 in round 30/30
Current state: 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 106.4175s.
DP-UCT: Maximal search depth set to 10

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 10
StateHashKey: 6291462
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 32/40 in round 30/30
Current state: 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 118.241111111111s.
DP-UCT: Maximal search depth set to 9

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 9
StateHashKey: 10485777
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 33/40 in round 30/30
Current state: 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 0 

Setting time for this decision to 133.02075s.
DP-UCT: Maximal search depth set to 8

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 0
Remaining Steps: 8
StateHashKey: 6291492
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 34/40 in round 30/30
Current state: 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 152.023142857143s.
DP-UCT: Maximal search depth set to 7

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 7
StateHashKey: 14680089
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 35/40 in round 30/30
Current state: 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 177.3595s.
DP-UCT: Maximal search depth set to 6

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 6
StateHashKey: 2097206
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 36/40 in round 30/30
Current state: 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 1 

Setting time for this decision to 212.8306s.
DP-UCT: Maximal search depth set to 5

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 1
Remaining Steps: 5
StateHashKey: 10485773
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 37/40 in round 30/30
Current state: 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 1 1 

Setting time for this decision to 266.037s.
DP-UCT: Maximal search depth set to 4

Current root state is a reward lock state!
obstacle-at(x1, y2): 1
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 0
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 1
obstacle-at(x4, y3): 1
Remaining Steps: 4
StateHashKey: 14680099
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 38/40 in round 30/30
Current state: 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 354.714666666667s.
DP-UCT: Maximal search depth set to 3

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 0
obstacle-at(x2, y2): 0
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 1
obstacle-at(x3, y3): 1
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 3
StateHashKey: 2097208
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 39/40 in round 30/30
Current state: 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 532.07s.
DP-UCT: Maximal search depth set to 2

Current root state is a reward lock state!
obstacle-at(x1, y2): 0
obstacle-at(x1, y3): 1
obstacle-at(x2, y2): 1
obstacle-at(x2, y3): 1
obstacle-at(x3, y2): 0
obstacle-at(x3, y3): 0
robot-at(x1, y1): 0
robot-at(x1, y2): 0
robot-at(x1, y3): 0
robot-at(x1, y4): 0
robot-at(x2, y1): 0
robot-at(x2, y2): 0
robot-at(x2, y3): 0
robot-at(x2, y4): 0
robot-at(x3, y1): 0
robot-at(x3, y2): 0
robot-at(x3, y3): 0
robot-at(x3, y4): 0
robot-at(x4, y1): 0
robot-at(x4, y2): 0
robot-at(x4, y3): 0
robot-at(x4, y4): 1

obstacle-at(x4, y2): 0
obstacle-at(x4, y3): 0
Remaining Steps: 2
StateHashKey: 2097166
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
Planning step 40/40 in round 30/30
Current state: 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 | 0 0 

Setting time for this decision to 1064.136s.
DP-UCT: Maximal search depth set to 1

Returning the optimal last action!
Returning unique policy: noop() 

Statistics of DP-UCT:
Initialization: 
  Statistics of IDS:
  Average search depth: 4.60988 (in 2207 runs)
  Maximal search depth: 40
  Cache hits: 58950

ROUND FINISHED
Accumulated number of remaining steps in first solved root state: 0
Accumulated number of trials in root state: 15000
Accumulated number of search nodes in root state: 76178

Used RAM: 336992

Submitted action: noop() 
Immediate reward: 0
***********************************************

***********************************************
>>> END OF ROUND 30 -- REWARD RECEIVED: -5
***********************************************

***********************************************
Immediate rewards:
Round 0: -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -6
Round 1: -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -7
Round 2: -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -6
Round 3: -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -6
Round 4: -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -5
Round 5: -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -5
Round 6: -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -6
Round 7: -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -10
Round 8: -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -14
Round 9: -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -5
Round 10: -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -5
Round 11: -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -5
Round 12: -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -5
Round 13: -1 -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -8
Round 14: -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -5
Round 15: -1 -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -8
Round 16: -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -7
Round 17: -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -11
Round 18: -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -5
Round 19: -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -5
Round 20: -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -5
Round 21: -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -5
Round 22: -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -5
Round 23: -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -6
Round 24: -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -5
Round 25: -1 -1 -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -9
Round 26: -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -6
Round 27: -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -6
Round 28: -1 -1 -1 -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -8
Round 29: -1 -1 -1 -1 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  = -5

>>>           TOTAL REWARD: -194
>>>          AVERAGE REWARD: -6.46666666666667
***********************************************
PROST complete running time: 13.6943960189819s
